{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from os import path\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import RSLPStemmer\n",
    "import text_unidecode as unidecode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews_df = pd.read_csv('interview_data.csv', sep=',', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Interview Questions</th>\n",
       "      <th>Date</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Offer?</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Difficulty of Interview</th>\n",
       "      <th>How the candidate applied</th>\n",
       "      <th>Process</th>\n",
       "      <th>Who found review helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>Why you ? What brough tyou here ?</td>\n",
       "      <td>30-May-23</td>\n",
       "      <td>Anonymous Interview Candidate in Zürich</td>\n",
       "      <td>Declined Offer</td>\n",
       "      <td>Neutral Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google (Zürich)</td>\n",
       "      <td>It wa s avery smooth interviw . I really liked...</td>\n",
       "      <td>Be the first to find this interview helpful\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>How would you optimize a database query? How w...</td>\n",
       "      <td>18-May-23</td>\n",
       "      <td>Anonymous Interview Candidate</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>I interviewed at Google</td>\n",
       "      <td>They asked me about my technical skills and st...</td>\n",
       "      <td>2 people found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>predict some metrics using regression</td>\n",
       "      <td>4-May-23</td>\n",
       "      <td>Anonymous Interview Candidate in Mountain View...</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google (Mountain View, CA)</td>\n",
       "      <td>brainstorm some statistics question with the i...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>How would you forecast a brands sales.</td>\n",
       "      <td>2-May-23</td>\n",
       "      <td>Anonymous Interview Candidate in London, England</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Neutral Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google (London, England)</td>\n",
       "      <td>Few relatively simple technical questions. Ver...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>I signed an NDA cannot disclose those</td>\n",
       "      <td>27-Mar-23</td>\n",
       "      <td>Anonymous Employee</td>\n",
       "      <td>Accepted Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google</td>\n",
       "      <td>There is s a tech screen and then an onsite. Y...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company                                Interview Questions       Date  \\\n",
       "0  Google                  Why you ? What brough tyou here ?  30-May-23   \n",
       "1  Google  How would you optimize a database query? How w...  18-May-23   \n",
       "2  Google              predict some metrics using regression   4-May-23   \n",
       "3  Google             How would you forecast a brands sales.   2-May-23   \n",
       "4  Google              I signed an NDA cannot disclose those  27-Mar-23   \n",
       "\n",
       "                                           Candidate          Offer?  \\\n",
       "0            Anonymous Interview Candidate in Zürich  Declined Offer   \n",
       "1                      Anonymous Interview Candidate        No Offer   \n",
       "2  Anonymous Interview Candidate in Mountain View...        No Offer   \n",
       "3   Anonymous Interview Candidate in London, England        No Offer   \n",
       "4                                 Anonymous Employee  Accepted Offer   \n",
       "\n",
       "           Experience  Difficulty of Interview  \\\n",
       "0   Neutral Experience     Difficult Interview   \n",
       "1  Positive Experience       Average Interview   \n",
       "2  Positive Experience     Difficult Interview   \n",
       "3   Neutral Experience     Difficult Interview   \n",
       "4  Positive Experience     Difficult Interview   \n",
       "\n",
       "                     How the candidate applied  \\\n",
       "0             I interviewed at Google (Zürich)   \n",
       "1                      I interviewed at Google   \n",
       "2  I interviewed at Google (Mountain View, CA)   \n",
       "3    I interviewed at Google (London, England)   \n",
       "4                      I interviewed at Google   \n",
       "\n",
       "                                             Process  \\\n",
       "0  It wa s avery smooth interviw . I really liked...   \n",
       "1  They asked me about my technical skills and st...   \n",
       "2  brainstorm some statistics question with the i...   \n",
       "3  Few relatively simple technical questions. Ver...   \n",
       "4  There is s a tech screen and then an onsite. Y...   \n",
       "\n",
       "                            Who found review helpful  \n",
       "0  Be the first to find this interview helpful\\nH...  \n",
       "1  2 people found this interview helpful\\nHelpful...  \n",
       "2  1 person found this interview helpful\\nHelpful...  \n",
       "3  1 person found this interview helpful\\nHelpful...  \n",
       "4  1 person found this interview helpful\\nHelpful...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interviews_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text in DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/conls91/nltk_data...\n",
      "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentence):\n",
    "    # Lower case all text\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Remove all numbers\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    \n",
    "    # Remove all punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "    \n",
    "    # Tokenize \n",
    "    tokenized_sentence = word_tokenize(sentence)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenized_sentence = [w for w in tokenized_sentence if not w in stop_words]\n",
    "    \n",
    "    # Join tokenized sentence back together\n",
    "    cleaned_sentence = ' '.join(tokenized_sentence)\n",
    "    \n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Interview Questions</th>\n",
       "      <th>Date</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Offer?</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Difficulty of Interview</th>\n",
       "      <th>How the candidate applied</th>\n",
       "      <th>Process</th>\n",
       "      <th>Who found review helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>Why you ? What brough tyou here ?</td>\n",
       "      <td>30-May-23</td>\n",
       "      <td>Anonymous Interview Candidate in Zürich</td>\n",
       "      <td>Declined Offer</td>\n",
       "      <td>Neutral Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google (Zürich)</td>\n",
       "      <td>It wa s avery smooth interviw . I really liked...</td>\n",
       "      <td>Be the first to find this interview helpful\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>How would you optimize a database query? How w...</td>\n",
       "      <td>18-May-23</td>\n",
       "      <td>Anonymous Interview Candidate</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>I interviewed at Google</td>\n",
       "      <td>They asked me about my technical skills and st...</td>\n",
       "      <td>2 people found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>predict some metrics using regression</td>\n",
       "      <td>4-May-23</td>\n",
       "      <td>Anonymous Interview Candidate in Mountain View...</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google (Mountain View, CA)</td>\n",
       "      <td>brainstorm some statistics question with the i...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>How would you forecast a brands sales.</td>\n",
       "      <td>2-May-23</td>\n",
       "      <td>Anonymous Interview Candidate in London, England</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>Neutral Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google (London, England)</td>\n",
       "      <td>Few relatively simple technical questions. Ver...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>I signed an NDA cannot disclose those</td>\n",
       "      <td>27-Mar-23</td>\n",
       "      <td>Anonymous Employee</td>\n",
       "      <td>Accepted Offer</td>\n",
       "      <td>Positive Experience</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>I interviewed at Google</td>\n",
       "      <td>There is s a tech screen and then an onsite. Y...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company                                Interview Questions       Date  \\\n",
       "0  Google                  Why you ? What brough tyou here ?  30-May-23   \n",
       "1  Google  How would you optimize a database query? How w...  18-May-23   \n",
       "2  Google              predict some metrics using regression   4-May-23   \n",
       "3  Google             How would you forecast a brands sales.   2-May-23   \n",
       "4  Google              I signed an NDA cannot disclose those  27-Mar-23   \n",
       "\n",
       "                                           Candidate          Offer?  \\\n",
       "0            Anonymous Interview Candidate in Zürich  Declined Offer   \n",
       "1                      Anonymous Interview Candidate        No Offer   \n",
       "2  Anonymous Interview Candidate in Mountain View...        No Offer   \n",
       "3   Anonymous Interview Candidate in London, England        No Offer   \n",
       "4                                 Anonymous Employee  Accepted Offer   \n",
       "\n",
       "           Experience  Difficulty of Interview  \\\n",
       "0   Neutral Experience     Difficult Interview   \n",
       "1  Positive Experience       Average Interview   \n",
       "2  Positive Experience     Difficult Interview   \n",
       "3   Neutral Experience     Difficult Interview   \n",
       "4  Positive Experience     Difficult Interview   \n",
       "\n",
       "                     How the candidate applied  \\\n",
       "0             I interviewed at Google (Zürich)   \n",
       "1                      I interviewed at Google   \n",
       "2  I interviewed at Google (Mountain View, CA)   \n",
       "3    I interviewed at Google (London, England)   \n",
       "4                      I interviewed at Google   \n",
       "\n",
       "                                             Process  \\\n",
       "0  It wa s avery smooth interviw . I really liked...   \n",
       "1  They asked me about my technical skills and st...   \n",
       "2  brainstorm some statistics question with the i...   \n",
       "3  Few relatively simple technical questions. Ver...   \n",
       "4  There is s a tech screen and then an onsite. Y...   \n",
       "\n",
       "                            Who found review helpful  \n",
       "0  Be the first to find this interview helpful\\nH...  \n",
       "1  2 people found this interview helpful\\nHelpful...  \n",
       "2  1 person found this interview helpful\\nHelpful...  \n",
       "3  1 person found this interview helpful\\nHelpful...  \n",
       "4  1 person found this interview helpful\\nHelpful...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interviews_df_cleaned = interviews_df.copy()\n",
    "interviews_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews_df_cleaned['Interview Questions'] = interviews_df_cleaned['Interview Questions'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26340/3654472535.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  interviews_df_cleaned['Date'] = pd.to_datetime(interviews_df_cleaned['Date'])\n"
     ]
    }
   ],
   "source": [
    "interviews_df_cleaned['Date'] = pd.to_datetime(interviews_df_cleaned['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews_df_cleaned['Offer?'] = interviews_df_cleaned['Offer?'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews_df_cleaned['Experience '] = interviews_df_cleaned['Experience '].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews_df_cleaned['Difficulty of Interview'] = interviews_df_cleaned['Difficulty of Interview'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviews_df_cleaned['Candidate'] = interviews_df_cleaned['Candidate'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Interview Questions</th>\n",
       "      <th>Date</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Offer?</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Difficulty of Interview</th>\n",
       "      <th>How the candidate applied</th>\n",
       "      <th>Process</th>\n",
       "      <th>Who found review helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>brough tyou</td>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>anonymous interview candidate zürich</td>\n",
       "      <td>declined offer</td>\n",
       "      <td>neutral experience</td>\n",
       "      <td>difficult interview</td>\n",
       "      <td>I interviewed at Google (Zürich)</td>\n",
       "      <td>It wa s avery smooth interviw . I really liked...</td>\n",
       "      <td>Be the first to find this interview helpful\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>would optimize database query would evaluate p...</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>anonymous interview candidate</td>\n",
       "      <td>no offer</td>\n",
       "      <td>positive experience</td>\n",
       "      <td>average interview</td>\n",
       "      <td>I interviewed at Google</td>\n",
       "      <td>They asked me about my technical skills and st...</td>\n",
       "      <td>2 people found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>predict metrics using regression</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>anonymous interview candidate mountain view ca</td>\n",
       "      <td>no offer</td>\n",
       "      <td>positive experience</td>\n",
       "      <td>difficult interview</td>\n",
       "      <td>I interviewed at Google (Mountain View, CA)</td>\n",
       "      <td>brainstorm some statistics question with the i...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>would forecast brands sales</td>\n",
       "      <td>2023-05-02</td>\n",
       "      <td>anonymous interview candidate london england</td>\n",
       "      <td>no offer</td>\n",
       "      <td>neutral experience</td>\n",
       "      <td>difficult interview</td>\n",
       "      <td>I interviewed at Google (London, England)</td>\n",
       "      <td>Few relatively simple technical questions. Ver...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>signed nda disclose</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>anonymous employee</td>\n",
       "      <td>accepted offer</td>\n",
       "      <td>positive experience</td>\n",
       "      <td>difficult interview</td>\n",
       "      <td>I interviewed at Google</td>\n",
       "      <td>There is s a tech screen and then an onsite. Y...</td>\n",
       "      <td>1 person found this interview helpful\\nHelpful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company                                Interview Questions       Date  \\\n",
       "0  Google                                        brough tyou 2023-05-30   \n",
       "1  Google  would optimize database query would evaluate p... 2023-05-18   \n",
       "2  Google                   predict metrics using regression 2023-05-04   \n",
       "3  Google                        would forecast brands sales 2023-05-02   \n",
       "4  Google                                signed nda disclose 2023-03-27   \n",
       "\n",
       "                                        Candidate          Offer?  \\\n",
       "0            anonymous interview candidate zürich  declined offer   \n",
       "1                   anonymous interview candidate        no offer   \n",
       "2  anonymous interview candidate mountain view ca        no offer   \n",
       "3    anonymous interview candidate london england        no offer   \n",
       "4                              anonymous employee  accepted offer   \n",
       "\n",
       "           Experience  Difficulty of Interview  \\\n",
       "0   neutral experience     difficult interview   \n",
       "1  positive experience       average interview   \n",
       "2  positive experience     difficult interview   \n",
       "3   neutral experience     difficult interview   \n",
       "4  positive experience     difficult interview   \n",
       "\n",
       "                     How the candidate applied  \\\n",
       "0             I interviewed at Google (Zürich)   \n",
       "1                      I interviewed at Google   \n",
       "2  I interviewed at Google (Mountain View, CA)   \n",
       "3    I interviewed at Google (London, England)   \n",
       "4                      I interviewed at Google   \n",
       "\n",
       "                                             Process  \\\n",
       "0  It wa s avery smooth interviw . I really liked...   \n",
       "1  They asked me about my technical skills and st...   \n",
       "2  brainstorm some statistics question with the i...   \n",
       "3  Few relatively simple technical questions. Ver...   \n",
       "4  There is s a tech screen and then an onsite. Y...   \n",
       "\n",
       "                            Who found review helpful  \n",
       "0  Be the first to find this interview helpful\\nH...  \n",
       "1  2 people found this interview helpful\\nHelpful...  \n",
       "2  1 person found this interview helpful\\nHelpful...  \n",
       "3  1 person found this interview helpful\\nHelpful...  \n",
       "4  1 person found this interview helpful\\nHelpful...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interviews_df_cleaned.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find rate of offers given to candidates per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_cleaned = interviews_df_cleaned[(interviews_df_cleaned['Company'] == 'Meta')]\n",
    "google_df_cleaned = interviews_df_cleaned[(interviews_df_cleaned['Company'] == 'Google')]\n",
    "amazon_df_cleaned = interviews_df_cleaned[(interviews_df_cleaned['Company'] == 'Amazon')]\n",
    "microsoft_df_cleaned = interviews_df_cleaned[(interviews_df_cleaned['Company'] == 'Microsoft')]\n",
    "apple_df_cleaned = interviews_df_cleaned[(interviews_df_cleaned['Company'] == 'Apple')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficulty of Interview\n",
      "average interview      105\n",
      "difficult interview     39\n",
      "easy interview           6\n",
      "Name: count, dtype: int64\n",
      "Difficulty of Interview\n",
      "average interview      66\n",
      "difficult interview    37\n",
      "easy interview          7\n",
      "Name: count, dtype: int64\n",
      "Difficulty of Interview\n",
      "average interview      113\n",
      "difficult interview     29\n",
      "easy interview          18\n",
      "Name: count, dtype: int64\n",
      "Difficulty of Interview\n",
      "average interview      97\n",
      "difficult interview    44\n",
      "easy interview         29\n",
      "Name: count, dtype: int64\n",
      "Difficulty of Interview\n",
      "average interview      23\n",
      "difficult interview    14\n",
      "easy interview          4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(meta_df_cleaned['Difficulty of Interview'].value_counts())\n",
    "print(google_df_cleaned['Difficulty of Interview'].value_counts())\n",
    "print(amazon_df_cleaned['Difficulty of Interview'].value_counts())\n",
    "print(microsoft_df_cleaned['Difficulty of Interview'].value_counts())\n",
    "print(apple_df_cleaned['Difficulty of Interview'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 21.33% of candidates receive job offers for Meta\n",
      "Only 13.64% of candidates receive job offers for Google\n",
      "Only 21.88% of candidates receive job offers for Amazon\n",
      "Only 35.29% of candidates receive job offers for Microsoft\n",
      "Only 24.39% of candidates receive job offers for Apple\n"
     ]
    }
   ],
   "source": [
    "company_cleaned_df = [meta_df_cleaned, google_df_cleaned, amazon_df_cleaned, microsoft_df_cleaned, apple_df_cleaned]\n",
    "name_cleaned_df = ['Meta', 'Google', 'Amazon', 'Microsoft', 'Apple']\n",
    "for company, name in zip(company_cleaned_df, name_cleaned_df):\n",
    "    company_offer_percentage = ((company['Offer?'].value_counts()[1] + company['Offer?'].value_counts()[2]) / (company['Offer?'].value_counts()[0] + company['Offer?'].value_counts()[1] + company['Offer?'].value_counts()[2]) ) * 100\n",
    "    print( f'Only {round(company_offer_percentage, 2)}% of candidates receive job offers for {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0% of candidates describe the interview process as difficult for Meta\n",
      "33.64% of candidates describe the interview process as difficult for Google\n",
      "18.12% of candidates describe the interview process as difficult for Amazon\n",
      "25.88% of candidates describe the interview process as difficult for Microsoft\n",
      "34.15% of candidates describe the interview process as difficult for Apple\n"
     ]
    }
   ],
   "source": [
    "for company, name in zip(company_cleaned_df, name_cleaned_df):\n",
    "    company_difficulty = (company['Difficulty of Interview'].value_counts()[1] / (company['Difficulty of Interview'].value_counts()[0] + company['Difficulty of Interview'].value_counts()[1] + company['Difficulty of Interview'].value_counts()[2])) * 100\n",
    "    print( f'{round(company_difficulty, 2)}% of candidates describe the interview process as difficult for {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0% of candidates describe the interview process as average for Meta\n",
      "60.0% of candidates describe the interview process as average for Google\n",
      "70.62% of candidates describe the interview process as average for Amazon\n",
      "57.06% of candidates describe the interview process as average for Microsoft\n",
      "56.1% of candidates describe the interview process as average for Apple\n"
     ]
    }
   ],
   "source": [
    "for company, name in zip(company_cleaned_df, name_cleaned_df):\n",
    "    company_difficulty = (company['Difficulty of Interview'].value_counts()[0] / (company['Difficulty of Interview'].value_counts()[0] + company['Difficulty of Interview'].value_counts()[1] + company['Difficulty of Interview'].value_counts()[2])) * 100\n",
    "    print( f'{round(company_difficulty, 2)}% of candidates describe the interview process as average for {name}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of interview questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_questions_df = interviews_df_cleaned[['Company', 'Interview Questions']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Interview Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>brough tyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>would optimize database query would evaluate p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>predict metrics using regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>would forecast brands sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>signed nda disclose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Meta</td>\n",
       "      <td>many orders fries mcdonalds sell year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Meta</td>\n",
       "      <td>perform sql join ab test case study resume dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Meta</td>\n",
       "      <td>given list search consecutive n numbers whose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Meta</td>\n",
       "      <td>whats favorite fb product improve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>Meta</td>\n",
       "      <td>given table sql would join count distinct etc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>631 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company                                Interview Questions\n",
       "0    Google                                        brough tyou\n",
       "1    Google  would optimize database query would evaluate p...\n",
       "2    Google                   predict metrics using regression\n",
       "3    Google                        would forecast brands sales\n",
       "4    Google                                signed nda disclose\n",
       "..      ...                                                ...\n",
       "626    Meta              many orders fries mcdonalds sell year\n",
       "627    Meta  perform sql join ab test case study resume dee...\n",
       "628    Meta  given list search consecutive n numbers whose ...\n",
       "629    Meta                  whats favorite fb product improve\n",
       "630    Meta      given table sql would join count distinct etc\n",
       "\n",
       "[631 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(3,3), min_df=0.001, max_df = 0.75)\n",
    "vectorized_questions = pd.DataFrame(vectorizer.fit_transform(interview_questions_df['Interview Questions']).toarray(), columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "vectorized_questions.loc['Total'] = vectorized_questions.sum(numeric_only=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_questions = vectorized_questions.sort_values(vectorized_questions.last_valid_index(), axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word_list = [(col, vectorized_questions[col].iloc[-1]) for col in vectorized_questions.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machine learning questions', 2.265013675431684),\n",
       " ('tell time questions', 2.225727140435356),\n",
       " ('would measure success', 2.0771499818669072),\n",
       " ('technical questions asked', 2.0),\n",
       " ('question overfitting underfitting', 2.0),\n",
       " ('experience data science', 1.9168559038175053),\n",
       " ('statistics machine learning', 1.736092908904114),\n",
       " ('questions data science', 1.633338509046447),\n",
       " ('measure success product', 1.4721858178082279),\n",
       " ('standard error mean', 1.467252189122276),\n",
       " ('prior experience data', 1.4466010737333335),\n",
       " ('probability statistics programming', 1.414213562373095),\n",
       " ('recommendation system design', 1.414213562373095),\n",
       " ('matrix leet code', 1.414213562373095),\n",
       " ('spiral within grid', 1.414213562373095),\n",
       " ('coding talk modelsdata', 1.414213562373095),\n",
       " ('much coding talk', 1.414213562373095),\n",
       " ('code spiral within', 1.414213562373095),\n",
       " ('tell time lead', 1.414213562373095),\n",
       " ('spiral matrix leet', 1.414213562373095),\n",
       " ('anomalies find patterns', 1.414213562373095),\n",
       " ('basic probability statistics', 1.414213562373095),\n",
       " ('time lead team', 1.414213562373095),\n",
       " ('system design improvement', 1.414213562373095),\n",
       " ('find patterns came', 1.414213562373095),\n",
       " ('explain one project', 1.3698062093051582),\n",
       " ('determine best friends', 1.3347790258794536),\n",
       " ('machine learning models', 1.2620813399947703),\n",
       " ('difference bagging boosting', 1.2181146922442487),\n",
       " ('machine learning model', 1.1827817855368536),\n",
       " ('examples deal conflicts', 1.1547005383792515),\n",
       " ('difficulties faced model', 1.1547005383792515),\n",
       " ('pipeline obtaining data', 1.1547005383792515),\n",
       " ('experiences interest data', 1.1547005383792515),\n",
       " ('interest data science', 1.1547005383792515),\n",
       " ('coding question mcq', 1.1547005383792515),\n",
       " ('faced model lot', 1.1547005383792515),\n",
       " ('compose pipeline obtaining', 1.1547005383792515),\n",
       " ('around trees bagging', 1.1547005383792515),\n",
       " ('mcq machine learning', 1.1547005383792515),\n",
       " ('structures algorithms abbastanza', 1.1547005383792515),\n",
       " ('algorithms abbastanza difficili', 1.1547005383792515),\n",
       " ('question examples deal', 1.1547005383792515),\n",
       " ('data structures algorithms', 1.1547005383792515),\n",
       " ('deal conflicts manager', 1.1547005383792515),\n",
       " ('obtaining data vm', 1.1547005383792515),\n",
       " ('trees bagging boosting', 1.1547005383792515),\n",
       " ('describe experiences interest', 1.1547005383792515),\n",
       " ('question mcq machine', 1.1547005383792515),\n",
       " ('questions around trees', 1.1547005383792515),\n",
       " ('model lot layers', 1.1547005383792515),\n",
       " ('bias variance tradeoff', 1.140292015422854),\n",
       " ('sql machine learning', 1.030531626725209),\n",
       " ('design ab testing', 1.0196821305320327),\n",
       " ('general questions data', 1.0112562773092222),\n",
       " ('data science case', 1.0112562773092222),\n",
       " ('science case studies', 1.0112562773092222),\n",
       " ('asked mainly projects', 1.0023644210024325),\n",
       " ('write sql query', 1.000277136284319),\n",
       " ('know machine learning', 1.0),\n",
       " ('please webcam device', 1.0),\n",
       " ('improve model performance', 1.0),\n",
       " ('basic statistical questions', 1.0),\n",
       " ('describe pca works', 1.0),\n",
       " ('data scientist core', 1.0),\n",
       " ('long ago remember', 1.0),\n",
       " ('know norm norm', 1.0),\n",
       " ('know good fit', 1.0),\n",
       " ('questions fp tp', 1.0),\n",
       " ('basic ml questions', 1.0),\n",
       " ('firstround check cv', 1.0),\n",
       " ('model performance one', 1.0),\n",
       " ('im allowed share', 1.0),\n",
       " ('scientist core questions', 1.0),\n",
       " ('tell technical background', 1.0),\n",
       " ('fp tp fn', 1.0),\n",
       " ('asked usual questions', 1.0),\n",
       " ('asked projects resume', 1.0),\n",
       " ('asked phd research', 1.0),\n",
       " ('solve coding problems', 1.0),\n",
       " ('ask randomforest lasso', 1.0),\n",
       " ('want join fb', 1.0),\n",
       " ('want go meta', 1.0),\n",
       " ('question based resume', 1.0),\n",
       " ('performance one resume', 1.0),\n",
       " ('tell know displays', 1.0),\n",
       " ('talked ml techniques', 1.0),\n",
       " ('challenging questions fp', 1.0),\n",
       " ('choose use neural', 1.0),\n",
       " ('core questions related', 1.0),\n",
       " ('questions tables show', 1.0),\n",
       " ('convolution matrixmatrix multiplication', 1.0),\n",
       " ('tell answer questions', 1.0),\n",
       " ('work domain knowledge', 1.0),\n",
       " ('na na na', 1.0),\n",
       " ('questions related feild', 1.0),\n",
       " ('latest invention think', 1.0),\n",
       " ('value avoid overfitting', 1.0),\n",
       " ('value chase study', 1.0),\n",
       " ('questions mainly project', 1.0),\n",
       " ('distribute coupon people', 1.0),\n",
       " ('project work domain', 1.0),\n",
       " ('window function group', 1.0),\n",
       " ('difference boosting bagging', 1.0),\n",
       " ('everything sun moon', 1.0),\n",
       " ('neural network versus', 1.0),\n",
       " ('projects worked phd', 1.0),\n",
       " ('prefer google apple', 1.0),\n",
       " ('introduce question probality', 1.0),\n",
       " ('explain sql works', 1.0),\n",
       " ('describe project proud', 1.0),\n",
       " ('linear regression assumptions', 1.0),\n",
       " ('responsible future job', 1.0),\n",
       " ('calculate sample size', 1.0),\n",
       " ('previous experience field', 1.0),\n",
       " ('use neural network', 1.0),\n",
       " ('network versus svm', 1.0),\n",
       " ('strength relates analysis', 1.0),\n",
       " ('standard behavioral questions', 1.0),\n",
       " ('tell current responsibilities', 1.0),\n",
       " ('question sorting array', 1.0),\n",
       " ('visualize multidimensional data', 1.0),\n",
       " ('mainly project work', 1.0),\n",
       " ('quants logical reasoning', 1.0),\n",
       " ('notification rate drops', 1.0),\n",
       " ('write code xyz', 1.0),\n",
       " ('maximum product subarray', 1.0),\n",
       " ('analyze network facebook', 1.0),\n",
       " ('many behavior questions', 1.0),\n",
       " ('algorithmic questions ask', 1.0),\n",
       " ('tp fn tn', 1.0),\n",
       " ('signed nda disclose', 1.0),\n",
       " ('tell time failed', 1.0),\n",
       " ('write sql python', 1.0),\n",
       " ('amazon basics engineering', 1.0),\n",
       " ('anything want ask', 1.0),\n",
       " ('one resume project', 1.0),\n",
       " ('data science questions', 0.9789016833406373),\n",
       " ('data science project', 0.9789016833406373),\n",
       " ('python machine learning', 0.9539689361852194),\n",
       " ('explain bias variance', 0.9414152291109155),\n",
       " ('sql python questions', 0.9207583805235542),\n",
       " ('learning model best', 0.9024543293001791),\n",
       " ('model best performance', 0.9024543293001791),\n",
       " ('build machine learning', 0.9024543293001791),\n",
       " ('best performance achieve', 0.9024543293001791),\n",
       " ('product sense questions', 0.9023389928006478),\n",
       " ('nontechnical person team', 0.8944271909999159),\n",
       " ('pvalue nontechnical person', 0.8944271909999159),\n",
       " ('explain pvalue nontechnical', 0.8944271909999159),\n",
       " ('text manipualtion sql', 0.8944271909999159),\n",
       " ('coding focused search', 0.8944271909999159),\n",
       " ('python coding focused', 0.8944271909999159),\n",
       " ('would explain pvalue', 0.8944271909999159),\n",
       " ('focused search text', 0.8944271909999159),\n",
       " ('pvalue would explain', 0.8944271909999159),\n",
       " ('search text manipualtion', 0.8944271909999159),\n",
       " ('blah blah blah', 0.8571428571428572),\n",
       " ('multiple choice questions', 0.8528028654224417),\n",
       " ('questions multiple choice', 0.8528028654224417),\n",
       " ('coding machine learning', 0.8472225951171719),\n",
       " ('sql coding machine', 0.8472225951171719),\n",
       " ('facebook user groups', 0.818937566586456),\n",
       " ('user groups gone', 0.818937566586456),\n",
       " ('designing system bing', 0.816496580927726),\n",
       " ('system bing image', 0.816496580927726),\n",
       " ('asked approach designing', 0.816496580927726),\n",
       " ('bing image search', 0.816496580927726),\n",
       " ('approach designing system', 0.816496580927726),\n",
       " ('interviewer asked approach', 0.816496580927726),\n",
       " ('make unfair coin', 0.8012727345792768),\n",
       " ('error linear regression', 0.8012727345792768),\n",
       " ('assumption error linear', 0.8012727345792768),\n",
       " ('unfair coin fair', 0.8012727345792768),\n",
       " ('write code generate', 0.7652966928517877),\n",
       " ('test review resume', 0.7607561675105083),\n",
       " ('hypothesis test review', 0.7607561675105083),\n",
       " ('review resume machine', 0.7607561675105083),\n",
       " ('learning models boosting', 0.7607561675105083),\n",
       " ('resume machine learning', 0.7607561675105083),\n",
       " ('models boosting bagging', 0.7607561675105083),\n",
       " ('questions involved statistics', 0.7559289460184545),\n",
       " ('involved statistics probability', 0.7559289460184545),\n",
       " ('probability data science', 0.7559289460184545),\n",
       " ('science design questions', 0.7559289460184545),\n",
       " ('data science design', 0.7559289460184545),\n",
       " ('leetcode questions involved', 0.7559289460184545),\n",
       " ('statistics probability data', 0.7559289460184545),\n",
       " ('one sql question', 0.7496600245734164),\n",
       " ('data science probability', 0.7442560038543093),\n",
       " ('questions machine learning', 0.7428158410578916),\n",
       " ('one project delivered', 0.7286341587087846),\n",
       " ('experiment design ab', 0.7286341587087846),\n",
       " ('sql query find', 0.7286341587087846),\n",
       " ('one project cv', 0.7286341587087846),\n",
       " ('mainly projects resume', 0.7286341587087846),\n",
       " ('mainly sql python', 0.7286341587087846),\n",
       " ('signed nda cant', 0.7083229928081545),\n",
       " ('find spam request', 0.7071067811865476),\n",
       " ('specially internship experiences', 0.7071067811865476),\n",
       " ('find percentile write', 0.7071067811865476),\n",
       " ('basic questions domain', 0.7071067811865476),\n",
       " ('basic questions etc', 0.7071067811865476),\n",
       " ('sql product quetions', 0.7071067811865476),\n",
       " ('would conduct ab', 0.7071067811865476),\n",
       " ('study demand forecasting', 0.7071067811865476),\n",
       " ('describe previous experience', 0.7071067811865476),\n",
       " ('experience work team', 0.7071067811865476),\n",
       " ('write sql queries', 0.7071067811865476),\n",
       " ('describe pervious experience', 0.7071067811865476),\n",
       " ('time deliver result', 0.7071067811865476),\n",
       " ('case study demand', 0.7071067811865476),\n",
       " ('difference linear regression', 0.7071067811865476),\n",
       " ('spam request friends', 0.7071067811865476),\n",
       " ('interpret coefficient logistics', 0.7071067811865476),\n",
       " ('basic ml knowledge', 0.7071067811865476),\n",
       " ('pervious experience employers', 0.7071067811865476),\n",
       " ('detailed questions ab', 0.7071067811865476),\n",
       " ('interest show interest', 0.7071067811865476),\n",
       " ('relevant experience role', 0.7071067811865476),\n",
       " ('question set cover', 0.7071067811865476),\n",
       " ('tell given coin', 0.7071067811865476),\n",
       " ('presentation easy questions', 0.7071067811865476),\n",
       " ('explain prior project', 0.7071067811865476),\n",
       " ('tell past project', 0.7071067811865476),\n",
       " ('inspect missing data', 0.7071067811865476),\n",
       " ('sql basic questions', 0.7071067811865476),\n",
       " ('sql case question', 0.7071067811865476),\n",
       " ('resume job posting', 0.7071067811865476),\n",
       " ('binary search question', 0.7071067811865476),\n",
       " ('pvalue tell past', 0.7071067811865476),\n",
       " ('would forecast brands', 0.7071067811865476),\n",
       " ('design optimize elevator', 0.7071067811865476),\n",
       " ('questions probability statistics', 0.7071067811865476),\n",
       " ('current role looking', 0.7071067811865476),\n",
       " ('linear regression ttest', 0.7071067811865476),\n",
       " ('facebook timeline features', 0.7071067811865476),\n",
       " ('round dsa round', 0.7071067811865476),\n",
       " ('linear regression etc', 0.7071067811865476),\n",
       " ('one obstacles acedamic', 0.7071067811865476),\n",
       " ('describe relevant experience', 0.7071067811865476),\n",
       " ('specific problems meet', 0.7071067811865476),\n",
       " ('detail cnn works', 0.7071067811865476),\n",
       " ('describe process data', 0.7071067811865476),\n",
       " ('one data leetcode', 0.7071067811865476),\n",
       " ('replace empty cells', 0.7071067811865476),\n",
       " ('wrote highlevel question', 0.7071067811865476),\n",
       " ('explain detail cnn', 0.7071067811865476),\n",
       " ('items resume job', 0.7071067811865476),\n",
       " ('questions ab test', 0.7071067811865476),\n",
       " ('prove probability integral', 0.7071067811865476),\n",
       " ('please describe previous', 0.7071067811865476),\n",
       " ('explain support vector', 0.7071067811865476),\n",
       " ('data manipulation coding', 0.7071067811865476),\n",
       " ('calculate median python', 0.7071067811865476),\n",
       " ('sql productexperimental deign', 0.7071067811865476),\n",
       " ('data leetcode ml', 0.7071067811865476),\n",
       " ('use mean vs', 0.7071067811865476),\n",
       " ('predict metrics using', 0.7071067811865476),\n",
       " ('find width confidence', 0.7071067811865476),\n",
       " ('solve algorithms python', 0.7071067811865476),\n",
       " ('code hash table', 0.7071067811865476),\n",
       " ('distance data point', 0.7071067811865476),\n",
       " ('problems meet project', 0.7071067811865476),\n",
       " ('skills sql scale', 0.7071067811865476),\n",
       " ('describe current role', 0.7071067811865476),\n",
       " ('optimize elevator question', 0.7071067811865476),\n",
       " ('problems deadline environment', 0.7071067811865476),\n",
       " ('code calculate median', 0.7071067811865476),\n",
       " ('conduct ab test', 0.7071067811865476),\n",
       " ('empty cells median', 0.7071067811865476),\n",
       " ('metrics use evaluate', 0.7071067811865476),\n",
       " ('describe experience work', 0.7071067811865476),\n",
       " ('asked invert binary', 0.7071067811865476),\n",
       " ('daus newsfeed would', 0.7071067811865476),\n",
       " ('questions including code', 0.7071067811865476),\n",
       " ('solve global warming', 0.7071067811865476),\n",
       " ('team remote operations', 0.7071067811865476),\n",
       " ('metrics using regression', 0.7071067811865476),\n",
       " ('asked question set', 0.7071067811865476),\n",
       " ('tell time agree', 0.7071067811865476),\n",
       " ('would solve global', 0.7071067811865476),\n",
       " ('productexperimental deign questions', 0.7071067811865476),\n",
       " ('process data analysis', 0.7071067811865476),\n",
       " ('tell basic ml', 0.7071067811865476),\n",
       " ('coefficient logistics regression', 0.7071067811865476),\n",
       " ('coding simulation setup', 0.7071067811865476),\n",
       " ('see within next', 0.7071067811865476),\n",
       " ('manipulation coding test', 0.7071067811865476),\n",
       " ('define meaningful social', 0.7071067811865476),\n",
       " ('tell time deliver', 0.7071067811865476),\n",
       " ('key interest show', 0.7071067811865476),\n",
       " ('two sql case', 0.7071067811865476),\n",
       " ('missing data important', 0.7071067811865476),\n",
       " ('approach problems deadline', 0.7071067811865476),\n",
       " ('support vector machine', 0.7071067811865476),\n",
       " ('easy questions dnn', 0.7071067811865476),\n",
       " ('within next years', 0.7071067811865476),\n",
       " ('tell background ideal', 0.7071067811865476),\n",
       " ('would summarize twitter', 0.7071067811865476),\n",
       " ('summarize twitter feed', 0.7071067811865476),\n",
       " ('coding challenge project', 0.7071067811865476),\n",
       " ('describe background interested', 0.7071067811865476),\n",
       " ('complex binary search', 0.7071067811865476),\n",
       " ('basic coding simulation', 0.7071067811865476),\n",
       " ('something challenging working', 0.7071067811865476),\n",
       " ('tell something challenging', 0.7071067811865476),\n",
       " ('describe past projects', 0.7071067811865476),\n",
       " ('self previous experience', 0.7071067811865476),\n",
       " ('notifications prior launch', 0.7071067811865476),\n",
       " ('background ideal role', 0.7071067811865476),\n",
       " ('background interested role', 0.7071067811865476),\n",
       " ('challenge project work', 0.7071067811865476),\n",
       " ('background specially internship', 0.7071067811865476),\n",
       " ('questions domain knowledge', 0.7071067811865476),\n",
       " ('invert binary tree', 0.7071067811865476),\n",
       " ('use evaluate model', 0.7071067811865476),\n",
       " ('given coin biased', 0.7071067811865476),\n",
       " ('lead team remote', 0.7071067811865476),\n",
       " ('newsfeed would investigate', 0.7071067811865476),\n",
       " ('mean vs median', 0.7071067811865476),\n",
       " ('sql queries demand', 0.7071067811865476),\n",
       " ('meaningful social interaction', 0.7071067811865476),\n",
       " ('measure distance data', 0.7071067811865476),\n",
       " ('regarding facebook timeline', 0.7071067811865476),\n",
       " ('first round dsa', 0.7071067811865476),\n",
       " ('priorities engaged multitasking', 0.7071067811865476),\n",
       " ('prior project worked', 0.7071067811865476),\n",
       " ('lot sql product', 0.7071067811865476),\n",
       " ('many questions probability', 0.7071067811865476),\n",
       " ('assumption linear regression', 0.7071067811865476),\n",
       " ('past projects worked', 0.7071067811865476),\n",
       " ('time agree advisor', 0.7071067811865476),\n",
       " ('introduce self previous', 0.7071067811865476),\n",
       " ('obstacles acedamic experience', 0.7071067811865476),\n",
       " ('sort priorities engaged', 0.7071067811865476),\n",
       " ('width confidence interval', 0.7071067811865476),\n",
       " ('forecast brands sales', 0.7071067811865476),\n",
       " ('rate skills sql', 0.7071067811865476),\n",
       " ('open questions including', 0.7071067811865476),\n",
       " ('hash table python', 0.7071067811865476),\n",
       " ('probability integral transform', 0.7071067811865476),\n",
       " ('evaluate notifications prior', 0.7071067811865476),\n",
       " ('highlevel question areas', 0.7071067811865476),\n",
       " ('percentile write code', 0.7071067811865476),\n",
       " ('asked solve algorithms', 0.7071067811865476),\n",
       " ('including recommender systems', 0.7071067811865475),\n",
       " ('thing asked interview', 0.7071067811865475),\n",
       " ('interview experience nlp', 0.7071067811865475),\n",
       " ('mechanisms including recommender', 0.7071067811865475),\n",
       " ('asked interview experience', 0.7071067811865475),\n",
       " ('experience nlp mechanisms', 0.7071067811865475),\n",
       " ('one thing asked', 0.7071067811865475),\n",
       " ('nlp mechanisms including', 0.7071067811865475),\n",
       " ('explain probability distribution', 0.6715162225823551),\n",
       " ('would consider mean', 0.6715162225823551),\n",
       " ('distribution normal apply', 0.6715162225823551),\n",
       " ('consider mean median', 0.6715162225823551),\n",
       " ('probability distribution normal', 0.6715162225823551),\n",
       " ('situation would consider', 0.6715162225823551),\n",
       " ('characters judge characters', 0.6666666666666667),\n",
       " ('models model supported', 0.6666666666666667),\n",
       " ('model supported azure', 0.6666666666666667),\n",
       " ('characters could split', 0.6666666666666667),\n",
       " ('azure analysis services', 0.6666666666666667),\n",
       " ('sets graph barpartite', 0.6666666666666667),\n",
       " ('difference multidimensional tabular', 0.6666666666666667),\n",
       " ('could split two', 0.6666666666666667),\n",
       " ('split two sets', 0.6666666666666667),\n",
       " ('pairs characters judge', 0.6666666666666667),\n",
       " ('tabular models model', 0.6666666666666667),\n",
       " ('judge characters could', 0.6666666666666667),\n",
       " ('explain key difference', 0.6666666666666667),\n",
       " ('supported azure analysis', 0.6666666666666667),\n",
       " ('key difference multidimensional', 0.6666666666666667),\n",
       " ('multidimensional tabular models', 0.6666666666666667),\n",
       " ('two sets graph', 0.6666666666666667),\n",
       " ('given pairs characters', 0.6666666666666667),\n",
       " ('would measure health', 0.6659900688035141),\n",
       " ('tell time used', 0.6537630993317411),\n",
       " ('time used data', 0.6537630993317411),\n",
       " ('question coding question', 0.6146775625931751),\n",
       " ('probability question coding', 0.6146775625931751),\n",
       " ('algorithm would use', 0.6143682320318306),\n",
       " ('questions coding questions', 0.6033372648200431),\n",
       " ('basic stats machine', 0.6033372648200431),\n",
       " ('stats machine learning', 0.6033372648200431),\n",
       " ('learning questions coding', 0.6033372648200431),\n",
       " ('encontrado con un', 0.6030226891555273),\n",
       " ('un problema de', 0.6030226891555273),\n",
       " ('te encontrado con', 0.6030226891555273),\n",
       " ('en ambiente laboral', 0.6030226891555273),\n",
       " ('problema de inclusión', 0.6030226891555273),\n",
       " ('de inclusión social', 0.6030226891555273),\n",
       " ('con un problema', 0.6030226891555273),\n",
       " ('social en ambiente', 0.6030226891555273),\n",
       " ('inclusión social en', 0.6030226891555273),\n",
       " ('ambiente laboral explicación', 0.6030226891555273),\n",
       " ('laboral explicación solución', 0.6030226891555273),\n",
       " ('many years experience', 0.5970468864645908),\n",
       " ('probability explain machine', 0.5970468864645908),\n",
       " ('explain machine learning', 0.5970468864645908),\n",
       " ('years experience data', 0.5970468864645908),\n",
       " ('given sql table', 0.5966585582367605),\n",
       " ('normal distribution plot', 0.591836956092209),\n",
       " ('science project detail', 0.5888911372952459),\n",
       " ('statistics programming sql', 0.5888911372952459),\n",
       " ('programming sql machine', 0.5888911372952459),\n",
       " ('measure health news', 0.5888911372952459),\n",
       " ('ml data science', 0.5888911372952459),\n",
       " ('basic ml data', 0.5888911372952459),\n",
       " ('describe data science', 0.5888911372952459),\n",
       " ('cant disclose unfortunately', 0.5888911372952459),\n",
       " ('nda cant disclose', 0.5888911372952459),\n",
       " ('health news feed', 0.5888911372952459),\n",
       " ('could ab test', 0.5861279709976156),\n",
       " ('test see increase', 0.5861279709976156),\n",
       " ('ab test see', 0.5861279709976156),\n",
       " ('complicated sql questions', 0.5773502691896258),\n",
       " ('random forest model', 0.5773502691896258),\n",
       " ('machine learning past', 0.5773502691896258),\n",
       " ('ask answer data', 0.5773502691896258),\n",
       " ('python java based', 0.5773502691896258),\n",
       " ('would situation directly', 0.5773502691896258),\n",
       " ('function checks word', 0.5773502691896258),\n",
       " ('panel data crosssectional', 0.5773502691896258),\n",
       " ('professional experience move', 0.5773502691896258),\n",
       " ('standard stats behavior', 0.5773502691896258),\n",
       " ('months california trained', 0.5773502691896258),\n",
       " ('data crosssectional data', 0.5773502691896258),\n",
       " ('detect virus inappropriate', 0.5773502691896258),\n",
       " ('asked two three', 0.5773502691896258),\n",
       " ('favorite fb product', 0.5773502691896258),\n",
       " ('question case study', 0.5773502691896258),\n",
       " ('problem fake friend', 0.5773502691896258),\n",
       " ('situation directly relevant', 0.5773502691896258),\n",
       " ('willing spend months', 0.5773502691896258),\n",
       " ('identify close friends', 0.5773502691896258),\n",
       " ('friends social media', 0.5773502691896258),\n",
       " ('fake friend requests', 0.5773502691896258),\n",
       " ('virus inappropriate content', 0.5773502691896258),\n",
       " ('directly relevant principle', 0.5773502691896258),\n",
       " ('technical question using', 0.5773502691896258),\n",
       " ('close friends social', 0.5773502691896258),\n",
       " ('worked made difference', 0.5773502691896258),\n",
       " ('describe difference knn', 0.5773502691896258),\n",
       " ('name expectations phone', 0.5773502691896258),\n",
       " ('questions visa status', 0.5773502691896258),\n",
       " ('builds ads model', 0.5773502691896258),\n",
       " ('sql questions solve', 0.5773502691896258),\n",
       " ('modeling data python', 0.5773502691896258),\n",
       " ('model basic algorithms', 0.5773502691896258),\n",
       " ('testing python coding', 0.5773502691896258),\n",
       " ('approach highdimensional dataset', 0.5773502691896258),\n",
       " ('python stepp step', 0.5773502691896258),\n",
       " ('coding questions rejection', 0.5773502691896258),\n",
       " ('learning model customers', 0.5773502691896258),\n",
       " ('using probability theory', 0.5773502691896258),\n",
       " ('resume questions visa', 0.5773502691896258),\n",
       " ('applied quantitative problem', 0.5773502691896258),\n",
       " ('questions rejection sampling', 0.5773502691896258),\n",
       " ('situations provided best', 0.5773502691896258),\n",
       " ('stats questions theory', 0.5773502691896258),\n",
       " ('coding sum squares', 0.5773502691896258),\n",
       " ('question using probability', 0.5773502691896258),\n",
       " ('reverse linked list', 0.5773502691896258),\n",
       " ('multiple tasks given', 0.5773502691896258),\n",
       " ('using python pandas', 0.5773502691896258),\n",
       " ('learning past projects', 0.5773502691896258),\n",
       " ('would yhou approach', 0.5773502691896258),\n",
       " ('would estimate metrics', 0.5773502691896258),\n",
       " ('statistics statistical sampling', 0.5773502691896258),\n",
       " ('approach reverse linked', 0.5773502691896258),\n",
       " ('think facebook would', 0.5773502691896258),\n",
       " ('stats behavior product', 0.5773502691896258),\n",
       " ('facebook would create', 0.5773502691896258),\n",
       " ('questions theory relevant', 0.5773502691896258),\n",
       " ('sql basic lp', 0.5773502691896258),\n",
       " ('two three business', 0.5773502691896258),\n",
       " ('sql related medium', 0.5773502691896258),\n",
       " ('resume many case', 0.5773502691896258),\n",
       " ('around basic ml', 0.5773502691896258),\n",
       " ('educational background applied', 0.5773502691896258),\n",
       " ('ab test experiment', 0.5773502691896258),\n",
       " ('whats favorite fb', 0.5773502691896258),\n",
       " ('medium level questions', 0.5773502691896258),\n",
       " ('validation tool facebook', 0.5773502691896258),\n",
       " ('three business cases', 0.5773502691896258),\n",
       " ('questions solve immediately', 0.5773502691896258),\n",
       " ('tell approach reverse', 0.5773502691896258),\n",
       " ('technical coding questions', 0.5773502691896258),\n",
       " ('eazy sql question', 0.5773502691896258),\n",
       " ('would problem fake', 0.5773502691896258),\n",
       " ('manipulation using python', 0.5773502691896258),\n",
       " ('metrics ab test', 0.5773502691896258),\n",
       " ('go resume many', 0.5773502691896258),\n",
       " ('time diffferent opinion', 0.5773502691896258),\n",
       " ('basic statistics statistical', 0.5773502691896258),\n",
       " ('measure impact business', 0.5773502691896258),\n",
       " ('related medium level', 0.5773502691896258),\n",
       " ('written behaviour technical', 0.5773502691896258),\n",
       " ('basic resume questions', 0.5773502691896258),\n",
       " ('experience move interview', 0.5773502691896258),\n",
       " ('manage multiple tasks', 0.5773502691896258),\n",
       " ('basic question coding', 0.5773502691896258),\n",
       " ('expectations phone number', 0.5773502691896258),\n",
       " ('spend months california', 0.5773502691896258),\n",
       " ('hypothesis testing python', 0.5773502691896258),\n",
       " ('basic ml concepts', 0.5773502691896258),\n",
       " ('difference type type', 0.5773502691896258),\n",
       " ('basic lp solutions', 0.5773502691896258),\n",
       " ('youtube videos interview', 0.5773502691896258),\n",
       " ('case study related', 0.5773502691896258),\n",
       " ('data manipulation using', 0.5773502691896258),\n",
       " ('basics machine learning', 0.5773502691896258),\n",
       " ('data structure question', 0.5773502691896258),\n",
       " ('study related probability', 0.5773502691896258),\n",
       " ('explain difference type', 0.5773502691896258),\n",
       " ('describe time diffferent', 0.5773502691896258),\n",
       " ('would create product', 0.5773502691896258),\n",
       " ('deep learning model', 0.5773502691896258),\n",
       " ('questions around basic', 0.5773502691896258),\n",
       " ('explain deep learning', 0.5773502691896258),\n",
       " ('describe project worked', 0.5773502691896258),\n",
       " ('create function checks', 0.5773502691896258),\n",
       " ('create validation tool', 0.5773502691896258),\n",
       " ('principal component analysis', 0.5773502691896258),\n",
       " ('data python stepp', 0.5773502691896258),\n",
       " ('inappropriate content youtube', 0.5773502691896258),\n",
       " ('behavior product sense', 0.5773502691896258),\n",
       " ('phone number address', 0.5773502691896258),\n",
       " ('sample questions provided', 0.5773502691896258),\n",
       " ('difference knn nearest', 0.5773502691896258),\n",
       " ('math behind principal', 0.5773502691896258),\n",
       " ('answer data structure', 0.5773502691896258),\n",
       " ('provided best ways', 0.5773502691896258),\n",
       " ('differences panel data', 0.5773502691896258),\n",
       " ('bq basic statistics', 0.5773502691896258),\n",
       " ('one coding questions', 0.5773502691896258),\n",
       " ('fb product improve', 0.5773502691896258),\n",
       " ('describe manage multiple', 0.5773502691896258),\n",
       " ('knn nearest neighbor', 0.5773502691896258),\n",
       " ('lp solutions assumption', 0.5773502691896258),\n",
       " ('estimate metrics ab', 0.5773502691896258),\n",
       " ('sql question case', 0.5773502691896258),\n",
       " ('checks word palindrome', 0.5773502691896258),\n",
       " ('forest model implementation', 0.5773502691896258),\n",
       " ('nda similar sample', 0.5773502691896258),\n",
       " ('math case study', 0.5773502691896258),\n",
       " ('ads model basic', 0.5773502691896258),\n",
       " ('type type error', 0.5773502691896258),\n",
       " ('best ways solve', 0.5773502691896258),\n",
       " ('question coding sum', 0.5773502691896258),\n",
       " ('diffferent opinion colleagues', 0.5773502691896258),\n",
       " ('videos interview process', 0.5773502691896258),\n",
       " ('design ab test', 0.5773502691896258),\n",
       " ('behind principal component', 0.5773502691896258),\n",
       " ('would design ab', 0.5773502691896258),\n",
       " ('hard stats questions', 0.5773502691896258),\n",
       " ('sql python java', 0.5773502691896258),\n",
       " ('move interview process', 0.5773502691896258),\n",
       " ('similar sample questions', 0.5773502691896258),\n",
       " ('java based programs', 0.5773502691896258),\n",
       " ('similiar youtube videos', 0.5773502691896258),\n",
       " ('many case study', 0.5773502691896258),\n",
       " ('behaviour technical coding', 0.5773502691896258),\n",
       " ('would measure impact', 0.5773502691896258),\n",
       " ('python coding questions', 0.5773502691896258),\n",
       " ('model implementation code', 0.5773502691896258),\n",
       " ('impact business initiative', 0.5773502691896258),\n",
       " ('project worked made', 0.5773502691896258),\n",
       " ('background applied quantitative', 0.5773502691896258),\n",
       " ('tool facebook marketplace', 0.5773502691896258),\n",
       " ('yhou approach highdimensional', 0.5773502691896258),\n",
       " ('project ab testing', 0.5706343017504287),\n",
       " ('system design interview', 0.5547001962252291),\n",
       " ('machine learning algorithms', 0.5534088745111914),\n",
       " ('account cases user', 0.5345224838248488),\n",
       " ('many questions regarding', 0.5345224838248488),\n",
       " ('video call platform', 0.5345224838248488),\n",
       " ('call vice versa', 0.5345224838248488),\n",
       " ('missed call vice', 0.5345224838248488),\n",
       " ('given user calling', 0.5345224838248488),\n",
       " ('call platform would', 0.5345224838248488),\n",
       " ('calling another user', 0.5345224838248488),\n",
       " ('another user video', 0.5345224838248488),\n",
       " ('would account cases', 0.5345224838248488),\n",
       " ('user calling another', 0.5345224838248488),\n",
       " ('cases user missed', 0.5345224838248488),\n",
       " ('user video call', 0.5345224838248488),\n",
       " ('platform would account', 0.5345224838248488),\n",
       " ('user missed call', 0.5345224838248488),\n",
       " ('see increase product', 0.5233737858379888),\n",
       " ('success like emoji', 0.5165952883783771),\n",
       " ('measure success like', 0.5165952883783771),\n",
       " ('like emoji feature', 0.5165952883783771),\n",
       " ('used data influence', 0.5152221546271367),\n",
       " ('data influence decision', 0.5152221546271367),\n",
       " ('behavior sql machine', 0.5074399199900124),\n",
       " ('machine learning excel', 0.5074399199900124),\n",
       " ('sql python machine', 0.5074399199900124),\n",
       " ('sense questions product', 0.5074399199900124),\n",
       " ('sql question one', 0.5074399199900124),\n",
       " ('question one strategy', 0.5074399199900124),\n",
       " ('one strategy question', 0.5074399199900124),\n",
       " ('product team focused', 0.5074399199900124),\n",
       " ('learning stats asked', 0.5074399199900124),\n",
       " ('machine learning stats', 0.5074399199900124),\n",
       " ('technical questions sql', 0.5074399199900124),\n",
       " ('questions python machine', 0.5074399199900124),\n",
       " ('questions product team', 0.5074399199900124),\n",
       " ('learning excel tabelu', 0.5074399199900124),\n",
       " ('questions sql python', 0.5074399199900124),\n",
       " ('para seu futuro', 0.5),\n",
       " ('joining fb would', 0.5),\n",
       " ('orders fries mcdonalds', 0.5),\n",
       " ('data manipulation data', 0.5),\n",
       " ('fb would measure', 0.5),\n",
       " ('mcdonalds sell year', 0.5),\n",
       " ('behavioral questions got', 0.5),\n",
       " ('python stats ml', 0.5),\n",
       " ('measure two people', 0.5),\n",
       " ('analysis opportunity facebook', 0.5),\n",
       " ('supply chain problem', 0.5),\n",
       " ('python standard interview', 0.5),\n",
       " ('write query table', 0.5),\n",
       " ('que você vê', 0.5),\n",
       " ('python sql case', 0.5),\n",
       " ('phone call interview', 0.5),\n",
       " ('data science concepts', 0.5),\n",
       " ('behaviorals sql easy', 0.5),\n",
       " ('data intuition statistics', 0.5),\n",
       " ('materials publicly available', 0.5),\n",
       " ('deep learning one', 0.5),\n",
       " ('explain random forest', 0.5),\n",
       " ('write ttest python', 0.5),\n",
       " ('prep materials publicly', 0.5),\n",
       " ('hyperparameters de xgboost', 0.5),\n",
       " ('predict next reading', 0.5),\n",
       " ('data analysis opportunity', 0.5),\n",
       " ('sql case statement', 0.5),\n",
       " ('string processing treebased', 0.5),\n",
       " ('ridge research papaer', 0.5),\n",
       " ('vê para seu', 0.5),\n",
       " ('faced work handles', 0.5),\n",
       " ('medium leetcode level', 0.5),\n",
       " ('new observation outlier', 0.5),\n",
       " ('apply data analysis', 0.5),\n",
       " ('new product design', 0.5),\n",
       " ('would helpful creation', 0.5),\n",
       " ('sequence integer list', 0.5),\n",
       " ('one technical one', 0.5),\n",
       " ('unsupervised learning algorithms', 0.5),\n",
       " ('query table using', 0.5),\n",
       " ('fries mcdonalds sell', 0.5),\n",
       " ('parents joining fb', 0.5),\n",
       " ('people many friends', 0.5),\n",
       " ('question deep learning', 0.5),\n",
       " ('model new product', 0.5),\n",
       " ('successful would differently', 0.5),\n",
       " ('você vê para', 0.5),\n",
       " ('people close friend', 0.5),\n",
       " ('give model new', 0.5),\n",
       " ('time series sensors', 0.5),\n",
       " ('situation faced work', 0.5),\n",
       " ('forest discuss pros', 0.5),\n",
       " ('observation outlier biasvariance', 0.5),\n",
       " ('helpful creation reactions', 0.5),\n",
       " ('test comes particular', 0.5),\n",
       " ('want give model', 0.5),\n",
       " ('asked experience generally', 0.5),\n",
       " ('asked determine two', 0.5),\n",
       " ('two people close', 0.5),\n",
       " ('asked background want', 0.5),\n",
       " ('question easy medium', 0.5),\n",
       " ('attracts apply data', 0.5),\n",
       " ('similar interview prep', 0.5),\n",
       " ('science concepts regression', 0.5),\n",
       " ('study fb products', 0.5),\n",
       " ('functionalities would helpful', 0.5),\n",
       " ('study real supply', 0.5),\n",
       " ('find maximum sub', 0.5),\n",
       " ('sensors predict next', 0.5),\n",
       " ('tell project worked', 0.5),\n",
       " ('two users best', 0.5),\n",
       " ('sub sequence integer', 0.5),\n",
       " ('based cv experience', 0.5),\n",
       " ('dataset keeping info', 0.5),\n",
       " ('detect new observation', 0.5),\n",
       " ('papaer optimization etc', 0.5),\n",
       " ('one algorithm question', 0.5),\n",
       " ('sense business case', 0.5),\n",
       " ('anything included materials', 0.5),\n",
       " ('describe ml problems', 0.5),\n",
       " ('impact parents joining', 0.5),\n",
       " ('next years life', 0.5),\n",
       " ('one call recruiter', 0.5),\n",
       " ('business case applied', 0.5),\n",
       " ('sql combine two', 0.5),\n",
       " ('interview asked background', 0.5),\n",
       " ('several programming languages', 0.5),\n",
       " ('quick intro coding', 0.5),\n",
       " ('interview prep materials', 0.5),\n",
       " ('using group statement', 0.5),\n",
       " ('random forest discuss', 0.5),\n",
       " ('one product analysis', 0.5),\n",
       " ('variable test comes', 0.5),\n",
       " ('problems work current', 0.5),\n",
       " ('discuss pros cons', 0.5),\n",
       " ('intro coding product', 0.5),\n",
       " ('ml problems work', 0.5),\n",
       " ('disadvantages several programming', 0.5),\n",
       " ('ttest python sql', 0.5),\n",
       " ('concepts regression performancd', 0.5),\n",
       " ('conditional probability case', 0.5),\n",
       " ('sql easy python', 0.5),\n",
       " ('random variable test', 0.5),\n",
       " ('years life far', 0.5),\n",
       " ('les hyperparameters de', 0.5),\n",
       " ('advantages disadvantages several', 0.5),\n",
       " ('worked successful would', 0.5),\n",
       " ('share anything included', 0.5),\n",
       " ('processing treebased modeling', 0.5),\n",
       " ('compared advantages disadvantages', 0.5),\n",
       " ('easy medium leetcode', 0.5),\n",
       " ('work current position', 0.5),\n",
       " ('questions pretty much', 0.5),\n",
       " ('got several tasks', 0.5),\n",
       " ('learning one algorithm', 0.5),\n",
       " ('coding related string', 0.5),\n",
       " ('table using group', 0.5),\n",
       " ('product questions end', 0.5),\n",
       " ('product sense business', 0.5),\n",
       " ('combine two dataset', 0.5),\n",
       " ('easy python standard', 0.5),\n",
       " ('coding data manipulation', 0.5),\n",
       " ('ajuster les hyperparameters', 0.5),\n",
       " ('comes particular distribution', 0.5),\n",
       " ('comment ajuster les', 0.5),\n",
       " ('several unsupervised learning', 0.5),\n",
       " ('coding product questions', 0.5),\n",
       " ('stats ml case', 0.5),\n",
       " ('ml case behaviors', 0.5),\n",
       " ('manipulation data intuition', 0.5),\n",
       " ('product analysis question', 0.5),\n",
       " ('problem people many', 0.5),\n",
       " ('close friend fb', 0.5),\n",
       " ('questions got several', 0.5),\n",
       " ('regression performancd metrics', 0.5),\n",
       " ('case study fb', 0.5),\n",
       " ('mostly behavioral questions', 0.5),\n",
       " ('like next years', 0.5),\n",
       " ('sql question easy', 0.5),\n",
       " ('related string processing', 0.5),\n",
       " ('case applied data', 0.5),\n",
       " ('explain challenging situation', 0.5),\n",
       " ('many orders fries', 0.5),\n",
       " ('cant share anything', 0.5),\n",
       " ('call recruiter asked', 0.5),\n",
       " ('call interview asked', 0.5),\n",
       " ('research papaer optimization', 0.5),\n",
       " ('two dataset keeping', 0.5),\n",
       " ('determine two users', 0.5),\n",
       " ('lasso ridge research', 0.5),\n",
       " ('maximum sub sequence', 0.5),\n",
       " ('whats problem people', 0.5),\n",
       " ('creation reactions facebook', 0.5),\n",
       " ('series sensors predict', 0.5),\n",
       " ('pretty much based', 0.5),\n",
       " ('explain one several', 0.5),\n",
       " ('case study real', 0.5),\n",
       " ('one several unsupervised', 0.5),\n",
       " ('outlier biasvariance trade', 0.5),\n",
       " ('probability case study', 0.5),\n",
       " ('users best friends', 0.5),\n",
       " ('many friends facebook', 0.5),\n",
       " ('real supply chain', 0.5),\n",
       " ('much based cv', 0.5),\n",
       " ('project worked successful', 0.5),\n",
       " ('challenging situation faced', 0.5),\n",
       " ('technical one product', 0.5),\n",
       " ('nda cant share', 0.5),\n",
       " ('recruiter asked experience', 0.5),\n",
       " ('life far like', 0.5),\n",
       " ('sql python stats', 0.5),\n",
       " ('pontos em uma', 0.49999999999999994),\n",
       " ('problema de otimizacao', 0.49999999999999994),\n",
       " ('simples ajustar pontos', 0.49999999999999994),\n",
       " ('uma reta por', 0.49999999999999994),\n",
       " ('tempo real solucao', 0.49999999999999994),\n",
       " ('um problema de', 0.49999999999999994),\n",
       " ('de um problema', 0.49999999999999994),\n",
       " ('de otimizacao simples', 0.49999999999999994),\n",
       " ('solucao de um', 0.49999999999999994),\n",
       " ('em uma reta', 0.49999999999999994),\n",
       " ('codificar em tempo', 0.49999999999999994),\n",
       " ('real solucao de', 0.49999999999999994),\n",
       " ('em tempo real', 0.49999999999999994),\n",
       " ('reta por exemplo', 0.49999999999999994),\n",
       " ('otimizacao simples ajustar', 0.49999999999999994),\n",
       " ('ajustar pontos em', 0.49999999999999994),\n",
       " ('well general questions', 0.48812729661071275),\n",
       " ('like would see', 0.47836749602800555),\n",
       " ('code generate random', 0.4580062142407374),\n",
       " ('generate random normal', 0.4580062142407374),\n",
       " ('random normal distribution', 0.4580062142407374),\n",
       " ('one data science', 0.4525134054120383),\n",
       " ('describe one data', 0.4525134054120383),\n",
       " ('project youve worked', 0.4525134054120383),\n",
       " ('feature selection overfitting', 0.4525134054120383),\n",
       " ('type questions machine', 0.4525134054120383),\n",
       " ('data manipulation product', 0.4525134054120383),\n",
       " ('science project youve', 0.4525134054120383),\n",
       " ('questions data manipulation', 0.4525134054120383),\n",
       " ('learning probability questions', 0.4525134054120383),\n",
       " ('leetcode type questions', 0.4525134054120383),\n",
       " ('manipulation product sense', 0.4525134054120383),\n",
       " ('basic data science', 0.4525134054120383),\n",
       " ('science questions feature', 0.4525134054120383),\n",
       " ('sql questions data', 0.4525134054120383),\n",
       " ('questions feature selection', 0.4525134054120383),\n",
       " ('machine learning probability', 0.4525134054120383),\n",
       " ('merge operations apply', 0.4472135954999579),\n",
       " ('prioritise speed delivery', 0.4472135954999579),\n",
       " ('business question requires', 0.4472135954999579),\n",
       " ('requires complex joins', 0.4472135954999579),\n",
       " ('tell calculate score', 0.4472135954999579),\n",
       " ('use pvalues high', 0.4472135954999579),\n",
       " ('previous projects sql', 0.4472135954999579),\n",
       " ('quality end product', 0.4472135954999579),\n",
       " ('would create model', 0.4472135954999579),\n",
       " ('calculate score would', 0.4472135954999579),\n",
       " ('breath knowledge data', 0.4472135954999579),\n",
       " ('ridge introduce dimension', 0.4472135954999579),\n",
       " ('evaluation metric overfitting', 0.4472135954999579),\n",
       " ('sql business question', 0.4472135954999579),\n",
       " ('right hence prepared', 0.4472135954999579),\n",
       " ('would go figuring', 0.4472135954999579),\n",
       " ('instagram describe previous', 0.4472135954999579),\n",
       " ('us time hand', 0.4472135954999579),\n",
       " ('porque deberian contratarme', 0.4472135954999579),\n",
       " ('population density one', 0.4472135954999579),\n",
       " ('fb goes xx', 0.4472135954999579),\n",
       " ('time hand handle', 0.4472135954999579),\n",
       " ('change test metric', 0.4472135954999579),\n",
       " ('evaluate deer population', 0.4472135954999579),\n",
       " ('recente que voce', 0.4472135954999579),\n",
       " ('metric overfitting etc', 0.4472135954999579),\n",
       " ('dimension reduction technique', 0.4472135954999579),\n",
       " ('dimensional linear regression', 0.4472135954999579),\n",
       " ('introduce dimension reduction', 0.4472135954999579),\n",
       " ('discuss randomly select', 0.4472135954999579),\n",
       " ('displays first fibonacci', 0.4472135954999579),\n",
       " ('sql self join', 0.4472135954999579),\n",
       " ('product user population', 0.4472135954999579),\n",
       " ('complex joins subqueries', 0.4472135954999579),\n",
       " ('questions ml algorithms', 0.4472135954999579),\n",
       " ('testing questions selection', 0.4472135954999579),\n",
       " ('product goal would', 0.4472135954999579),\n",
       " ('multivariate analysis pandas', 0.4472135954999579),\n",
       " ('coding questions similar', 0.4472135954999579),\n",
       " ('work happening right', 0.4472135954999579),\n",
       " ('questions selection bias', 0.4472135954999579),\n",
       " ('coding questions behavioral', 0.4472135954999579),\n",
       " ('questions similar leet', 0.4472135954999579),\n",
       " ('leet code medium', 0.4472135954999579),\n",
       " ('code medium level', 0.4472135954999579),\n",
       " ('empresa porque deberian', 0.4472135954999579),\n",
       " ('workplace working project', 0.4472135954999579),\n",
       " ('randomly select sample', 0.4472135954999579),\n",
       " ('metrics instagram describe', 0.4472135954999579),\n",
       " ('cite um projeto', 0.4472135954999579),\n",
       " ('speed delivery quality', 0.4472135954999579),\n",
       " ('live coding assessment', 0.4472135954999579),\n",
       " ('improve project time', 0.4472135954999579),\n",
       " ('behavioral questions focused', 0.4472135954999579),\n",
       " ('would improve project', 0.4472135954999579),\n",
       " ('self join table', 0.4472135954999579),\n",
       " ('make change test', 0.4472135954999579),\n",
       " ('write python function', 0.4472135954999579),\n",
       " ('analysis pandas merge', 0.4472135954999579),\n",
       " ('given table find', 0.4472135954999579),\n",
       " ('also questions ml', 0.4472135954999579),\n",
       " ('go figuring adress', 0.4472135954999579),\n",
       " ('goal would go', 0.4472135954999579),\n",
       " ('goes might reason', 0.4472135954999579),\n",
       " ('goes xx goes', 0.4472135954999579),\n",
       " ('tell us time', 0.4472135954999579),\n",
       " ('google app make', 0.4472135954999579),\n",
       " ('xx goes might', 0.4472135954999579),\n",
       " ('xxx fb goes', 0.4472135954999579),\n",
       " ('aggregated two columns', 0.4472135954999579),\n",
       " ('one national park', 0.4472135954999579),\n",
       " ('one issue youve', 0.4472135954999579),\n",
       " ('hand handle difficult', 0.4472135954999579),\n",
       " ('handle difficult situation', 0.4472135954999579),\n",
       " ('table pandas calculate', 0.4472135954999579),\n",
       " ('happening right hence', 0.4472135954999579),\n",
       " ('youve overcome workplace', 0.4472135954999579),\n",
       " ('similar leet code', 0.4472135954999579),\n",
       " ('ab testing questions', 0.4472135954999579),\n",
       " ('high dimensional linear', 0.4472135954999579),\n",
       " ('operations apply functions', 0.4472135954999579),\n",
       " ('mainly work happening', 0.4472135954999579),\n",
       " ('selection bias ml', 0.4472135954999579),\n",
       " ('score would improve', 0.4472135954999579),\n",
       " ('place mainly work', 0.4472135954999579),\n",
       " ('figuring adress problem', 0.4472135954999579),\n",
       " ('sample product user', 0.4472135954999579),\n",
       " ('find bad sellers', 0.4472135954999579),\n",
       " ('basic statistic questions', 0.4472135954999579),\n",
       " ('basic questions around', 0.4472135954999579),\n",
       " ('find table aggregated', 0.4472135954999579),\n",
       " ('first fibonacci numbers', 0.4472135954999579),\n",
       " ('science live coding', 0.4472135954999579),\n",
       " ('bad sellers marketplace', 0.4472135954999579),\n",
       " ('focused amazon principles', 0.4472135954999579),\n",
       " ('um projeto desafiador', 0.4472135954999579),\n",
       " ('aportaria la empresa', 0.4472135954999579),\n",
       " ('um desafio recente', 0.4472135954999579),\n",
       " ('test metric increased', 0.4472135954999579),\n",
       " ('would prioritise speed', 0.4472135954999579),\n",
       " ('ask ab testing', 0.4472135954999579),\n",
       " ('function displays first', 0.4472135954999579),\n",
       " ('pandas merge operations', 0.4472135954999579),\n",
       " ('pandas calculate score', 0.4472135954999579),\n",
       " ('around evaluation metric', 0.4472135954999579),\n",
       " ('overcome workplace working', 0.4472135954999579),\n",
       " ('select sample product', 0.4472135954999579),\n",
       " ('app make change', 0.4472135954999579),\n",
       " ('questions focused amazon', 0.4472135954999579),\n",
       " ('table find table', 0.4472135954999579),\n",
       " ('join table pandas', 0.4472135954999579),\n",
       " ('desafiador que você', 0.4472135954999579),\n",
       " ('projeto desafiador que', 0.4472135954999579),\n",
       " ('design metrics instagram', 0.4472135954999579),\n",
       " ('questions around evaluation', 0.4472135954999579),\n",
       " ('desafio recente que', 0.4472135954999579),\n",
       " ('question use pvalues', 0.4472135954999579),\n",
       " ('que você desenvolveu', 0.4472135954999579),\n",
       " ('questions behavioral questions', 0.4472135954999579),\n",
       " ('knowledge data science', 0.4472135954999579),\n",
       " ('deer population density', 0.4472135954999579),\n",
       " ('data science live', 0.4472135954999579),\n",
       " ('delivery quality end', 0.4472135954999579),\n",
       " ('issue youve overcome', 0.4472135954999579),\n",
       " ('statistic questions also', 0.4472135954999579),\n",
       " ('describe previous projects', 0.4472135954999579),\n",
       " ('difference lasso ridge', 0.4472135954999579),\n",
       " ('density one national', 0.4472135954999579),\n",
       " ('table aggregated two', 0.4472135954999579),\n",
       " ('que voce enfrentou', 0.4472135954999579),\n",
       " ('model find bad', 0.4472135954999579),\n",
       " ('create model find', 0.4472135954999579),\n",
       " ('python function displays', 0.4472135954999579),\n",
       " ('question requires complex', 0.4472135954999579),\n",
       " ('que aportaria la', 0.4472135954999579),\n",
       " ('conte um desafio', 0.4472135954999579),\n",
       " ('pvalues high dimensional', 0.4472135954999579),\n",
       " ('questions also questions', 0.4472135954999579),\n",
       " ('lasso ridge introduce', 0.4472135954999579),\n",
       " ('la empresa porque', 0.4472135954999579),\n",
       " ('assumptions linear regression', 0.4415472154181739),\n",
       " ('min interview product', 0.4364357804719847),\n",
       " ('interview product case', 0.4364357804719847),\n",
       " ('would evaluate performance', 0.428944979272183),\n",
       " ('time enough answer', 0.42640143271122083),\n",
       " ('finding patterns time', 0.42640143271122083),\n",
       " ('theories programming eda', 0.42640143271122083),\n",
       " ('eda finding patterns', 0.42640143271122083),\n",
       " ('questions two programming', 0.42640143271122083),\n",
       " ('programming eda finding', 0.42640143271122083),\n",
       " ('choice questions two', 0.42640143271122083),\n",
       " ('questions around theories', 0.42640143271122083),\n",
       " ('set questions multiple', 0.42640143271122083),\n",
       " ('patterns time enough', 0.42640143271122083),\n",
       " ('programming questions multiple', 0.42640143271122083),\n",
       " ('choice questions around', 0.42640143271122083),\n",
       " ('around theories programming', 0.42640143271122083),\n",
       " ('two programming questions', 0.42640143271122083),\n",
       " ('two tables table', 0.4181088981634592),\n",
       " ('tables table one', 0.4181088981634592),\n",
       " ('records two fields', 0.4181088981634592),\n",
       " ('records fields id', 0.4181088981634592),\n",
       " ('id age table', 0.4181088981634592),\n",
       " ('million records fields', 0.4181088981634592),\n",
       " ('fields id age', 0.4181088981634592),\n",
       " ('table one million', 0.4181088981634592),\n",
       " ('one million records', 0.4181088981634592),\n",
       " ('age table records', 0.4181088981634592),\n",
       " ('table records two', 0.4181088981634592),\n",
       " ('th largest element', 0.40824829046386296),\n",
       " ('experience resume difficult', 0.40824829046386296),\n",
       " ('data confirm users', 0.40824829046386296),\n",
       " ('array questionfind th', 0.40824829046386296),\n",
       " ('related ab testing', 0.40824829046386296),\n",
       " ('related courses take', 0.40824829046386296),\n",
       " ('machine learning interviews', 0.40824829046386296),\n",
       " ('school data real', 0.40824829046386296),\n",
       " ('principle tech half', 0.40824829046386296),\n",
       " ...]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_interview_questions_df = interview_questions_df[(interview_questions_df['Company'] == 'Meta')]\n",
    "apple_interview_questions_df = interview_questions_df[(interview_questions_df['Company'] == 'Apple')]\n",
    "google_interview_questions_df = interview_questions_df[(interview_questions_df['Company'] == 'Google')]\n",
    "microsoft_interview_questions_df = interview_questions_df[(interview_questions_df['Company'] == 'Microsoft')]\n",
    "amazon_interview_questions_df = interview_questions_df[(interview_questions_df['Company'] == 'Amazon')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple TFIDF Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tell know displays', 1.0),\n",
       " ('asked projects resume', 1.0),\n",
       " ('tell current responsibilities', 1.0),\n",
       " ('strength relates analysis', 1.0),\n",
       " ('calculate sample size', 1.0),\n",
       " ('question based resume', 1.0),\n",
       " ('conduct ab test', 0.7071067811865475),\n",
       " ('sql basic questions', 0.7071067811865475),\n",
       " ('use evaluate model', 0.7071067811865475),\n",
       " ('specially internship experiences', 0.7071067811865475),\n",
       " ('resume job posting', 0.7071067811865475),\n",
       " ('questions domain knowledge', 0.7071067811865475),\n",
       " ('question set cover', 0.7071067811865475),\n",
       " ('basic questions etc', 0.7071067811865475),\n",
       " ('basic questions domain', 0.7071067811865475),\n",
       " ('asked question set', 0.7071067811865475),\n",
       " ('background specially internship', 0.7071067811865475),\n",
       " ('items resume job', 0.7071067811865475),\n",
       " ('metrics use evaluate', 0.7071067811865475),\n",
       " ('would conduct ab', 0.7071067811865475),\n",
       " ('approach problems deadline', 0.7071067811865475),\n",
       " ('problems deadline environment', 0.7071067811865475),\n",
       " ('knn nearest neighbor', 0.5773502691896257),\n",
       " ('describe difference knn', 0.5773502691896257),\n",
       " ('difference knn nearest', 0.5773502691896257),\n",
       " ('sense questions product', 0.5),\n",
       " ('years life far', 0.5),\n",
       " ('predict next reading', 0.5),\n",
       " ('series sensors predict', 0.5),\n",
       " ('next years life', 0.5),\n",
       " ('sensors predict next', 0.5),\n",
       " ('product sense questions', 0.5),\n",
       " ('like next years', 0.5),\n",
       " ('questions product team', 0.5),\n",
       " ('life far like', 0.5),\n",
       " ('time series sensors', 0.5),\n",
       " ('product team focused', 0.5),\n",
       " ('la empresa porque', 0.4472135954999579),\n",
       " ('que aportaria la', 0.4472135954999579),\n",
       " ('porque deberian contratarme', 0.4472135954999579),\n",
       " ('overcome workplace working', 0.4472135954999579),\n",
       " ('one issue youve', 0.4472135954999579),\n",
       " ('issue youve overcome', 0.4472135954999579),\n",
       " ('empresa porque deberian', 0.4472135954999579),\n",
       " ('youve overcome workplace', 0.4472135954999579),\n",
       " ('workplace working project', 0.4472135954999579),\n",
       " ('aportaria la empresa', 0.4472135954999579),\n",
       " ('interview relaxed conversation', 0.408248290463863),\n",
       " ('concept learn penalized', 0.408248290463863),\n",
       " ('courses take concept', 0.408248290463863),\n",
       " ('conversation asked many', 0.408248290463863),\n",
       " ('learn penalized regression', 0.408248290463863),\n",
       " ('many questions asked', 0.408248290463863),\n",
       " ('asked many questions', 0.408248290463863),\n",
       " ('take concept learn', 0.408248290463863),\n",
       " ('related courses take', 0.408248290463863),\n",
       " ('relaxed conversation asked', 0.408248290463863),\n",
       " ('ml related courses', 0.408248290463863),\n",
       " ('every interview relaxed', 0.408248290463863),\n",
       " ('index sum left', 0.37796447300922725),\n",
       " ('find index sum', 0.37796447300922725),\n",
       " ('questions probability questions', 0.37796447300922725),\n",
       " ('general behavioral questions', 0.37796447300922725),\n",
       " ('half array equal', 0.37796447300922725),\n",
       " ('brain teaser puzzle', 0.37796447300922725),\n",
       " ('behavioral questions probability', 0.37796447300922725),\n",
       " ('questions one brain', 0.37796447300922725),\n",
       " ('probability questions one', 0.37796447300922725),\n",
       " ('left half array', 0.37796447300922725),\n",
       " ('one brain teaser', 0.37796447300922725),\n",
       " ('sum left half', 0.37796447300922725),\n",
       " ('equal right half', 0.37796447300922725),\n",
       " ('array equal right', 0.37796447300922725),\n",
       " ('impact model training', 0.33333333333333337),\n",
       " ('describe detail difference', 0.33333333333333337),\n",
       " ('regards difference impact', 0.33333333333333337),\n",
       " ('regularization specifically regards', 0.33333333333333337),\n",
       " ('detail difference regularization', 0.33333333333333337),\n",
       " ('difference impact model', 0.33333333333333337),\n",
       " ('specifically regards difference', 0.33333333333333337),\n",
       " ('difference regularization specifically', 0.33333333333333337),\n",
       " ('model training process', 0.33333333333333337),\n",
       " ('ks products group', 0.31622776601683794),\n",
       " ('group users together', 0.31622776601683794),\n",
       " ('users transactions amongst', 0.31622776601683794),\n",
       " ('amongst ks products', 0.31622776601683794),\n",
       " ('millions users transactions', 0.31622776601683794),\n",
       " ('products group users', 0.31622776601683794),\n",
       " ('together meaningful segments', 0.31622776601683794),\n",
       " ('transactions amongst ks', 0.31622776601683794),\n",
       " ('users together meaningful', 0.31622776601683794),\n",
       " ('take millions users', 0.31622776601683794),\n",
       " ('information count daily', 0.2886751345948129),\n",
       " ('platform ipad iphone', 0.2886751345948129),\n",
       " ('given table user', 0.2886751345948129),\n",
       " ('ipad iphone mac', 0.2886751345948129),\n",
       " ('daily active users', 0.2886751345948129),\n",
       " ('count daily active', 0.2886751345948129),\n",
       " ('table user log', 0.2886751345948129),\n",
       " ('log platform information', 0.2886751345948129),\n",
       " ('user log platform', 0.2886751345948129),\n",
       " ('active users platform', 0.2886751345948129),\n",
       " ('platform information count', 0.2886751345948129),\n",
       " ('users platform ipad', 0.2886751345948129),\n",
       " ('mainly case studies', 0.2773500981126146),\n",
       " ('walked project youre', 0.2773500981126146),\n",
       " ('test consisted simple', 0.2773500981126146),\n",
       " ('youre proud metric', 0.2773500981126146),\n",
       " ('proud metric design', 0.2773500981126146),\n",
       " ('project youre proud', 0.2773500981126146),\n",
       " ('interview questions technical', 0.2773500981126146),\n",
       " ('sql question python', 0.2773500981126146),\n",
       " ('metric design questions', 0.2773500981126146),\n",
       " ('technical test consisted', 0.2773500981126146),\n",
       " ('case studies around', 0.2773500981126146),\n",
       " ('around various apple', 0.2773500981126146),\n",
       " ('studies around various', 0.2773500981126146),\n",
       " ('hrstyle interview questions', 0.2773500981126146),\n",
       " ('consisted simple enough', 0.2773500981126146),\n",
       " ('apple app lines', 0.2773500981126146),\n",
       " ('python question working', 0.2773500981126146),\n",
       " ('enough sql question', 0.2773500981126146),\n",
       " ('question working dataframes', 0.2773500981126146),\n",
       " ('questions technical test', 0.2773500981126146),\n",
       " ('various apple app', 0.2773500981126146),\n",
       " ('question python question', 0.2773500981126146),\n",
       " ('design questions mainly', 0.2773500981126146),\n",
       " ('usual hrstyle interview', 0.2773500981126146),\n",
       " ('questions mainly case', 0.2773500981126146),\n",
       " ('simple enough sql', 0.2773500981126146),\n",
       " ('anagrams list print', 0.2672612419124244),\n",
       " ('print list anagrams', 0.2672612419124244),\n",
       " ('code python find', 0.2672612419124244),\n",
       " ('xgboost handling biasvariance', 0.2672612419124244),\n",
       " ('find anagrams list', 0.2672612419124244),\n",
       " ('whats bias variance', 0.2672612419124244),\n",
       " ('biasvariance tradeoff code', 0.2672612419124244),\n",
       " ('list print list', 0.2672612419124244),\n",
       " ('tradeoff xgboost handling', 0.2672612419124244),\n",
       " ('variance tradeoff xgboost', 0.2672612419124244),\n",
       " ('handling biasvariance tradeoff', 0.2672612419124244),\n",
       " ('python find anagrams', 0.2672612419124244),\n",
       " ('bias variance tradeoff', 0.2672612419124244),\n",
       " ('tradeoff code python', 0.2672612419124244),\n",
       " ('favorite apple product', 0.23570226039551584),\n",
       " ('explain scenario found', 0.23570226039551584),\n",
       " ('would improve debate', 0.23570226039551584),\n",
       " ('confidence interval favorite', 0.23570226039551584),\n",
       " ('scenario found something', 0.23570226039551584),\n",
       " ('vs frequentist statistics', 0.23570226039551584),\n",
       " ('followup would improve', 0.23570226039551584),\n",
       " ('describe confidence interval', 0.23570226039551584),\n",
       " ('found something unexpected', 0.23570226039551584),\n",
       " ('product followup would', 0.23570226039551584),\n",
       " ('frequentist statistics explain', 0.23570226039551584),\n",
       " ('statistics explain scenario', 0.23570226039551584),\n",
       " ('bayesian vs frequentist', 0.23570226039551584),\n",
       " ('apple product followup', 0.23570226039551584),\n",
       " ('improve debate bayesian', 0.23570226039551584),\n",
       " ('interval favorite apple', 0.23570226039551584),\n",
       " ('debate bayesian vs', 0.23570226039551584),\n",
       " ('something unexpected data', 0.23570226039551584),\n",
       " ('regret sql build', 0.21320071635561044),\n",
       " ('row every group', 0.21320071635561044),\n",
       " ('python search function', 0.21320071635561044),\n",
       " ('top skills sets', 0.21320071635561044),\n",
       " ('sorting function python', 0.21320071635561044),\n",
       " ('others biggest regret', 0.21320071635561044),\n",
       " ('sql build metric', 0.21320071635561044),\n",
       " ('skills sets apart', 0.21320071635561044),\n",
       " ('sets apart form', 0.21320071635561044),\n",
       " ('python sorting function', 0.21320071635561044),\n",
       " ('ok look first', 0.21320071635561044),\n",
       " ('metric ok look', 0.21320071635561044),\n",
       " ('first row every', 0.21320071635561044),\n",
       " ('group python sorting', 0.21320071635561044),\n",
       " ('every group python', 0.21320071635561044),\n",
       " ('function python search', 0.21320071635561044),\n",
       " ('name top skills', 0.21320071635561044),\n",
       " ('form others biggest', 0.21320071635561044),\n",
       " ('look first row', 0.21320071635561044),\n",
       " ('apart form others', 0.21320071635561044),\n",
       " ('build metric ok', 0.21320071635561044),\n",
       " ('biggest regret sql', 0.21320071635561044),\n",
       " ('bias decide whether', 0.1924500897298753),\n",
       " ('typical data science', 0.1924500897298753),\n",
       " ('experience paymentsrevenue data', 0.1924500897298753),\n",
       " ('binary tree implementation', 0.1924500897298753),\n",
       " ('draw confusion matrix', 0.1924500897298753),\n",
       " ('better naive bayes', 0.1924500897298753),\n",
       " ('screen involved sql', 0.1924500897298753),\n",
       " ('regarding experience paymentsrevenue', 0.1924500897298753),\n",
       " ('recall coding questions', 0.1924500897298753),\n",
       " ('behavioural stuff deal', 0.1924500897298753),\n",
       " ('questions regarding experience', 0.1924500897298753),\n",
       " ('questions included binary', 0.1924500897298753),\n",
       " ('variance bias decide', 0.1924500897298753),\n",
       " ('science interview hiring', 0.1924500897298753),\n",
       " ('tree implementation computing', 0.1924500897298753),\n",
       " ('python string question', 0.1924500897298753),\n",
       " ('sql coding coderpad', 0.1924500897298753),\n",
       " ('talked behavioural stuff', 0.1924500897298753),\n",
       " ('technical screen involved', 0.1924500897298753),\n",
       " ('confusion matrix calculate', 0.1924500897298753),\n",
       " ('stuff deal difficult', 0.1924500897298753),\n",
       " ('coding questions included', 0.1924500897298753),\n",
       " ('coding coderpad basic', 0.1924500897298753),\n",
       " ('coderpad basic python', 0.1924500897298753),\n",
       " ('stakeholders talked behavioural', 0.1924500897298753),\n",
       " ('data science interview', 0.1924500897298753),\n",
       " ('difficult situations technical', 0.1924500897298753),\n",
       " ('data stakeholders talked', 0.1924500897298753),\n",
       " ('classifier describe neural', 0.1924500897298753),\n",
       " ('classification algorithm better', 0.1924500897298753),\n",
       " ('deal difficult situations', 0.1924500897298753),\n",
       " ('decide whether one', 0.1924500897298753),\n",
       " ('situations technical screen', 0.1924500897298753),\n",
       " ('calculate precision recall', 0.1924500897298753),\n",
       " ('describe neural network', 0.1924500897298753),\n",
       " ('hiring manager asked', 0.1924500897298753),\n",
       " ('computing ngrams python', 0.1924500897298753),\n",
       " ('involved sql coding', 0.1924500897298753),\n",
       " ('basic python string', 0.1924500897298753),\n",
       " ('asked questions regarding', 0.1924500897298753),\n",
       " ('precision recall coding', 0.1924500897298753),\n",
       " ('manager asked questions', 0.1924500897298753),\n",
       " ('paymentsrevenue data stakeholders', 0.1924500897298753),\n",
       " ('matrix calculate precision', 0.1924500897298753),\n",
       " ('one classification algorithm', 0.1924500897298753),\n",
       " ('interview hiring manager', 0.1924500897298753),\n",
       " ('whether one classification', 0.1924500897298753),\n",
       " ('naive bayes classifier', 0.1924500897298753),\n",
       " ('algorithm better naive', 0.1924500897298753),\n",
       " ('network draw confusion', 0.1924500897298753),\n",
       " ('bayes classifier describe', 0.1924500897298753),\n",
       " ('included binary tree', 0.1924500897298753),\n",
       " ('neural network draw', 0.1924500897298753),\n",
       " ('implementation computing ngrams', 0.1924500897298753),\n",
       " ('cdf meet manager', 0.17960530202677494),\n",
       " ('dollars however interview', 0.17960530202677494),\n",
       " ('design product free', 0.17960530202677494),\n",
       " ('collection part questions', 0.17960530202677494),\n",
       " ('ask projects asking', 0.17960530202677494),\n",
       " ('pdf cdf meet', 0.17960530202677494),\n",
       " ('part questions regarding', 0.17960530202677494),\n",
       " ('store json file', 0.17960530202677494),\n",
       " ('manager dollars however', 0.17960530202677494),\n",
       " ('manager hiring manager', 0.17960530202677494),\n",
       " ('hiring manager dollars', 0.17960530202677494),\n",
       " ('data collection part', 0.17960530202677494),\n",
       " ('meet manager hiring', 0.17960530202677494),\n",
       " ('statistics pdf cdf', 0.17960530202677494),\n",
       " ('quality assurance design', 0.17960530202677494),\n",
       " ('lunch hiring manager', 0.17960530202677494),\n",
       " ('regarding quality assurance', 0.17960530202677494),\n",
       " ('json store json', 0.17960530202677494),\n",
       " ('hiring manager python', 0.17960530202677494),\n",
       " ('heshe ask projects', 0.17960530202677494),\n",
       " ('however interview heshe', 0.17960530202677494),\n",
       " ('projects asking statistics', 0.17960530202677494),\n",
       " ('questions regarding quality', 0.17960530202677494),\n",
       " ('interview heshe ask', 0.17960530202677494),\n",
       " ('json file data', 0.17960530202677494),\n",
       " ('product free lunch', 0.17960530202677494),\n",
       " ('free lunch hiring', 0.17960530202677494),\n",
       " ('asking statistics pdf', 0.17960530202677494),\n",
       " ('loading json store', 0.17960530202677494),\n",
       " ('file data collection', 0.17960530202677494),\n",
       " ('assurance design product', 0.17960530202677494),\n",
       " ('visualization loading slow', 0.12403473458920845),\n",
       " ('values tableau visualization', 0.12403473458920845),\n",
       " ('worked splunk worked', 0.12403473458920845),\n",
       " ('values worked splunk', 0.12403473458920845),\n",
       " ('also types filters', 0.12403473458920845),\n",
       " ('analysis workflow dealing', 0.12403473458920845),\n",
       " ('another person sitting', 0.12403473458920845),\n",
       " ('column use strsplit', 0.12403473458920845),\n",
       " ('workflow dealing nans', 0.12403473458920845),\n",
       " ('tests causing power', 0.12403473458920845),\n",
       " ('tests interferes mac', 0.12403473458920845),\n",
       " ('use strsplit function', 0.12403473458920845),\n",
       " ('tests run general', 0.12403473458920845),\n",
       " ('types filters uses', 0.12403473458920845),\n",
       " ('causes power fluctuations', 0.12403473458920845),\n",
       " ('uses dealing nan', 0.12403473458920845),\n",
       " ('causing power fluctuations', 0.12403473458920845),\n",
       " ('worked mongo db', 0.12403473458920845),\n",
       " ('names column use', 0.12403473458920845),\n",
       " ('tableau visualization loading', 0.12403473458920845),\n",
       " ('power fluctuations confirm', 0.12403473458920845),\n",
       " ('fluctuations access report', 0.12403473458920845),\n",
       " ('fluctuations confirm persons', 0.12403473458920845),\n",
       " ('function tableau context', 0.12403473458920845),\n",
       " ('general data analysis', 0.12403473458920845),\n",
       " ('python create dataframe', 0.12403473458920845),\n",
       " ('interferes mac power', 0.12403473458920845),\n",
       " ('product another person', 0.12403473458920845),\n",
       " ('letter python create', 0.12403473458920845),\n",
       " ('loading slow product', 0.12403473458920845),\n",
       " ('power fluctuations access', 0.12403473458920845),\n",
       " ('tableau context filters', 0.12403473458920845),\n",
       " ('power causes power', 0.12403473458920845),\n",
       " ('mac power causes', 0.12403473458920845),\n",
       " ('persons tests causing', 0.12403473458920845),\n",
       " ('person sitting next', 0.12403473458920845),\n",
       " ('performing tests interferes', 0.12403473458920845),\n",
       " ('null values worked', 0.12403473458920845),\n",
       " ('null values tableau', 0.12403473458920845),\n",
       " ('next room performing', 0.12403473458920845),\n",
       " ('nans null values', 0.12403473458920845),\n",
       " ('first names column', 0.12403473458920845),\n",
       " ('find rows starting', 0.12403473458920845),\n",
       " ('filters uses dealing', 0.12403473458920845),\n",
       " ('filters also types', 0.12403473458920845),\n",
       " ('confirm persons tests', 0.12403473458920845),\n",
       " ('context filters also', 0.12403473458920845),\n",
       " ('strsplit function tableau', 0.12403473458920845),\n",
       " ('create dataframe return', 0.12403473458920845),\n",
       " ('data analysis workflow', 0.12403473458920845),\n",
       " ('starting letter python', 0.12403473458920845),\n",
       " ('sql find rows', 0.12403473458920845),\n",
       " ('splunk worked mongo', 0.12403473458920845),\n",
       " ('dataframe return first', 0.12403473458920845),\n",
       " ('dealing nan null', 0.12403473458920845),\n",
       " ('dealing nans null', 0.12403473458920845),\n",
       " ('slow product another', 0.12403473458920845),\n",
       " ('sitting next room', 0.12403473458920845),\n",
       " ('nan null values', 0.12403473458920845),\n",
       " ('run general data', 0.12403473458920845),\n",
       " ('rows starting letter', 0.12403473458920845),\n",
       " ('room performing tests', 0.12403473458920845),\n",
       " ('return first names', 0.12403473458920845),\n",
       " ('report tests run', 0.12403473458920845),\n",
       " ('access report tests', 0.12403473458920845)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_vectorizer = TfidfVectorizer(ngram_range=(3,3), min_df=0.01, max_df = 0.75)\n",
    "apple_vectorized_questions = pd.DataFrame(apple_vectorizer.fit_transform(apple_interview_questions_df['Interview Questions']).toarray(), columns = apple_vectorizer.get_feature_names_out())\n",
    "apple_vectorized_questions.loc['Total'] = apple_vectorized_questions.sum(numeric_only=True, axis=0)\n",
    "apple_vectorized_questions = apple_vectorized_questions.sort_values(apple_vectorized_questions.last_valid_index(), axis=1, ascending=False)\n",
    "apple_sorted_word_list = [(col, apple_vectorized_questions[col].iloc[-1]) for col in apple_vectorized_questions.columns]\n",
    "apple_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google TFIDF Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('statistics machine learning', 1.7071067811865475),\n",
       " ('standard error mean', 1.449686985531412),\n",
       " ('machine learning questions', 1.252067208627597),\n",
       " ('prefer google apple', 1.0),\n",
       " ('window function group', 1.0),\n",
       " ('describe pca works', 1.0),\n",
       " ('explain sql works', 1.0),\n",
       " ('introduce question probality', 1.0),\n",
       " ('signed nda disclose', 1.0),\n",
       " ('responsible future job', 1.0),\n",
       " ('projects worked phd', 1.0),\n",
       " ('unfair coin fair', 0.8000214916751375),\n",
       " ('assumption error linear', 0.8000214916751375),\n",
       " ('make unfair coin', 0.8000214916751375),\n",
       " ('error linear regression', 0.8000214916751375),\n",
       " ('write code generate', 0.7526188540958284),\n",
       " ('hash table python', 0.7071067811865475),\n",
       " ('given coin biased', 0.7071067811865475),\n",
       " ('forecast brands sales', 0.7071067811865475),\n",
       " ('find width confidence', 0.7071067811865475),\n",
       " ('questions ab test', 0.7071067811865475),\n",
       " ('explain prior project', 0.7071067811865475),\n",
       " ('basic coding simulation', 0.7071067811865475),\n",
       " ('probability integral transform', 0.7071067811865475),\n",
       " ('asked invert binary', 0.7071067811865475),\n",
       " ('use mean vs', 0.7071067811865475),\n",
       " ('detailed questions ab', 0.7071067811865475),\n",
       " ('describe process data', 0.7071067811865475),\n",
       " ('describe previous experience', 0.7071067811865475),\n",
       " ('would solve global', 0.7071067811865475),\n",
       " ('width confidence interval', 0.7071067811865475),\n",
       " ('questions including code', 0.7071067811865475),\n",
       " ('data manipulation coding', 0.7071067811865475),\n",
       " ('coding simulation setup', 0.7071067811865475),\n",
       " ('code hash table', 0.7071067811865475),\n",
       " ('tell given coin', 0.7071067811865475),\n",
       " ('asked solve algorithms', 0.7071067811865475),\n",
       " ('invert binary tree', 0.7071067811865475),\n",
       " ('sort priorities engaged', 0.7071067811865475),\n",
       " ('priorities engaged multitasking', 0.7071067811865475),\n",
       " ('prior project worked', 0.7071067811865475),\n",
       " ('predict metrics using', 0.7071067811865475),\n",
       " ('please describe previous', 0.7071067811865475),\n",
       " ('open questions including', 0.7071067811865475),\n",
       " ('process data analysis', 0.7071067811865475),\n",
       " ('solve global warming', 0.7071067811865475),\n",
       " ('solve algorithms python', 0.7071067811865475),\n",
       " ('metrics using regression', 0.7071067811865475),\n",
       " ('prove probability integral', 0.7071067811865475),\n",
       " ('mean vs median', 0.7071067811865475),\n",
       " ('manipulation coding test', 0.7071067811865475),\n",
       " ('would forecast brands', 0.7071067811865475),\n",
       " ('signed nda cant', 0.6963891110115998),\n",
       " ('explain probability distribution', 0.6702649796782157),\n",
       " ('consider mean median', 0.6702649796782157),\n",
       " ('probability distribution normal', 0.6702649796782157),\n",
       " ('distribution normal apply', 0.6702649796782157),\n",
       " ('situation would consider', 0.6702649796782157),\n",
       " ('would consider mean', 0.6702649796782157),\n",
       " ('question coding question', 0.6038059508510546),\n",
       " ('probability question coding', 0.6038059508510546),\n",
       " ('learning questions coding', 0.5928820002847399),\n",
       " ('questions coding questions', 0.5928820002847399),\n",
       " ('nda cant disclose', 0.5928820002847399),\n",
       " ('cant disclose unfortunately', 0.5928820002847399),\n",
       " ('normal distribution plot', 0.5830082795793272),\n",
       " ('could ab test', 0.5818199491075641),\n",
       " ('ab test see', 0.5818199491075641),\n",
       " ('test see increase', 0.5818199491075641),\n",
       " ('basic question coding', 0.5773502691896258),\n",
       " ('multiple tasks given', 0.5773502691896258),\n",
       " ('months california trained', 0.5773502691896258),\n",
       " ('standard stats behavior', 0.5773502691896258),\n",
       " ('coding questions rejection', 0.5773502691896258),\n",
       " ('hypothesis testing python', 0.5773502691896258),\n",
       " ('coding sum squares', 0.5773502691896258),\n",
       " ('bq basic statistics', 0.5773502691896258),\n",
       " ('basic statistics statistical', 0.5773502691896258),\n",
       " ('inappropriate content youtube', 0.5773502691896258),\n",
       " ('ask answer data', 0.5773502691896258),\n",
       " ('virus inappropriate content', 0.5773502691896258),\n",
       " ('manage multiple tasks', 0.5773502691896258),\n",
       " ('detect virus inappropriate', 0.5773502691896258),\n",
       " ('questions rejection sampling', 0.5773502691896258),\n",
       " ('statistics statistical sampling', 0.5773502691896258),\n",
       " ('stats behavior product', 0.5773502691896258),\n",
       " ('data structure question', 0.5773502691896258),\n",
       " ('phone number address', 0.5773502691896258),\n",
       " ('behavior product sense', 0.5773502691896258),\n",
       " ('describe manage multiple', 0.5773502691896258),\n",
       " ('answer data structure', 0.5773502691896258),\n",
       " ('willing spend months', 0.5773502691896258),\n",
       " ('name expectations phone', 0.5773502691896258),\n",
       " ('python coding questions', 0.5773502691896258),\n",
       " ('expectations phone number', 0.5773502691896258),\n",
       " ('testing python coding', 0.5773502691896258),\n",
       " ('question coding sum', 0.5773502691896258),\n",
       " ('one coding questions', 0.5773502691896258),\n",
       " ('spend months california', 0.5773502691896258),\n",
       " ('see increase product', 0.5318975493013407),\n",
       " ('asked background want', 0.5),\n",
       " ('disadvantages several programming', 0.5),\n",
       " ('comes particular distribution', 0.5),\n",
       " ('data science concepts', 0.5),\n",
       " ('research papaer optimization', 0.5),\n",
       " ('compared advantages disadvantages', 0.5),\n",
       " ('data manipulation data', 0.5),\n",
       " ('based cv experience', 0.5),\n",
       " ('manipulation data intuition', 0.5),\n",
       " ('interview asked background', 0.5),\n",
       " ('variable test comes', 0.5),\n",
       " ('pretty much based', 0.5),\n",
       " ('recruiter asked experience', 0.5),\n",
       " ('questions pretty much', 0.5),\n",
       " ('concepts regression performancd', 0.5),\n",
       " ('phone call interview', 0.5),\n",
       " ('data intuition statistics', 0.5),\n",
       " ('regression performancd metrics', 0.5),\n",
       " ('ridge research papaer', 0.5),\n",
       " ('coding data manipulation', 0.5),\n",
       " ('much based cv', 0.5),\n",
       " ('advantages disadvantages several', 0.5),\n",
       " ('test comes particular', 0.5),\n",
       " ('science concepts regression', 0.5),\n",
       " ('one call recruiter', 0.5),\n",
       " ('call interview asked', 0.5),\n",
       " ('several programming languages', 0.5),\n",
       " ('call recruiter asked', 0.5),\n",
       " ('papaer optimization etc', 0.5),\n",
       " ('random variable test', 0.5),\n",
       " ('asked experience generally', 0.5),\n",
       " ('lasso ridge research', 0.5),\n",
       " ('code generate random', 0.46176922328205966),\n",
       " ('random normal distribution', 0.46176922328205966),\n",
       " ('generate random normal', 0.46176922328205966),\n",
       " ('questions selection bias', 0.4472135954999579),\n",
       " ('feature selection overfitting', 0.4472135954999579),\n",
       " ('density one national', 0.4472135954999579),\n",
       " ('ab testing questions', 0.4472135954999579),\n",
       " ('pvalues high dimensional', 0.4472135954999579),\n",
       " ('test metric increased', 0.4472135954999579),\n",
       " ('dimensional linear regression', 0.4472135954999579),\n",
       " ('questions feature selection', 0.4472135954999579),\n",
       " ('evaluate deer population', 0.4472135954999579),\n",
       " ('use pvalues high', 0.4472135954999579),\n",
       " ('deer population density', 0.4472135954999579),\n",
       " ('basic data science', 0.4472135954999579),\n",
       " ('testing questions selection', 0.4472135954999579),\n",
       " ('google app make', 0.4472135954999579),\n",
       " ('science questions feature', 0.4472135954999579),\n",
       " ('question use pvalues', 0.4472135954999579),\n",
       " ('high dimensional linear', 0.4472135954999579),\n",
       " ('population density one', 0.4472135954999579),\n",
       " ('app make change', 0.4472135954999579),\n",
       " ('selection bias ml', 0.4472135954999579),\n",
       " ('make change test', 0.4472135954999579),\n",
       " ('ask ab testing', 0.4472135954999579),\n",
       " ('data science questions', 0.4472135954999579),\n",
       " ('one national park', 0.4472135954999579),\n",
       " ('change test metric', 0.4472135954999579),\n",
       " ('would evaluate performance', 0.4210883070490975),\n",
       " ('problème de leetcode', 0.408248290463863),\n",
       " ('compétences pensez vous', 0.408248290463863),\n",
       " ('principe de tiroir', 0.408248290463863),\n",
       " ('would find top', 0.408248290463863),\n",
       " ('increase sample size', 0.408248290463863),\n",
       " ('avec le principe', 0.408248290463863),\n",
       " ('apply bootstrapping samples', 0.408248290463863),\n",
       " ('le principe de', 0.408248290463863),\n",
       " ('highestselling items list', 0.408248290463863),\n",
       " ('abuse thats remember', 0.408248290463863),\n",
       " ('youtube abuse thats', 0.408248290463863),\n",
       " ('samples increase sample', 0.408248290463863),\n",
       " ('tell youtube abuse', 0.408248290463863),\n",
       " ('vous pouvoir apporter', 0.408248290463863),\n",
       " ('bootstrapping samples increase', 0.408248290463863),\n",
       " ('pensez vous pouvoir', 0.408248290463863),\n",
       " ('apporter notre entreprise', 0.408248290463863),\n",
       " ('bad apply bootstrapping', 0.408248290463863),\n",
       " ('leetcode avec le', 0.408248290463863),\n",
       " ('quelles compétences pensez', 0.408248290463863),\n",
       " ('find top highestselling', 0.408248290463863),\n",
       " ('de leetcode avec', 0.408248290463863),\n",
       " ('top highestselling items', 0.408248290463863),\n",
       " ('glassdoor forced contribute', 0.408248290463863),\n",
       " ('good bad apply', 0.408248290463863),\n",
       " ('list order histories', 0.408248290463863),\n",
       " ('items list order', 0.408248290463863),\n",
       " ('remember glassdoor forced', 0.408248290463863),\n",
       " ('thats remember glassdoor', 0.408248290463863),\n",
       " ('pouvoir apporter notre', 0.408248290463863),\n",
       " ('related statistical analysisprobability', 0.38662945453226616),\n",
       " ('coding question related', 0.38662945453226616),\n",
       " ('question related statistical', 0.38662945453226616),\n",
       " ('statistical analysisprobability openended', 0.38662945453226616),\n",
       " ('analysisprobability openended question', 0.38662945453226616),\n",
       " ('gaussian mixture model', 0.3809218944389917),\n",
       " ('business case explain', 0.37796447300922725),\n",
       " ('product line launched', 0.37796447300922725),\n",
       " ('describe crossfunctional work', 0.37796447300922725),\n",
       " ('background describe crossfunctional', 0.37796447300922725),\n",
       " ('new product line', 0.37796447300922725),\n",
       " ('case explain measure', 0.37796447300922725),\n",
       " ('go background describe', 0.37796447300922725),\n",
       " ('crossfunctional work describe', 0.37796447300922725),\n",
       " ('work describe project', 0.37796447300922725),\n",
       " ('project involving pa', 0.37796447300922725),\n",
       " ('measure value new', 0.37796447300922725),\n",
       " ('value new product', 0.37796447300922725),\n",
       " ('explain measure value', 0.37796447300922725),\n",
       " ('describe project involving', 0.37796447300922725),\n",
       " ('machine learning algorithm', 0.35703182941751876),\n",
       " ('performance machine learning', 0.35703182941751876),\n",
       " ('database query would', 0.35703182941751876),\n",
       " ('evaluate performance machine', 0.35703182941751876),\n",
       " ('query would evaluate', 0.35703182941751876),\n",
       " ('optimize database query', 0.35703182941751876),\n",
       " ('would optimize database', 0.35703182941751876),\n",
       " ('random number generator', 0.3570318294175187),\n",
       " ('iid draws distribution', 0.3570318294175187),\n",
       " ('access random number', 0.3570318294175187),\n",
       " ('distribution access random', 0.3570318294175187),\n",
       " ('code generate iid', 0.3570318294175187),\n",
       " ('generate iid draws', 0.3570318294175187),\n",
       " ('draws distribution access', 0.3570318294175187),\n",
       " ('experiment test effectiveness', 0.35355339059327373),\n",
       " ('test effectiveness drug', 0.35355339059327373),\n",
       " ('groups people testing', 0.35355339059327373),\n",
       " ('testing drugs would', 0.35355339059327373),\n",
       " ('would design experiment', 0.35355339059327373),\n",
       " ('drugs would design', 0.35355339059327373),\n",
       " ('people testing drugs', 0.35355339059327373),\n",
       " ('design experiment test', 0.35355339059327373),\n",
       " ('given coin tosses', 0.3333333333333333),\n",
       " ('note pad write', 0.3333333333333333),\n",
       " ('last use coding', 0.3333333333333333),\n",
       " ('large teams direction', 0.3333333333333333),\n",
       " ('tosses fair coin', 0.3333333333333333),\n",
       " ('first last use', 0.3333333333333333),\n",
       " ('like work small', 0.3333333333333333),\n",
       " ('see career moving', 0.3333333333333333),\n",
       " ('teams direction see', 0.3333333333333333),\n",
       " ('teams large teams', 0.3333333333333333),\n",
       " ('inference one coding', 0.3333333333333333),\n",
       " ('statistics one question', 0.3333333333333333),\n",
       " ('one question causal', 0.3333333333333333),\n",
       " ('one coding question', 0.3333333333333333),\n",
       " ('probability coin results', 0.3333333333333333),\n",
       " ('pad write codes', 0.3333333333333333),\n",
       " ('result heads probability', 0.3333333333333333),\n",
       " ('heads probability coin', 0.3333333333333333),\n",
       " ('one question computational', 0.3333333333333333),\n",
       " ('would like work', 0.3333333333333333),\n",
       " ('small teams large', 0.3333333333333333),\n",
       " ('compare first last', 0.3333333333333333),\n",
       " ('fair coin result', 0.3333333333333333),\n",
       " ('use coding note', 0.3333333333333333),\n",
       " ('data compare first', 0.3333333333333333),\n",
       " ('question computational statistics', 0.3333333333333333),\n",
       " ('computational statistics one', 0.3333333333333333),\n",
       " ('columns data compare', 0.3333333333333333),\n",
       " ('coin tosses fair', 0.3333333333333333),\n",
       " ('coin results head', 0.3333333333333333),\n",
       " ('coin result heads', 0.3333333333333333),\n",
       " ('work small teams', 0.3333333333333333),\n",
       " ('coding note pad', 0.3333333333333333),\n",
       " ('question causal inference', 0.3333333333333333),\n",
       " ('causal inference one', 0.3333333333333333),\n",
       " ('direction see career', 0.3333333333333333),\n",
       " ('clusters find common', 0.31622776601683794),\n",
       " ('separate different clusters', 0.31622776601683794),\n",
       " ('wanted change would', 0.31622776601683794),\n",
       " ('use data science', 0.31622776601683794),\n",
       " ('science give recommendations', 0.31622776601683794),\n",
       " ('data science give', 0.31622776601683794),\n",
       " ('find common friends', 0.31622776601683794),\n",
       " ('design algorithm separate', 0.31622776601683794),\n",
       " ('analysis chart design', 0.31622776601683794),\n",
       " ('team wanted change', 0.31622776601683794),\n",
       " ('common friends friends', 0.31622776601683794),\n",
       " ('give recommendations team', 0.31622776601683794),\n",
       " ('would use data', 0.31622776601683794),\n",
       " ('algorithm separate different', 0.31622776601683794),\n",
       " ('product feature team', 0.31622776601683794),\n",
       " ('chart design algorithm', 0.31622776601683794),\n",
       " ('friends friends python', 0.31622776601683794),\n",
       " ('different clusters find', 0.31622776601683794),\n",
       " ('change would use', 0.31622776601683794),\n",
       " ('feature team wanted', 0.31622776601683794),\n",
       " ('random probability guess', 0.31539387336185454),\n",
       " ('take one card', 0.31539387336185454),\n",
       " ('card random probability', 0.31539387336185454),\n",
       " ('one card random', 0.31539387336185454),\n",
       " ('deck take one', 0.31539387336185454),\n",
       " ('probability guess right', 0.31539387336185454),\n",
       " ('would make inference', 0.3015113445777636),\n",
       " ('inference data two', 0.3015113445777636),\n",
       " ('suggestions research project', 0.3015113445777636),\n",
       " ('two ad campaigns', 0.3015113445777636),\n",
       " ('rows columns dataset', 0.3015113445777636),\n",
       " ('dataset pseudo email', 0.3015113445777636),\n",
       " ('data two ad', 0.3015113445777636),\n",
       " ('bias would make', 0.3015113445777636),\n",
       " ('make inference data', 0.3015113445777636),\n",
       " ('would remove bias', 0.3015113445777636),\n",
       " ('ab tetsing question', 0.3015113445777636),\n",
       " ('columns dataset pseudo', 0.3015113445777636),\n",
       " ('college asking suggestions', 0.3015113445777636),\n",
       " ('coding multiply aij', 0.3015113445777636),\n",
       " ('multiply aij rows', 0.3015113445777636),\n",
       " ('remove bias would', 0.3015113445777636),\n",
       " ('asking suggestions research', 0.3015113445777636),\n",
       " ('pseudo email college', 0.3015113445777636),\n",
       " ('email college asking', 0.3015113445777636),\n",
       " ('question would remove', 0.3015113445777636),\n",
       " ('aij rows columns', 0.3015113445777636),\n",
       " ('tetsing question would', 0.3015113445777636),\n",
       " ('fibonnaci sequence analyze', 0.2773500981126146),\n",
       " ('analyze computational complexity', 0.2773500981126146),\n",
       " ('sample median write', 0.2773500981126146),\n",
       " ('mean se sample', 0.2773500981126146),\n",
       " ('function return elements', 0.2773500981126146),\n",
       " ('sample mean se', 0.2773500981126146),\n",
       " ('elements fibonnaci sequence', 0.2773500981126146),\n",
       " ('se sample mean', 0.2773500981126146),\n",
       " ('sequence analyze computational', 0.2773500981126146),\n",
       " ('write function return', 0.2773500981126146),\n",
       " ('return elements fibonnaci', 0.2773500981126146),\n",
       " ('median write function', 0.2773500981126146),\n",
       " ('se sample median', 0.2773500981126146),\n",
       " ('question inperson varying', 0.27027270184151436),\n",
       " ('varying number probability', 0.27027270184151436),\n",
       " ('inperson varying number', 0.27027270184151436),\n",
       " ('probability statistics questions', 0.27027270184151436),\n",
       " ('phone screen probability', 0.27027270184151436),\n",
       " ('statistics questions along', 0.27027270184151436),\n",
       " ('number probability statistics', 0.27027270184151436),\n",
       " ('along coding language', 0.27027270184151436),\n",
       " ('coding language choice', 0.27027270184151436),\n",
       " ('questions along coding', 0.27027270184151436),\n",
       " ('screen probability question', 0.27027270184151436),\n",
       " ('coding question inperson', 0.27027270184151436),\n",
       " ('generate normal distribution', 0.26975117434099516),\n",
       " ('effect plot histogram', 0.26975117434099516),\n",
       " ('effect salary question', 0.26975117434099516),\n",
       " ('level effect salary', 0.26975117434099516),\n",
       " ('question interaction effect', 0.26975117434099516),\n",
       " ('plot histogram chart', 0.26975117434099516),\n",
       " ('education level effect', 0.26975117434099516),\n",
       " ('salary question interaction', 0.26975117434099516),\n",
       " ('chart generate normal', 0.26975117434099516),\n",
       " ('mean education level', 0.26975117434099516),\n",
       " ('histogram chart generate', 0.26975117434099516),\n",
       " ('interaction effect plot', 0.26975117434099516),\n",
       " ('error mean education', 0.26975117434099516),\n",
       " ('risky creative things', 0.2672612419124244),\n",
       " ('string parsing simple', 0.2672612419124244),\n",
       " ('creative things done', 0.2672612419124244),\n",
       " ('machine learning well', 0.2672612419124244),\n",
       " ('well general questions', 0.2672612419124244),\n",
       " ('particularly risky creative', 0.2672612419124244),\n",
       " ('learning well general', 0.2672612419124244),\n",
       " ('parsing simple machine', 0.2672612419124244),\n",
       " ('question sql joins', 0.2672612419124244),\n",
       " ('general questions particularly', 0.2672612419124244),\n",
       " ('joins string parsing', 0.2672612419124244),\n",
       " ('questions particularly risky', 0.2672612419124244),\n",
       " ('sql joins string', 0.2672612419124244),\n",
       " ('simple machine learning', 0.2672612419124244),\n",
       " ('method three different', 0.25819888974716115),\n",
       " ('regression bayesian probability', 0.25819888974716115),\n",
       " ('gaussian discrimination method', 0.25819888974716115),\n",
       " ('cases robust linear', 0.25819888974716115),\n",
       " ('three different cases', 0.25819888974716115),\n",
       " ('calculation random markov', 0.25819888974716115),\n",
       " ('markov field rnn', 0.25819888974716115),\n",
       " ('probability calculation random', 0.25819888974716115),\n",
       " ('different cases robust', 0.25819888974716115),\n",
       " ('random markov field', 0.25819888974716115),\n",
       " ('discrimination method three', 0.25819888974716115),\n",
       " ('bayesian probability calculation', 0.25819888974716115),\n",
       " ('linear regression bayesian', 0.25819888974716115),\n",
       " ('robust linear regression', 0.25819888974716115),\n",
       " ('derive gaussian discrimination', 0.25819888974716115),\n",
       " ('error median interpret', 0.2520344145693441),\n",
       " ('generate matrix follows', 0.2520344145693441),\n",
       " ('interpret standard error', 0.2520344145693441),\n",
       " ('median interpret standard', 0.2520344145693441),\n",
       " ('follows bernoulli distribution', 0.2520344145693441),\n",
       " ('bernoulli distribution python', 0.2520344145693441),\n",
       " ('element matrix sum', 0.2520344145693441),\n",
       " ('python divide element', 0.2520344145693441),\n",
       " ('mean generate matrix', 0.2520344145693441),\n",
       " ('error mean generate', 0.2520344145693441),\n",
       " ('standard error median', 0.2520344145693441),\n",
       " ('matrix sum columns', 0.2520344145693441),\n",
       " ('matrix follows bernoulli', 0.2520344145693441),\n",
       " ('divide element matrix', 0.2520344145693441),\n",
       " ('distribution python divide', 0.2520344145693441),\n",
       " ('need make margin', 0.2514777325325963),\n",
       " ('many samples need', 0.2514777325325963),\n",
       " ('sample size margin', 0.2514777325325963),\n",
       " ('samples need make', 0.2514777325325963),\n",
       " ('make margin error', 0.2514777325325963),\n",
       " ('error many samples', 0.2514777325325963),\n",
       " ('margin error many', 0.2514777325325963),\n",
       " ('size margin error', 0.2514777325325963),\n",
       " ('one card red', 0.24204306306304058),\n",
       " ('card spades one', 0.24204306306304058),\n",
       " ('spades one would', 0.24204306306304058),\n",
       " ('one would ask', 0.24204306306304058),\n",
       " ('card red card', 0.24204306306304058),\n",
       " ('questions ask one', 0.24204306306304058),\n",
       " ('ask one card', 0.24204306306304058),\n",
       " ('give two questions', 0.24204306306304058),\n",
       " ('right give two', 0.24204306306304058),\n",
       " ('red card spades', 0.24204306306304058),\n",
       " ('guess right give', 0.24204306306304058),\n",
       " ('two questions ask', 0.24204306306304058),\n",
       " ('known clustering project', 0.23691830246379086),\n",
       " ('regression confidence intervals', 0.23691830246379086),\n",
       " ('correlated effect coefficients', 0.23691830246379086),\n",
       " ('using gaussian mixture', 0.23691830246379086),\n",
       " ('use feature selection', 0.23691830246379086),\n",
       " ('evaluate performance model', 0.23691830246379086),\n",
       " ('logistic regression confidence', 0.23691830246379086),\n",
       " ('difference kmean em', 0.23691830246379086),\n",
       " ('mixture model know', 0.23691830246379086),\n",
       " ('effect coefficients logistic', 0.23691830246379086),\n",
       " ('two predictors highly', 0.23691830246379086),\n",
       " ('labels known clustering', 0.23691830246379086),\n",
       " ('predictors highly correlated', 0.23691830246379086),\n",
       " ('highly correlated effect', 0.23691830246379086),\n",
       " ('model know applicable', 0.23691830246379086),\n",
       " ('confidence intervals coefficients', 0.23691830246379086),\n",
       " ('coefficients logistic regression', 0.23691830246379086),\n",
       " ('questions prepare good', 0.22941573387056183),\n",
       " ('prepare good examples', 0.22941573387056183),\n",
       " ('print next problem', 0.22941573387056183),\n",
       " ('prepare gca business', 0.22941573387056183),\n",
       " ('regression testing training', 0.22941573387056183),\n",
       " ('problem drawing histogram', 0.22941573387056183),\n",
       " ('interviewer asked regression', 0.22941573387056183),\n",
       " ('good examples situations', 0.22941573387056183),\n",
       " ('basic behavior interview', 0.22941573387056183),\n",
       " ('interview questions prepare', 0.22941573387056183),\n",
       " ('training interviewer asked', 0.22941573387056183),\n",
       " ('interviewer asked code', 0.22941573387056183),\n",
       " ('behavior interview questions', 0.22941573387056183),\n",
       " ('asked regression testing', 0.22941573387056183),\n",
       " ('mle ci hypothesis', 0.22941573387056183),\n",
       " ('know cold prepare', 0.22941573387056183),\n",
       " ('interview interviewer asked', 0.22941573387056183),\n",
       " ('meets interview interviewer', 0.22941573387056183),\n",
       " ('studies write basic', 0.22941573387056183),\n",
       " ('used google docs', 0.22941573387056183),\n",
       " ('asked code sorting', 0.22941573387056183),\n",
       " ('basic mle ci', 0.22941573387056183),\n",
       " ('google docs google', 0.22941573387056183),\n",
       " ('docs google meets', 0.22941573387056183),\n",
       " ('write basic behavior', 0.22941573387056183),\n",
       " ('ci hypothesis testing', 0.22941573387056183),\n",
       " ('gca business case', 0.22941573387056183),\n",
       " ('cold prepare gca', 0.22941573387056183),\n",
       " ('testing training interviewer', 0.22941573387056183),\n",
       " ('hypothesis testing know', 0.22941573387056183),\n",
       " ('business case studies', 0.22941573387056183),\n",
       " ('case studies write', 0.22941573387056183),\n",
       " ('google meets interview', 0.22941573387056183),\n",
       " ('next problem drawing', 0.22941573387056183),\n",
       " ('testing know cold', 0.22941573387056183),\n",
       " ('numbers print next', 0.22941573387056183),\n",
       " ('sorting numbers print', 0.22941573387056183),\n",
       " ('code sorting numbers', 0.22941573387056183),\n",
       " ('accurate aware interviewers', 0.18569533817705186),\n",
       " ('ask similar questions', 0.18569533817705186),\n",
       " ('looking different behaviors', 0.18569533817705186),\n",
       " ('purely mathematical one', 0.18569533817705186),\n",
       " ('additionally ready talk', 0.18569533817705186),\n",
       " ('guide recruiter sends', 0.18569533817705186),\n",
       " ('practical answer vs', 0.18569533817705186),\n",
       " ('interviewers often ask', 0.18569533817705186),\n",
       " ('talk past work', 0.18569533817705186),\n",
       " ('eg practical answer', 0.18569533817705186),\n",
       " ('aware interviewers often', 0.18569533817705186),\n",
       " ('mathematical one additionally', 0.18569533817705186),\n",
       " ('different behaviors eg', 0.18569533817705186),\n",
       " ('answer vs purely', 0.18569533817705186),\n",
       " ('nda guide recruiter', 0.18569533817705186),\n",
       " ('one additionally ready', 0.18569533817705186),\n",
       " ('behaviors eg practical', 0.18569533817705186),\n",
       " ('modules looking different', 0.18569533817705186),\n",
       " ('quite accurate aware', 0.18569533817705186),\n",
       " ('ready talk past', 0.18569533817705186),\n",
       " ('vs purely mathematical', 0.18569533817705186),\n",
       " ('past work experience', 0.18569533817705186),\n",
       " ('different modules looking', 0.18569533817705186),\n",
       " ('questions different modules', 0.18569533817705186),\n",
       " ('signed nda guide', 0.18569533817705186),\n",
       " ('sends quite accurate', 0.18569533817705186),\n",
       " ('often ask similar', 0.18569533817705186),\n",
       " ('similar questions different', 0.18569533817705186),\n",
       " ('recruiter sends quite', 0.18569533817705186),\n",
       " ('testing reliable test', 0.17250640036759934),\n",
       " ('reliable test coding', 0.17250640036759934),\n",
       " ('generate sample normal', 0.17250640036759934),\n",
       " ('coding question write', 0.17250640036759934),\n",
       " ('whether mu zero', 0.17250640036759934),\n",
       " ('decides whether mu', 0.17250640036759934),\n",
       " ('function generate sample', 0.17250640036759934),\n",
       " ('sample normal distribution', 0.17250640036759934),\n",
       " ('draw normal distribution', 0.17250640036759934),\n",
       " ('deviation decides whether', 0.17250640036759934),\n",
       " ('distribution mu standard', 0.17250640036759934),\n",
       " ('use mean medium', 0.17250640036759934),\n",
       " ('error draw normal', 0.17250640036759934),\n",
       " ('question write function', 0.17250640036759934),\n",
       " ('distribution plot histogram', 0.17250640036759934),\n",
       " ('zero hypothesis testing', 0.17250640036759934),\n",
       " ('hypothesis testing reliable', 0.17250640036759934),\n",
       " ('normal distribution mu', 0.17250640036759934),\n",
       " ('mu standard deviation', 0.17250640036759934),\n",
       " ('mu zero hypothesis', 0.17250640036759934),\n",
       " ('write function generate', 0.17250640036759934),\n",
       " ('margin error draw', 0.17250640036759934),\n",
       " ('test coding question', 0.17250640036759934),\n",
       " ('mean medium sample', 0.17250640036759934),\n",
       " ('medium sample size', 0.17250640036759934),\n",
       " ('standard deviation decides', 0.17250640036759934),\n",
       " ('number overall signals', 0.1690308509457035),\n",
       " ('better way estimate', 0.1647446975872474),\n",
       " ('effect design better', 0.1647446975872474),\n",
       " ('data argue would', 0.1647446975872474),\n",
       " ('data running mc', 0.1647446975872474),\n",
       " ('confidence intervals sample', 0.1647446975872474),\n",
       " ('probability questions confidence', 0.1647446975872474),\n",
       " ('questions confidence intervals', 0.1647446975872474),\n",
       " ('running mc simulations', 0.1647446975872474),\n",
       " ('problem data argue', 0.1647446975872474),\n",
       " ('longer gave problem', 0.1647446975872474),\n",
       " ('argue would estimate', 0.1647446975872474),\n",
       " ('questions longer gave', 0.1647446975872474),\n",
       " ('questions manipulating data', 0.1647446975872474),\n",
       " ('nda cant give', 0.1647446975872474),\n",
       " ('way estimate also', 0.1647446975872474),\n",
       " ('details first interview', 0.1647446975872474),\n",
       " ('manipulating data running', 0.1647446975872474),\n",
       " ('estimate also basic', 0.1647446975872474),\n",
       " ('intervals sample size', 0.1647446975872474),\n",
       " ('interview essentially typical', 0.1647446975872474),\n",
       " ('testing questions longer', 0.1647446975872474),\n",
       " ('cant give details', 0.1647446975872474),\n",
       " ('give details first', 0.1647446975872474),\n",
       " ('hypothesis testing questions', 0.1647446975872474),\n",
       " ('gave problem data', 0.1647446975872474),\n",
       " ('would estimate effect', 0.1647446975872474),\n",
       " ('sample size hypothesis', 0.1647446975872474),\n",
       " ('size hypothesis testing', 0.1647446975872474),\n",
       " ('essentially typical probability', 0.1647446975872474),\n",
       " ('design better way', 0.1647446975872474),\n",
       " ('also basic coding', 0.1647446975872474),\n",
       " ('first interview essentially', 0.1647446975872474),\n",
       " ('coding questions manipulating', 0.1647446975872474),\n",
       " ('basic coding questions', 0.1647446975872474),\n",
       " ('typical probability questions', 0.1647446975872474),\n",
       " ('estimate effect design', 0.1647446975872474),\n",
       " ('decided using gaussian', 0.1566666740543838),\n",
       " ('rank index forgot', 0.1566666740543838),\n",
       " ('clustering project evaluate', 0.1566666740543838),\n",
       " ('applicable normal distribution', 0.1566666740543838),\n",
       " ('coefficients mean gaussian', 0.1566666740543838),\n",
       " ('normal distribution labels', 0.1566666740543838),\n",
       " ('distribution labels known', 0.1566666740543838),\n",
       " ('model project use', 0.1566666740543838),\n",
       " ('em decided using', 0.1566666740543838),\n",
       " ('adjusted rank index', 0.1566666740543838),\n",
       " ('index forgot defined', 0.1566666740543838),\n",
       " ('project evaluate performance', 0.1566666740543838),\n",
       " ('project use adjusted', 0.1566666740543838),\n",
       " ('intervals coefficients mean', 0.1566666740543838),\n",
       " ('kmean em decided', 0.1566666740543838),\n",
       " ('feature selection two', 0.1566666740543838),\n",
       " ('model difference kmean', 0.1566666740543838),\n",
       " ('use adjusted rank', 0.1566666740543838),\n",
       " ('know applicable normal', 0.1566666740543838),\n",
       " ('selection two predictors', 0.1566666740543838),\n",
       " ('performance model project', 0.1566666740543838),\n",
       " ('mean gaussian mixture', 0.1566666740543838),\n",
       " ('mixture model difference', 0.1566666740543838),\n",
       " ('statistics situation would', 0.10108524699495136),\n",
       " ('uniform distributions mean', 0.10108524699495136),\n",
       " ('see increase one', 0.10108524699495136),\n",
       " ('right explain probability', 0.10108524699495136),\n",
       " ('two product campaigns', 0.10108524699495136),\n",
       " ('selection solution two', 0.10108524699495136),\n",
       " ('standard deviation probability', 0.10108524699495136),\n",
       " ('statistical probability deck', 0.10108524699495136),\n",
       " ('solution four people', 0.10108524699495136),\n",
       " ('solution machine learning', 0.10108524699495136),\n",
       " ('solution given data', 0.10108524699495136),\n",
       " ('solution two predictors', 0.10108524699495136),\n",
       " ('mean standard deviation', 0.10108524699495136),\n",
       " ('intervals coefficients difference', 0.10108524699495136),\n",
       " ('probability person gets', 0.10108524699495136),\n",
       " ('coin fair solution', 0.10108524699495136),\n",
       " ('four floors building', 0.10108524699495136),\n",
       " ('machine learning labels', 0.10108524699495136),\n",
       " ('floors building probability', 0.10108524699495136),\n",
       " ('person gets different', 0.10108524699495136),\n",
       " ('performance model use', 0.10108524699495136),\n",
       " ('margin error assumption', 0.10108524699495136),\n",
       " ('people elevator four', 0.10108524699495136),\n",
       " ('mean median sample', 0.10108524699495136),\n",
       " ('median sample size', 0.10108524699495136),\n",
       " ('floor make unfair', 0.10108524699495136),\n",
       " ('deviation probability solution', 0.10108524699495136),\n",
       " ('feature selection solution', 0.10108524699495136),\n",
       " ('different floor make', 0.10108524699495136),\n",
       " ('fair solution machine', 0.10108524699495136),\n",
       " ('model use feature', 0.10108524699495136),\n",
       " ('one product statistical', 0.10108524699495136),\n",
       " ('normal apply given', 0.10108524699495136),\n",
       " ('error assumption error', 0.10108524699495136),\n",
       " ('em using gaussian', 0.10108524699495136),\n",
       " ('elevator four floors', 0.10108524699495136),\n",
       " ('probability deck take', 0.10108524699495136),\n",
       " ('data two product', 0.10108524699495136),\n",
       " ('probability solution four', 0.10108524699495136),\n",
       " ('campaigns could ab', 0.10108524699495136),\n",
       " ('guess right explain', 0.10108524699495136),\n",
       " ('regression solution given', 0.10108524699495136),\n",
       " ('given uniform distributions', 0.10108524699495136),\n",
       " ('apply given uniform', 0.10108524699495136),\n",
       " ('increase one product', 0.10108524699495136),\n",
       " ('given data two', 0.10108524699495136),\n",
       " ('gets different floor', 0.10108524699495136),\n",
       " ('linear regression solution', 0.10108524699495136),\n",
       " ('general statistics situation', 0.10108524699495136),\n",
       " ('kmean em using', 0.10108524699495136),\n",
       " ('building probability person', 0.10108524699495136),\n",
       " ('four people elevator', 0.10108524699495136),\n",
       " ('coefficients difference kmean', 0.10108524699495136),\n",
       " ('product campaigns could', 0.10108524699495136),\n",
       " ('product statistical probability', 0.10108524699495136),\n",
       " ('clustering project would', 0.10108524699495136),\n",
       " ('distributions mean standard', 0.10108524699495136),\n",
       " ('project would evaluate', 0.10108524699495136),\n",
       " ('learning labels known', 0.10108524699495136),\n",
       " ('follows binomial distribution', 0.08451542547285175),\n",
       " ('follows note might', 0.08451542547285175),\n",
       " ('distribution pvalue expected', 0.08451542547285175),\n",
       " ('given number overall', 0.08451542547285175),\n",
       " ('experience hence perform', 0.08451542547285175),\n",
       " ('understand user experience', 0.08451542547285175),\n",
       " ('follows roughly bell', 0.08451542547285175),\n",
       " ('understand whether dismiss', 0.08451542547285175),\n",
       " ('estimate variance numerator', 0.08451542547285175),\n",
       " ('error program google', 0.08451542547285175),\n",
       " ('upper infinity resultpval', 0.08451542547285175),\n",
       " ('google maps team', 0.08451542547285175),\n",
       " ('testingstatistics numerator denominator', 0.08451542547285175),\n",
       " ('experience button app', 0.08451542547285175),\n",
       " ('values values distribution', 0.08451542547285175),\n",
       " ('distribution numsignalcontrol roundrandomnormal', 0.08451542547285175),\n",
       " ('use normal approximation', 0.08451542547285175),\n",
       " ('denominator calculate value', 0.08451542547285175),\n",
       " ('define numerator denominator', 0.08451542547285175),\n",
       " ('words values values', 0.08451542547285175),\n",
       " ('comparison scenario simulation', 0.08451542547285175),\n",
       " ('worse user experience', 0.08451542547285175),\n",
       " ('code follows note', 0.08451542547285175),\n",
       " ('click dismiss ignore', 0.08451542547285175),\n",
       " ('calculate value append', 0.08451542547285175),\n",
       " ('button click dismiss', 0.08451542547285175),\n",
       " ('button app hypothesis', 0.08451542547285175),\n",
       " ('binomial distribution numnegativesignalcontrol', 0.08451542547285175),\n",
       " ('bell shaped distribution', 0.08451542547285175),\n",
       " ('approximation estimate variance', 0.08451542547285175),\n",
       " ('appendresultpval pvalue plothistogramresultpval', 0.08451542547285175),\n",
       " ('append result vector', 0.08451542547285175),\n",
       " ('app hypothesis higher', 0.08451542547285175),\n",
       " ('abstestingstatistics upper infinity', 0.08451542547285175),\n",
       " ('denominator often later', 0.08451542547285175),\n",
       " ('whether dismiss rate', 0.08451542547285175),\n",
       " ('denominator sqrt phattreatmentphattreatmentnumsignaltreatment',\n",
       "  0.08451542547285175),\n",
       " ('values distribution pvalue', 0.08451542547285175),\n",
       " ('distribution numnegativesignalcontrol randombinomialnumsignalcontrol',\n",
       "  0.08451542547285175),\n",
       " ('dismiss rate worse', 0.08451542547285175),\n",
       " ('user experience button', 0.08451542547285175),\n",
       " ('user experience hence', 0.08451542547285175),\n",
       " ('dismiss rate reasonable', 0.08451542547285175),\n",
       " ('value append result', 0.08451542547285175),\n",
       " ('dismiss pseudo code', 0.08451542547285175),\n",
       " ('help understand user', 0.08451542547285175),\n",
       " ('denominator test statistics', 0.08451542547285175),\n",
       " ('dismiss ignore negative', 0.08451542547285175),\n",
       " ('variance numerator phatcontrol', 0.08451542547285175),\n",
       " ('discussions resultpval replica', 0.08451542547285175),\n",
       " ('vector pvalue stdnormalareaundercurve', 0.08451542547285175),\n",
       " ('diagnose error program', 0.08451542547285175),\n",
       " ('denominator use normal', 0.08451542547285175),\n",
       " ('wants understand whether', 0.08451542547285175),\n",
       " ('test statistics idea', 0.08451542547285175),\n",
       " ('result vector pvalue', 0.08451542547285175),\n",
       " ('hence perform simulation', 0.08451542547285175),\n",
       " ('higher dismiss rate', 0.08451542547285175),\n",
       " ('phattreatment phatcontrol denominator', 0.08451542547285175),\n",
       " ('phattreatment numnegativesignaltreatment numsignaltreatment',\n",
       "  0.08451542547285175),\n",
       " ('phatcontrol phatcontrol numsignalcontrol', 0.08451542547285175),\n",
       " ('phatcontrol numsignalcontrol testingstatistics', 0.08451542547285175),\n",
       " ('phatcontrol numnegativesignalcontrol numsignalcontrol',\n",
       "  0.08451542547285175),\n",
       " ('phatcontrol denominator sqrt', 0.08451542547285175),\n",
       " ('perform simulation aa', 0.08451542547285175),\n",
       " ('overall signals number', 0.08451542547285175),\n",
       " ('shaped distribution numsignalcontrol', 0.08451542547285175),\n",
       " ('signal dismiss pseudo', 0.08451542547285175),\n",
       " ('signal interactions button', 0.08451542547285175),\n",
       " ('signals follows binomial', 0.08451542547285175),\n",
       " ('signals follows roughly', 0.08451542547285175),\n",
       " ('signals number negative', 0.08451542547285175),\n",
       " ('overall signals follows', 0.08451542547285175),\n",
       " ('often later discussions', 0.08451542547285175),\n",
       " ('numsignaltreatment roundrandomnormal std', 0.08451542547285175),\n",
       " ('phattreatmentphattreatmentnumsignaltreatment phatcontrol phatcontrol',\n",
       "  0.08451542547285175),\n",
       " ('plothistogramresultpval histogram pvalues', 0.08451542547285175),\n",
       " ('scenario simulation signal', 0.08451542547285175),\n",
       " ('roughly bell shaped', 0.08451542547285175),\n",
       " ('resultpval replica number', 0.08451542547285175),\n",
       " ('replica number overall', 0.08451542547285175),\n",
       " ('refer numerator denominator', 0.08451542547285175),\n",
       " ('reasonable metric help', 0.08451542547285175),\n",
       " ('right words values', 0.08451542547285175),\n",
       " ('rate worse user', 0.08451542547285175),\n",
       " ('rate reasonable metric', 0.08451542547285175),\n",
       " ('roundrandomnormal std given', 0.08451542547285175),\n",
       " ('program google maps', 0.08451542547285175),\n",
       " ('roundrandomnormal std numsignaltreatment', 0.08451542547285175),\n",
       " ('randombinomialnumsignaltreatment define numerator', 0.08451542547285175),\n",
       " ('randombinomialnumsignalcontrol numnegativesignaltreatment randombinomialnumsignaltreatment',\n",
       "  0.08451542547285175),\n",
       " ('pvalues skewed right', 0.08451542547285175),\n",
       " ('pvalue stdnormalareaundercurve lower', 0.08451542547285175),\n",
       " ('pvalue plothistogramresultpval histogram', 0.08451542547285175),\n",
       " ('pseudo code follows', 0.08451542547285175),\n",
       " ('numsignaltreatment numerator phattreatment', 0.08451542547285175),\n",
       " ('simulation aa comparison', 0.08451542547285175),\n",
       " ('simulation signal interactions', 0.08451542547285175),\n",
       " ('later discussions resultpval', 0.08451542547285175),\n",
       " ('metric help understand', 0.08451542547285175),\n",
       " ('statistics idea denominator', 0.08451542547285175),\n",
       " ('maps team wants', 0.08451542547285175),\n",
       " ('lower abstestingstatistics upper', 0.08451542547285175),\n",
       " ('std given number', 0.08451542547285175),\n",
       " ('std numsignaltreatment roundrandomnormal', 0.08451542547285175),\n",
       " ('stdnormalareaundercurve lower abstestingstatistics', 0.08451542547285175),\n",
       " ('resultpval appendresultpval pvalue', 0.08451542547285175),\n",
       " ('need diagnose error', 0.08451542547285175),\n",
       " ('interactions button click', 0.08451542547285175),\n",
       " ('team wants understand', 0.08451542547285175),\n",
       " ('infinity resultpval appendresultpval', 0.08451542547285175),\n",
       " ('ignore negative signal', 0.08451542547285175),\n",
       " ('idea denominator use', 0.08451542547285175),\n",
       " ('hypothesis higher dismiss', 0.08451542547285175),\n",
       " ('histogram pvalues skewed', 0.08451542547285175),\n",
       " ('might refer numerator', 0.08451542547285175),\n",
       " ('negative signal dismiss', 0.08451542547285175),\n",
       " ('numsignalcontrol testingstatistics numerator', 0.08451542547285175),\n",
       " ('numerator phattreatment phatcontrol', 0.08451542547285175),\n",
       " ('numsignalcontrol roundrandomnormal std', 0.08451542547285175),\n",
       " ('numsignalcontrol phattreatment numnegativesignaltreatment',\n",
       "  0.08451542547285175),\n",
       " ('skewed right words', 0.08451542547285175),\n",
       " ('numnegativesignaltreatment randombinomialnumsignaltreatment define',\n",
       "  0.08451542547285175),\n",
       " ('numnegativesignaltreatment numsignaltreatment numerator',\n",
       "  0.08451542547285175),\n",
       " ('numnegativesignalcontrol randombinomialnumsignalcontrol numnegativesignaltreatment',\n",
       "  0.08451542547285175),\n",
       " ('numnegativesignalcontrol numsignalcontrol phattreatment',\n",
       "  0.08451542547285175),\n",
       " ('numerator phatcontrol numnegativesignalcontrol', 0.08451542547285175),\n",
       " ('negative signals follows', 0.08451542547285175),\n",
       " ('numerator denominator test', 0.08451542547285175),\n",
       " ('numerator denominator often', 0.08451542547285175),\n",
       " ('numerator denominator calculate', 0.08451542547285175),\n",
       " ('number negative signals', 0.08451542547285175),\n",
       " ('note might refer', 0.08451542547285175),\n",
       " ('normal approximation estimate', 0.08451542547285175),\n",
       " ('sqrt phattreatmentphattreatmentnumsignaltreatment phatcontrol',\n",
       "  0.08451542547285175),\n",
       " ('aa comparison scenario', 0.08451542547285175)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_vectorizer = TfidfVectorizer(ngram_range=(3,3), min_df=0.001, max_df = 0.75)\n",
    "google_vectorized_questions = pd.DataFrame(google_vectorizer.fit_transform(google_interview_questions_df['Interview Questions']).toarray(), columns = google_vectorizer.get_feature_names_out())\n",
    "google_vectorized_questions.loc['Total'] = google_vectorized_questions.sum(numeric_only=True, axis=0)\n",
    "google_vectorized_questions = google_vectorized_questions.sort_values(google_vectorized_questions.last_valid_index(), axis=1, ascending=False)\n",
    "google_sorted_word_list = [(col, google_vectorized_questions[col].iloc[-1]) for col in google_vectorized_questions.columns]\n",
    "google_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon TFIDF Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('explain one project', 1.357886305319185),\n",
       " ('tell time questions', 1.2322411070622041),\n",
       " ('difference bagging boosting', 1.2129655239136254),\n",
       " ('sql machine learning', 1.0182599298148625),\n",
       " ('everything sun moon', 1.0),\n",
       " ('latest invention think', 1.0),\n",
       " ('tell answer questions', 1.0),\n",
       " ('basic ml questions', 1.0),\n",
       " ('tell time failed', 1.0),\n",
       " ('standard behavioral questions', 1.0),\n",
       " ('quants logical reasoning', 1.0),\n",
       " ('na na na', 1.0),\n",
       " ('many behavior questions', 1.0),\n",
       " ('value chase study', 1.0),\n",
       " ('amazon basics engineering', 1.0),\n",
       " ('visualize multidimensional data', 1.0),\n",
       " ('convolution matrixmatrix multiplication', 1.0),\n",
       " ('difference boosting bagging', 1.0),\n",
       " ('describe project proud', 1.0),\n",
       " ('write sql python', 1.0),\n",
       " ('firstround check cv', 1.0),\n",
       " ('write code xyz', 1.0),\n",
       " ('blah blah blah', 0.857142857142857),\n",
       " ('one project delivered', 0.7341908440294345),\n",
       " ('one project cv', 0.7341908440294345),\n",
       " ('describe pervious experience', 0.7071067811865476),\n",
       " ('case study demand', 0.7071067811865476),\n",
       " ('round dsa round', 0.7071067811865476),\n",
       " ('calculate median python', 0.7071067811865476),\n",
       " ('see within next', 0.7071067811865476),\n",
       " ('specific problems meet', 0.7071067811865476),\n",
       " ('sql queries demand', 0.7071067811865476),\n",
       " ('difference linear regression', 0.7071067811865476),\n",
       " ('first round dsa', 0.7071067811865476),\n",
       " ('study demand forecasting', 0.7071067811865476),\n",
       " ('easy questions dnn', 0.7071067811865476),\n",
       " ('basic ml knowledge', 0.7071067811865476),\n",
       " ('team remote operations', 0.7071067811865476),\n",
       " ('explain detail cnn', 0.7071067811865476),\n",
       " ('tell basic ml', 0.7071067811865476),\n",
       " ('challenge project work', 0.7071067811865476),\n",
       " ('problems meet project', 0.7071067811865476),\n",
       " ('pvalue tell past', 0.7071067811865476),\n",
       " ('coding challenge project', 0.7071067811865476),\n",
       " ('interpret coefficient logistics', 0.7071067811865476),\n",
       " ('key interest show', 0.7071067811865476),\n",
       " ('describe background interested', 0.7071067811865476),\n",
       " ('lead team remote', 0.7071067811865476),\n",
       " ('linear regression etc', 0.7071067811865476),\n",
       " ('interest show interest', 0.7071067811865476),\n",
       " ('linear regression ttest', 0.7071067811865476),\n",
       " ('inspect missing data', 0.7071067811865476),\n",
       " ('detail cnn works', 0.7071067811865476),\n",
       " ('highlevel question areas', 0.7071067811865476),\n",
       " ('missing data important', 0.7071067811865476),\n",
       " ('tell past project', 0.7071067811865476),\n",
       " ('past projects worked', 0.7071067811865476),\n",
       " ('pervious experience employers', 0.7071067811865476),\n",
       " ('presentation easy questions', 0.7071067811865476),\n",
       " ('coefficient logistics regression', 0.7071067811865476),\n",
       " ('describe past projects', 0.7071067811865476),\n",
       " ('background interested role', 0.7071067811865476),\n",
       " ('code calculate median', 0.7071067811865476),\n",
       " ('tell time agree', 0.7071067811865476),\n",
       " ('assumption linear regression', 0.7071067811865476),\n",
       " ('tell time deliver', 0.7071067811865476),\n",
       " ('wrote highlevel question', 0.7071067811865476),\n",
       " ('time agree advisor', 0.7071067811865476),\n",
       " ('write sql queries', 0.7071067811865476),\n",
       " ('time deliver result', 0.7071067811865476),\n",
       " ('within next years', 0.7071067811865476),\n",
       " ('statistics programming sql', 0.5918130633271818),\n",
       " ('programming sql machine', 0.5918130633271818),\n",
       " ('would situation directly', 0.5773502691896257),\n",
       " ('situation directly relevant', 0.5773502691896257),\n",
       " ('data manipulation using', 0.5773502691896257),\n",
       " ('probability explain machine', 0.5773502691896257),\n",
       " ('approach reverse linked', 0.5773502691896257),\n",
       " ('would measure impact', 0.5773502691896257),\n",
       " ('sql basic lp', 0.5773502691896257),\n",
       " ('sql python java', 0.5773502691896257),\n",
       " ('diffferent opinion colleagues', 0.5773502691896257),\n",
       " ('forest model implementation', 0.5773502691896257),\n",
       " ('machine learning past', 0.5773502691896257),\n",
       " ('math behind principal', 0.5773502691896257),\n",
       " ('machine learning models', 0.5773502691896257),\n",
       " ('science project detail', 0.5773502691896257),\n",
       " ('impact business initiative', 0.5773502691896257),\n",
       " ('using python pandas', 0.5773502691896257),\n",
       " ('data science project', 0.5773502691896257),\n",
       " ('data science questions', 0.5773502691896257),\n",
       " ('reverse linked list', 0.5773502691896257),\n",
       " ('lp solutions assumption', 0.5773502691896257),\n",
       " ('python java based', 0.5773502691896257),\n",
       " ('time diffferent opinion', 0.5773502691896257),\n",
       " ('java based programs', 0.5773502691896257),\n",
       " ('describe data science', 0.5773502691896257),\n",
       " ('learning past projects', 0.5773502691896257),\n",
       " ('random forest model', 0.5773502691896257),\n",
       " ('describe time diffferent', 0.5773502691896257),\n",
       " ('manipulation using python', 0.5773502691896257),\n",
       " ('basics machine learning', 0.5773502691896257),\n",
       " ('basic lp solutions', 0.5773502691896257),\n",
       " ('ml data science', 0.5773502691896257),\n",
       " ('written behaviour technical', 0.5773502691896257),\n",
       " ('educational background applied', 0.5773502691896257),\n",
       " ('basic ml data', 0.5773502691896257),\n",
       " ('measure impact business', 0.5773502691896257),\n",
       " ('applied quantitative problem', 0.5773502691896257),\n",
       " ('principal component analysis', 0.5773502691896257),\n",
       " ('model implementation code', 0.5773502691896257),\n",
       " ('explain machine learning', 0.5773502691896257),\n",
       " ('technical coding questions', 0.5773502691896257),\n",
       " ('behaviour technical coding', 0.5773502691896257),\n",
       " ('tell approach reverse', 0.5773502691896257),\n",
       " ('background applied quantitative', 0.5773502691896257),\n",
       " ('behind principal component', 0.5773502691896257),\n",
       " ('directly relevant principle', 0.5773502691896257),\n",
       " ('many questions regarding', 0.5345224838248488),\n",
       " ('behavior sql machine', 0.5093058070577674),\n",
       " ('learning excel tabelu', 0.5093058070577674),\n",
       " ('machine learning excel', 0.5093058070577674),\n",
       " ('machine learning stats', 0.5),\n",
       " ('você vê para', 0.5),\n",
       " ('question deep learning', 0.5),\n",
       " ('learning one algorithm', 0.5),\n",
       " ('query table using', 0.5),\n",
       " ('que você vê', 0.5),\n",
       " ('challenging situation faced', 0.5),\n",
       " ('unsupervised learning algorithms', 0.5),\n",
       " ('learning stats asked', 0.5),\n",
       " ('python machine learning', 0.5),\n",
       " ('one several unsupervised', 0.5),\n",
       " ('para seu futuro', 0.5),\n",
       " ('materials publicly available', 0.5),\n",
       " ('coding related string', 0.5),\n",
       " ('problems work current', 0.5),\n",
       " ('prep materials publicly', 0.5),\n",
       " ('processing treebased modeling', 0.5),\n",
       " ('using group statement', 0.5),\n",
       " ('mostly behavioral questions', 0.5),\n",
       " ('ml problems work', 0.5),\n",
       " ('model new product', 0.5),\n",
       " ('project worked successful', 0.5),\n",
       " ('deep learning one', 0.5),\n",
       " ('related string processing', 0.5),\n",
       " ('new product design', 0.5),\n",
       " ('give model new', 0.5),\n",
       " ('several unsupervised learning', 0.5),\n",
       " ('similar interview prep', 0.5),\n",
       " ('faced work handles', 0.5),\n",
       " ('situation faced work', 0.5),\n",
       " ('table using group', 0.5),\n",
       " ('got several tasks', 0.5),\n",
       " ('forest discuss pros', 0.5),\n",
       " ('explain one several', 0.5),\n",
       " ('string processing treebased', 0.5),\n",
       " ('study real supply', 0.5),\n",
       " ('successful would differently', 0.5),\n",
       " ('behavioral questions got', 0.5),\n",
       " ('discuss pros cons', 0.5),\n",
       " ('supply chain problem', 0.5),\n",
       " ('explain random forest', 0.5),\n",
       " ('write query table', 0.5),\n",
       " ('vê para seu', 0.5),\n",
       " ('worked successful would', 0.5),\n",
       " ('work current position', 0.5),\n",
       " ('describe ml problems', 0.5),\n",
       " ('interview prep materials', 0.5),\n",
       " ('one algorithm question', 0.5),\n",
       " ('case study real', 0.5),\n",
       " ('tell project worked', 0.5),\n",
       " ('questions got several', 0.5),\n",
       " ('explain challenging situation', 0.5),\n",
       " ('want give model', 0.5),\n",
       " ('real supply chain', 0.5),\n",
       " ('random forest discuss', 0.5),\n",
       " ('questions python machine', 0.5),\n",
       " ('focused amazon principles', 0.447213595499958),\n",
       " ('multivariate analysis pandas', 0.447213595499958),\n",
       " ('first fibonacci numbers', 0.447213595499958),\n",
       " ('us time hand', 0.447213595499958),\n",
       " ('conte um desafio', 0.447213595499958),\n",
       " ('knowledge data science', 0.447213595499958),\n",
       " ('displays first fibonacci', 0.447213595499958),\n",
       " ('merge operations apply', 0.447213595499958),\n",
       " ('function displays first', 0.447213595499958),\n",
       " ('desafiador que você', 0.447213595499958),\n",
       " ('hand handle difficult', 0.447213595499958),\n",
       " ('handle difficult situation', 0.447213595499958),\n",
       " ('would improve project', 0.447213595499958),\n",
       " ('data science live', 0.447213595499958),\n",
       " ('improve project time', 0.447213595499958),\n",
       " ('live coding assessment', 0.447213595499958),\n",
       " ('also questions ml', 0.447213595499958),\n",
       " ('desafio recente que', 0.447213595499958),\n",
       " ('write python function', 0.447213595499958),\n",
       " ('tell calculate score', 0.447213595499958),\n",
       " ('questions ml algorithms', 0.447213595499958),\n",
       " ('coding questions behavioral', 0.447213595499958),\n",
       " ('python function displays', 0.447213595499958),\n",
       " ('que voce enfrentou', 0.447213595499958),\n",
       " ('que você desenvolveu', 0.447213595499958),\n",
       " ('cite um projeto', 0.447213595499958),\n",
       " ('questions also questions', 0.447213595499958),\n",
       " ('questions behavioral questions', 0.447213595499958),\n",
       " ('questions focused amazon', 0.447213595499958),\n",
       " ('time hand handle', 0.447213595499958),\n",
       " ('recente que voce', 0.447213595499958),\n",
       " ('calculate score would', 0.447213595499958),\n",
       " ('science live coding', 0.447213595499958),\n",
       " ('score would improve', 0.447213595499958),\n",
       " ('breath knowledge data', 0.447213595499958),\n",
       " ('tell us time', 0.447213595499958),\n",
       " ('statistic questions also', 0.447213595499958),\n",
       " ('behavioral questions focused', 0.447213595499958),\n",
       " ('basic statistic questions', 0.447213595499958),\n",
       " ('projeto desafiador que', 0.447213595499958),\n",
       " ('operations apply functions', 0.447213595499958),\n",
       " ('um desafio recente', 0.447213595499958),\n",
       " ('um projeto desafiador', 0.447213595499958),\n",
       " ('analysis pandas merge', 0.447213595499958),\n",
       " ('pandas merge operations', 0.447213595499958),\n",
       " ('assumptions linear regression', 0.4347376691533752),\n",
       " ('records fields id', 0.41500353252886124),\n",
       " ('age table records', 0.41500353252886124),\n",
       " ('id age table', 0.41500353252886124),\n",
       " ('records two fields', 0.41500353252886124),\n",
       " ('table one million', 0.41500353252886124),\n",
       " ('table records two', 0.41500353252886124),\n",
       " ('million records fields', 0.41500353252886124),\n",
       " ('fields id age', 0.41500353252886124),\n",
       " ('two tables table', 0.41500353252886124),\n",
       " ('tables table one', 0.41500353252886124),\n",
       " ('one million records', 0.41500353252886124),\n",
       " ('write code question', 0.408248290463863),\n",
       " ('principle tech half', 0.408248290463863),\n",
       " ('aimed assessing leadership', 0.408248290463863),\n",
       " ('case logistic regression', 0.408248290463863),\n",
       " ('time analyzed set', 0.408248290463863),\n",
       " ('round behavioral question', 0.408248290463863),\n",
       " ('case study case', 0.408248290463863),\n",
       " ('ask write code', 0.408248290463863),\n",
       " ('set data found', 0.408248290463863),\n",
       " ('similar one finds', 0.408248290463863),\n",
       " ('principle half technical', 0.408248290463863),\n",
       " ('order tasks left', 0.408248290463863),\n",
       " ('half leadership principle', 0.408248290463863),\n",
       " ('sort tasks order', 0.408248290463863),\n",
       " ('google faqs machine', 0.408248290463863),\n",
       " ('found meaningful insights', 0.408248290463863),\n",
       " ('disadvantage method mention', 0.408248290463863),\n",
       " ('behavioral question aimed', 0.408248290463863),\n",
       " ('finds google faqs', 0.408248290463863),\n",
       " ('faqs machine learning', 0.408248290463863),\n",
       " ('due time limit', 0.408248290463863),\n",
       " ('easy level leet', 0.408248290463863),\n",
       " ('tasks left due', 0.408248290463863),\n",
       " ('tasks order tasks', 0.408248290463863),\n",
       " ('assessing leadership principle', 0.408248290463863),\n",
       " ('tech half leadership', 0.408248290463863),\n",
       " ('study case logistic', 0.408248290463863),\n",
       " ('analyzed set data', 0.408248290463863),\n",
       " ('left due time', 0.408248290463863),\n",
       " ('leadership principle half', 0.408248290463863),\n",
       " ('data found meaningful', 0.408248290463863),\n",
       " ('code question easy', 0.408248290463863),\n",
       " ('machine learning interviews', 0.408248290463863),\n",
       " ('every round behavioral', 0.408248290463863),\n",
       " ('level leet code', 0.408248290463863),\n",
       " ('mention case study', 0.408248290463863),\n",
       " ('question aimed assessing', 0.408248290463863),\n",
       " ('question easy level', 0.408248290463863),\n",
       " ('leadership principle tech', 0.408248290463863),\n",
       " ('one finds google', 0.408248290463863),\n",
       " ('last time analyzed', 0.408248290463863),\n",
       " ('method mention case', 0.408248290463863),\n",
       " ('given project preponed', 0.3779644730092272),\n",
       " ('ou vous avez', 0.3779644730092272),\n",
       " ('position experience data', 0.3779644730092272),\n",
       " ('deadline given project', 0.3779644730092272),\n",
       " ('une situation ou', 0.3779644730092272),\n",
       " ('avez surpassé vos', 0.3779644730092272),\n",
       " ('current position experience', 0.3779644730092272),\n",
       " ('come across scenario', 0.3779644730092272),\n",
       " ('décrivez une situation', 0.3779644730092272),\n",
       " ('across scenario deadline', 0.3779644730092272),\n",
       " ('tokenization would deal', 0.3779644730092272),\n",
       " ('surpassé vos objectifs', 0.3779644730092272),\n",
       " ('preponed deal result', 0.3779644730092272),\n",
       " ('would deal imbalanced', 0.3779644730092272),\n",
       " ('situation ou vous', 0.3779644730092272),\n",
       " ('deal imbalanced dataset', 0.3779644730092272),\n",
       " ('vous avez surpassé', 0.3779644730092272),\n",
       " ('scenario deadline given', 0.3779644730092272),\n",
       " ('project preponed deal', 0.3779644730092272),\n",
       " ('data tokenization would', 0.3779644730092272),\n",
       " ('experience data tokenization', 0.3779644730092272),\n",
       " ('take home nlp', 0.35355339059327373),\n",
       " ('leadership principle asking', 0.35355339059327373),\n",
       " ('project ab testing', 0.35355339059327373),\n",
       " ('questions leadership principle', 0.35355339059327373),\n",
       " ('type assignment tell', 0.35355339059327373),\n",
       " ('principles go project', 0.35355339059327373),\n",
       " ('tell questions leadership', 0.35355339059327373),\n",
       " ('nlp computer vision', 0.35355339059327373),\n",
       " ('principle asking include', 0.35355339059327373),\n",
       " ('ab testing detailed', 0.35355339059327373),\n",
       " ('vision kaggle type', 0.35355339059327373),\n",
       " ('machine learning model', 0.35355339059327373),\n",
       " ('sampling hypothesis testing', 0.35355339059327373),\n",
       " ('machine learning dive', 0.35355339059327373),\n",
       " ('testing design ab', 0.35355339059327373),\n",
       " ('testing detailed description', 0.35355339059327373),\n",
       " ('testing machine learning', 0.35355339059327373),\n",
       " ('go project ab', 0.35355339059327373),\n",
       " ('learning dive deep', 0.35355339059327373),\n",
       " ('leadership principles go', 0.35355339059327373),\n",
       " ('include component machine', 0.35355339059327373),\n",
       " ('home nlp computer', 0.35355339059327373),\n",
       " ('kaggle type assignment', 0.35355339059327373),\n",
       " ('ab testing design', 0.35355339059327373),\n",
       " ('description sampling hypothesis', 0.35355339059327373),\n",
       " ('ab testing machine', 0.35355339059327373),\n",
       " ('design ab testing', 0.35355339059327373),\n",
       " ('detailed description sampling', 0.35355339059327373),\n",
       " ('component machine learning', 0.35355339059327373),\n",
       " ('assignment tell time', 0.35355339059327373),\n",
       " ('asking include component', 0.35355339059327373),\n",
       " ('computer vision kaggle', 0.35355339059327373),\n",
       " ('test know worked', 0.3333333333333333),\n",
       " ('effective algorithm would', 0.3333333333333333),\n",
       " ('want find certain', 0.3333333333333333),\n",
       " ('vs regularization would', 0.3333333333333333),\n",
       " ('questions describe models', 0.3333333333333333),\n",
       " ('tables string transformations', 0.3333333333333333),\n",
       " ('question combining two', 0.3333333333333333),\n",
       " ('classification model suffers', 0.3333333333333333),\n",
       " ('transformations use language', 0.3333333333333333),\n",
       " ('use language want', 0.3333333333333333),\n",
       " ('suffers low precision', 0.3333333333333333),\n",
       " ('dropout work vs', 0.3333333333333333),\n",
       " ('know worked particular', 0.3333333333333333),\n",
       " ('find certain elements', 0.3333333333333333),\n",
       " ('array integers want', 0.3333333333333333),\n",
       " ('combining two tables', 0.3333333333333333),\n",
       " ('language want missing', 0.3333333333333333),\n",
       " ('two tables string', 0.3333333333333333),\n",
       " ('part question combining', 0.3333333333333333),\n",
       " ('certain elements effective', 0.3333333333333333),\n",
       " ('models hyperparameters tune', 0.3333333333333333),\n",
       " ('algorithm would use', 0.3333333333333333),\n",
       " ('worked particular problem', 0.3333333333333333),\n",
       " ('improve classification model', 0.3333333333333333),\n",
       " ('regularization would improve', 0.3333333333333333),\n",
       " ('elements effective algorithm', 0.3333333333333333),\n",
       " ('hyperparameters tune test', 0.3333333333333333),\n",
       " ('would use efficiency', 0.3333333333333333),\n",
       " ('integers want find', 0.3333333333333333),\n",
       " ('describe models hyperparameters', 0.3333333333333333),\n",
       " ('would improve classification', 0.3333333333333333),\n",
       " ('tune test know', 0.3333333333333333),\n",
       " ('string transformations use', 0.3333333333333333),\n",
       " ('model suffers low', 0.3333333333333333),\n",
       " ('modeling questions describe', 0.3333333333333333),\n",
       " ('work vs regularization', 0.3333333333333333),\n",
       " ('two deadlines time', 0.3162277660168379),\n",
       " ('roles within groupnot', 0.3162277660168379),\n",
       " ('incorporate rankings results', 0.3162277660168379),\n",
       " ('ill consider ds', 0.3162277660168379),\n",
       " ('certainly interested candidacy', 0.3162277660168379),\n",
       " ('different search algorithms', 0.3162277660168379),\n",
       " ('time two deadlines', 0.3162277660168379),\n",
       " ('phone screen would', 0.3162277660168379),\n",
       " ('groupnot naming group', 0.3162277660168379),\n",
       " ('screen would compare', 0.3162277660168379),\n",
       " ('search algorithms incorporate', 0.3162277660168379),\n",
       " ('time faced obstacle', 0.3162277660168379),\n",
       " ('group certainly interested', 0.3162277660168379),\n",
       " ('situation tell time', 0.3162277660168379),\n",
       " ('tell time two', 0.3162277660168379),\n",
       " ('bie roles within', 0.3162277660168379),\n",
       " ('tell time faced', 0.3162277660168379),\n",
       " ('time manage situation', 0.3162277660168379),\n",
       " ('results two different', 0.3162277660168379),\n",
       " ('two different search', 0.3162277660168379),\n",
       " ('within groupnot naming', 0.3162277660168379),\n",
       " ('consider ds bie', 0.3162277660168379),\n",
       " ('faced obstacle deadline', 0.3162277660168379),\n",
       " ('naming group certainly', 0.3162277660168379),\n",
       " ('algorithms incorporate rankings', 0.3162277660168379),\n",
       " ('deadlines time manage', 0.3162277660168379),\n",
       " ('ds bie roles', 0.3162277660168379),\n",
       " ('manage situation tell', 0.3162277660168379),\n",
       " ('would compare results', 0.3162277660168379),\n",
       " ('compare results two', 0.3162277660168379),\n",
       " ('would find every', 0.30151134457776363),\n",
       " ('python modifications string', 0.30151134457776363),\n",
       " ('given string characters', 0.30151134457776363),\n",
       " ('questions answered hour', 0.30151134457776363),\n",
       " ('modifications string second', 0.30151134457776363),\n",
       " ('characters would find', 0.30151134457776363),\n",
       " ('string characters would', 0.30151134457776363),\n",
       " ('word english language', 0.30151134457776363),\n",
       " ('ml python package', 0.30151134457776363),\n",
       " ('second one write', 0.30151134457776363),\n",
       " ('python package questions', 0.30151134457776363),\n",
       " ('interview given string', 0.30151134457776363),\n",
       " ('string second one', 0.30151134457776363),\n",
       " ('one write ml', 0.30151134457776363),\n",
       " ('language contained string', 0.30151134457776363),\n",
       " ('write ml python', 0.30151134457776363),\n",
       " ('english language contained', 0.30151134457776363),\n",
       " ('use python modifications', 0.30151134457776363),\n",
       " ('every word english', 0.30151134457776363),\n",
       " ('package questions answered', 0.30151134457776363),\n",
       " ('find every word', 0.30151134457776363),\n",
       " ('code interview given', 0.30151134457776363),\n",
       " ('agiu de acordo', 0.28867513459481287),\n",
       " ('billion rows would', 0.28867513459481287),\n",
       " ('cultural número da', 0.28867513459481287),\n",
       " ('source without affecting', 0.28867513459481287),\n",
       " ('rows would add', 0.28867513459481287),\n",
       " ('affecting user experience', 0.28867513459481287),\n",
       " ('acordo com aspécto', 0.28867513459481287),\n",
       " ('inserting data original', 0.28867513459481287),\n",
       " ('add column inserting', 0.28867513459481287),\n",
       " ('de acordo com', 0.28867513459481287),\n",
       " ('data original source', 0.28867513459481287),\n",
       " ('would add column', 0.28867513459481287),\n",
       " ('que você agiu', 0.28867513459481287),\n",
       " ('uma vez que', 0.28867513459481287),\n",
       " ('original source without', 0.28867513459481287),\n",
       " ('diga uma vez', 0.28867513459481287),\n",
       " ('com aspécto cultural', 0.28867513459481287),\n",
       " ('column inserting data', 0.28867513459481287),\n",
       " ('número da empresa', 0.28867513459481287),\n",
       " ('aspécto cultural número', 0.28867513459481287),\n",
       " ('vez que você', 0.28867513459481287),\n",
       " ('você agiu de', 0.28867513459481287),\n",
       " ('table billion rows', 0.28867513459481287),\n",
       " ('without affecting user', 0.28867513459481287),\n",
       " ('given two tables', 0.273109967038662),\n",
       " ('two fields well', 0.273109967038662),\n",
       " ('fields well id', 0.273109967038662),\n",
       " ('well id salary', 0.273109967038662),\n",
       " ('random forest lightgbm', 0.2672612419124244),\n",
       " ('leadership principles look', 0.2672612419124244),\n",
       " ('principles look online', 0.2672612419124244),\n",
       " ('regarding xgboost random', 0.2672612419124244),\n",
       " ('lightgbm many questions', 0.2672612419124244),\n",
       " ('regarding leadership principles', 0.2672612419124244),\n",
       " ('questions regarding leadership', 0.2672612419124244),\n",
       " ('questions regarding xgboost', 0.2672612419124244),\n",
       " ('xgboost random forest', 0.2672612419124244),\n",
       " ('forest lightgbm many', 0.2672612419124244),\n",
       " ('precision recall pca', 0.26726124191242434),\n",
       " ('recall pca work', 0.26726124191242434),\n",
       " ('data high cardinality', 0.26726124191242434),\n",
       " ('data deal categorical', 0.26726124191242434),\n",
       " ('missing data deal', 0.26726124191242434),\n",
       " ('work deal missing', 0.26726124191242434),\n",
       " ('deal categorical data', 0.26726124191242434),\n",
       " ('deal missing data', 0.26726124191242434),\n",
       " ('decision tree work', 0.26726124191242434),\n",
       " ('definition precision recall', 0.26726124191242434),\n",
       " ('tree work deal', 0.26726124191242434),\n",
       " ('categorical data high', 0.26726124191242434),\n",
       " ('high cardinality definition', 0.26726124191242434),\n",
       " ('cardinality definition precision', 0.26726124191242434),\n",
       " ('steps involved use', 0.2581988897471611),\n",
       " ('unsupervised learning techniques', 0.2581988897471611),\n",
       " ('case accurately predict', 0.2581988897471611),\n",
       " ('also technical questions', 0.2581988897471611),\n",
       " ('moving towards phone', 0.2581988897471611),\n",
       " ('multicollinearity correlation vif', 0.2581988897471611),\n",
       " ('vif tolerance etc', 0.2581988897471611),\n",
       " ('value knn explain', 0.2581988897471611),\n",
       " ('validity ip address', 0.2581988897471611),\n",
       " ('validation tell favorite', 0.2581988897471611),\n",
       " ('use willing relocate', 0.2581988897471611),\n",
       " ('use case ml', 0.2581988897471611),\n",
       " ('use case accurately', 0.2581988897471611),\n",
       " ('ups like ci', 0.2581988897471611),\n",
       " ('scenarios ml algorithm', 0.2581988897471611),\n",
       " ('compare two regressions', 0.2581988897471611),\n",
       " ('unsupervised machine learning', 0.2581988897471611),\n",
       " ('build summary table', 0.2581988897471611),\n",
       " ('willing relocate questions', 0.2581988897471611),\n",
       " ('wins losses country', 0.2581988897471611),\n",
       " ('words string cross', 0.2581988897471611),\n",
       " ('missing values mean', 0.2581988897471611),\n",
       " ('replace missing values', 0.2581988897471611),\n",
       " ('writteninanotepaddocument table cricket', 0.2581988897471611),\n",
       " ('return count words', 0.2581988897471611),\n",
       " ('accurately predict different', 0.2581988897471611),\n",
       " ('cross validation tell', 0.2581988897471611),\n",
       " ('cricket wins losses', 0.2581988897471611),\n",
       " ('relocate questions would', 0.2581988897471611),\n",
       " ('ml algorithm use', 0.2581988897471611),\n",
       " ('case ml questions', 0.2581988897471611),\n",
       " ('country check validity', 0.2581988897471611),\n",
       " ('write python code', 0.2581988897471611),\n",
       " ('address string given', 0.2581988897471611),\n",
       " ('count words string', 0.2581988897471611),\n",
       " ('would like know', 0.2581988897471611),\n",
       " ('ml questions steps', 0.2581988897471611),\n",
       " ('correlation vif tolerance', 0.2581988897471611),\n",
       " ('package use willing', 0.2581988897471611),\n",
       " ('anova compare two', 0.2581988897471611),\n",
       " ('statistical package use', 0.2581988897471611),\n",
       " ('two regressions coding', 0.2581988897471611),\n",
       " ('team going join', 0.2581988897471611),\n",
       " ('basic questions follow', 0.2581988897471611),\n",
       " ('questions also technical', 0.2581988897471611),\n",
       " ('table writteninanotepaddocument table', 0.2581988897471611),\n",
       " ('behavior basic questions', 0.2581988897471611),\n",
       " ('questions follow ups', 0.2581988897471611),\n",
       " ('behavioral interview questions', 0.2581988897471611),\n",
       " ('table cricket wins', 0.2581988897471611),\n",
       " ('summary table writteninanotepaddocument', 0.2581988897471611),\n",
       " ('behavioral questions use', 0.2581988897471611),\n",
       " ('questions steps involved', 0.2581988897471611),\n",
       " ('questions unsupervised machine', 0.2581988897471611),\n",
       " ('string given list', 0.2581988897471611),\n",
       " ('questions use case', 0.2581988897471611),\n",
       " ('questions would like', 0.2581988897471611),\n",
       " ('losses country check', 0.2581988897471611),\n",
       " ('string cross validation', 0.2581988897471611),\n",
       " ('ci anova compare', 0.2581988897471611),\n",
       " ('technical questions unsupervised', 0.2581988897471611),\n",
       " ('techniques assess multicollinearity', 0.2581988897471611),\n",
       " ('asked projects done', 0.2581988897471611),\n",
       " ('regressions coding replace', 0.2581988897471611),\n",
       " ('towards phone interview', 0.2581988897471611),\n",
       " ('time short deadline', 0.2581988897471611),\n",
       " ('short deadline handle', 0.2581988897471611),\n",
       " ('asked describe done', 0.2581988897471611),\n",
       " ('resume behavior basic', 0.2581988897471611),\n",
       " ('predict different scenarios', 0.2581988897471611),\n",
       " ('coding replace missing', 0.2581988897471611),\n",
       " ('techniques involve clustering', 0.2581988897471611),\n",
       " ('tell time short', 0.2581988897471611),\n",
       " ('code return count', 0.2581988897471611),\n",
       " ('assess multicollinearity correlation', 0.2581988897471611),\n",
       " ('projects done resume', 0.2581988897471611),\n",
       " ('python code return', 0.2581988897471611),\n",
       " ('clustering diff techniques', 0.2581988897471611),\n",
       " ('tell favorite algorithm', 0.2581988897471611),\n",
       " ('resume asked describe', 0.2581988897471611),\n",
       " ('check validity ip', 0.2581988897471611),\n",
       " ('different scenarios ml', 0.2581988897471611),\n",
       " ('know team going', 0.2581988897471611),\n",
       " ('handle write python', 0.2581988897471611),\n",
       " ('diff techniques assess', 0.2581988897471611),\n",
       " ('involve clustering diff', 0.2581988897471611),\n",
       " ('decide value knn', 0.2581988897471611),\n",
       " ('describe done detail', 0.2581988897471611),\n",
       " ('interview questions also', 0.2581988897471611),\n",
       " ('like know moving', 0.2581988897471611),\n",
       " ('like ci anova', 0.2581988897471611),\n",
       " ('deadline handle write', 0.2581988897471611),\n",
       " ('explain unsupervised learning', 0.2581988897471611),\n",
       " ('learning techniques involve', 0.2581988897471611),\n",
       " ('ip address string', 0.2581988897471611),\n",
       " ('done resume asked', 0.2581988897471611),\n",
       " ('done detail behavioral', 0.2581988897471611),\n",
       " ('involved use case', 0.2581988897471611),\n",
       " ('given list constraints', 0.2581988897471611),\n",
       " ('going join statistical', 0.2581988897471611),\n",
       " ('join statistical package', 0.2581988897471611),\n",
       " ('detail behavioral interview', 0.2581988897471611),\n",
       " ('follow ups like', 0.2581988897471611),\n",
       " ('know moving towards', 0.2581988897471611),\n",
       " ('knn explain unsupervised', 0.2581988897471611),\n",
       " ('ols regression output', 0.25113927984162115),\n",
       " ('pvalue confidence interval', 0.25113927984162115),\n",
       " ('confidence interval assumptions', 0.25113927984162115),\n",
       " ('regression output explain', 0.25113927984162115),\n",
       " ('acumen kind questions', 0.25113927984162115),\n",
       " ('vs mae interpret', 0.25113927984162115),\n",
       " ('regression mse vs', 0.25113927984162115),\n",
       " ('confidence intervals business', 0.25113927984162115),\n",
       " ('code calculate correlation', 0.25113927984162115),\n",
       " ('logistic regression simple', 0.25113927984162115),\n",
       " ('linear regression mse', 0.25113927984162115),\n",
       " ('questions interpret ols', 0.25113927984162115),\n",
       " ('interpret logistic regression', 0.25113927984162115),\n",
       " ('sql code calculate', 0.25113927984162115),\n",
       " ('easy medium questions', 0.25113927984162115),\n",
       " ('calculate correlation vectors', 0.25113927984162115),\n",
       " ('mse vs mae', 0.25113927984162115),\n",
       " ('business acumen kind', 0.25113927984162115),\n",
       " ('regression simple sql', 0.25113927984162115),\n",
       " ('intervals business acumen', 0.25113927984162115),\n",
       " ('mae interpret logistic', 0.25113927984162115),\n",
       " ('sql easy medium', 0.25113927984162115),\n",
       " ('interpret ols regression', 0.25113927984162115),\n",
       " ('questions sql easy', 0.25113927984162115),\n",
       " ('explain confidence intervals', 0.25113927984162115),\n",
       " ('simple sql code', 0.25113927984162115),\n",
       " ('medium questions interpret', 0.25113927984162115),\n",
       " ('output explain confidence', 0.25113927984162115),\n",
       " ('time questions sql', 0.25113927984162115),\n",
       " ('interval assumptions linear', 0.25113927984162115),\n",
       " ('questions based amazon', 0.24999999999999997),\n",
       " ('algorithms machine learning', 0.24999999999999997),\n",
       " ('business problem using', 0.24999999999999997),\n",
       " ('nda reveal much', 0.24999999999999997),\n",
       " ('well general questions', 0.24999999999999997),\n",
       " ('describe case solved', 0.24999999999999997),\n",
       " ('problem using machine', 0.24999999999999997),\n",
       " ('principles well general', 0.24999999999999997),\n",
       " ('solved ambiguous business', 0.24999999999999997),\n",
       " ('bins describe case', 0.24999999999999997),\n",
       " ('numbers give histogram', 0.24999999999999997),\n",
       " ('signed nda reveal', 0.24999999999999997),\n",
       " ('histogram divided bins', 0.24999999999999997),\n",
       " ('questions algorithms machine', 0.24999999999999997),\n",
       " ('ambiguous business problem', 0.24999999999999997),\n",
       " ('behavioural questions based', 0.24999999999999997),\n",
       " ('amazon principles well', 0.24999999999999997),\n",
       " ('learning ab testing', 0.24999999999999997),\n",
       " ('coding given integer', 0.24999999999999997),\n",
       " ('integer array numbers', 0.24999999999999997),\n",
       " ('machine learning ab', 0.24999999999999997),\n",
       " ('lot behavioural questions', 0.24999999999999997),\n",
       " ('ab testing signed', 0.24999999999999997),\n",
       " ('given integer array', 0.24999999999999997),\n",
       " ('using machine learning', 0.24999999999999997),\n",
       " ('array numbers give', 0.24999999999999997),\n",
       " ('divided bins describe', 0.24999999999999997),\n",
       " ('general questions algorithms', 0.24999999999999997),\n",
       " ('give histogram divided', 0.24999999999999997),\n",
       " ('based amazon principles', 0.24999999999999997),\n",
       " ('testing signed nda', 0.24999999999999997),\n",
       " ('case solved ambiguous', 0.24999999999999997),\n",
       " ('broken package broken', 0.24253562503633294),\n",
       " ('containing data form', 0.24253562503633294),\n",
       " ('assume file containing', 0.24253562503633294),\n",
       " ('two proportions ttest', 0.24253562503633294),\n",
       " ('onea twobonea twobonea', 0.24253562503633294),\n",
       " ('file containing data', 0.24253562503633294),\n",
       " ('different types pacel', 0.24253562503633294),\n",
       " ('simple compare two', 0.24253562503633294),\n",
       " ('pacel package give', 0.24253562503633294),\n",
       " ('package broken decide', 0.24253562503633294),\n",
       " ('package different types', 0.24253562503633294),\n",
       " ('package give broken', 0.24253562503633294),\n",
       " ('test train data', 0.24253562503633294),\n",
       " ('data form data', 0.24253562503633294),\n",
       " ('compare two proportions', 0.24253562503633294),\n",
       " ('pick simple compare', 0.24253562503633294),\n",
       " ('give broken package', 0.24253562503633294),\n",
       " ('one pick simple', 0.24253562503633294),\n",
       " ('form data onea', 0.24253562503633294),\n",
       " ('broken decide one', 0.24253562503633294),\n",
       " ('twobonea twobonea twob', 0.24253562503633294),\n",
       " ('split data test', 0.24253562503633294),\n",
       " ('types pacel package', 0.24253562503633294),\n",
       " ('coding question python', 0.24253562503633294),\n",
       " ('twobonea twob could', 0.24253562503633294),\n",
       " ('say package different', 0.24253562503633294),\n",
       " ('decide one pick', 0.24253562503633294),\n",
       " ('twob could split', 0.24253562503633294),\n",
       " ('data test train', 0.24253562503633294),\n",
       " ('could split data', 0.24253562503633294),\n",
       " ('question python assume', 0.24253562503633294),\n",
       " ('lets say package', 0.24253562503633294),\n",
       " ('python assume file', 0.24253562503633294),\n",
       " ('data onea twobonea', 0.24253562503633294),\n",
       " ('theorem explain bias', 0.23029518324004603),\n",
       " ('pvalue explain bayes', 0.23029518324004603),\n",
       " ('tradeoff example high', 0.23029518324004603),\n",
       " ('high variance models', 0.23029518324004603),\n",
       " ('boosting naive bayes', 0.23029518324004603),\n",
       " ('algorithm explain pvalue', 0.23029518324004603),\n",
       " ('high bias high', 0.23029518324004603),\n",
       " ('explain bias variance', 0.23029518324004603),\n",
       " ('example high bias', 0.23029518324004603),\n",
       " ('explain bayes theorem', 0.23029518324004603),\n",
       " ('bayes algorithm explain', 0.23029518324004603),\n",
       " ('bias high variance', 0.23029518324004603),\n",
       " ('bias variance tradeoff', 0.23029518324004603),\n",
       " ('bagging boosting naive', 0.23029518324004603),\n",
       " ('explain pvalue explain', 0.23029518324004603),\n",
       " ('naive bayes algorithm', 0.23029518324004603),\n",
       " ('variance tradeoff example', 0.23029518324004603),\n",
       " ('bayes theorem explain', 0.23029518324004603),\n",
       " ('easy sql coding', 0.22941573387056177),\n",
       " ('categorical variable thousands', 0.22941573387056177),\n",
       " ('introspected learnings end', 0.22941573387056177),\n",
       " ('case study kind', 0.22941573387056177),\n",
       " ('questions asked kinda', 0.22941573387056177),\n",
       " ('calculate pca questions', 0.22941573387056177),\n",
       " ('case study statistical', 0.22941573387056177),\n",
       " ('easy need practice', 0.22941573387056177),\n",
       " ('questions metric classification', 0.22941573387056177),\n",
       " ('coding easy need', 0.22941573387056177),\n",
       " ('joins sql categorical', 0.22941573387056177),\n",
       " ('familiar statistical concepts', 0.22941573387056177),\n",
       " ('series find flow', 0.22941573387056177),\n",
       " ('describe different joins', 0.22941573387056177),\n",
       " ('resume went deep', 0.22941573387056177),\n",
       " ('encode find linear', 0.22941573387056177),\n",
       " ('python coding quiz', 0.22941573387056177),\n",
       " ('values would encode', 0.22941573387056177),\n",
       " ('quiz one easy', 0.22941573387056177),\n",
       " ('classification problems one', 0.22941573387056177),\n",
       " ('simple need familiar', 0.22941573387056177),\n",
       " ('quiz needing one', 0.22941573387056177),\n",
       " ('worked good learning', 0.22941573387056177),\n",
       " ('variable thousands distinct', 0.22941573387056177),\n",
       " ('problems one bit', 0.22941573387056177),\n",
       " ('excited introspected learnings', 0.22941573387056177),\n",
       " ('one easy sql', 0.22941573387056177),\n",
       " ('one coding problem', 0.22941573387056177),\n",
       " ('one case study', 0.22941573387056177),\n",
       " ('one bit tricky', 0.22941573387056177),\n",
       " ('problem one case', 0.22941573387056177),\n",
       " ('experience questions asked', 0.22941573387056177),\n",
       " ('needing one inner', 0.22941573387056177),\n",
       " ('need practice lot', 0.22941573387056177),\n",
       " ('need familiar statistical', 0.22941573387056177),\n",
       " ('good learning experience', 0.22941573387056177),\n",
       " ('learning experience questions', 0.22941573387056177),\n",
       " ('models worked good', 0.22941573387056177),\n",
       " ('basic sql group', 0.22941573387056177),\n",
       " ('learnings end basic', 0.22941573387056177),\n",
       " ('study statistical knowledge', 0.22941573387056177),\n",
       " ('distinct values would', 0.22941573387056177),\n",
       " ('metric classification problems', 0.22941573387056177),\n",
       " ('linear trends time', 0.22941573387056177),\n",
       " ('matrix showing temperature', 0.22941573387056177),\n",
       " ('asked resume went', 0.22941573387056177),\n",
       " ('flow matrix showing', 0.22941573387056177),\n",
       " ('asked kinda excited', 0.22941573387056177),\n",
       " ('thousands distinct values', 0.22941573387056177),\n",
       " ('tricky python coding', 0.22941573387056177),\n",
       " ('time series find', 0.22941573387056177),\n",
       " ('trends time series', 0.22941573387056177),\n",
       " ('end basic sql', 0.22941573387056177),\n",
       " ('lot case study', 0.22941573387056177),\n",
       " ('one inner join', 0.22941573387056177),\n",
       " ('different joins sql', 0.22941573387056177),\n",
       " ('would encode find', 0.22941573387056177),\n",
       " ('sql group question', 0.22941573387056177),\n",
       " ('kinda excited introspected', 0.22941573387056177),\n",
       " ('bit tricky python', 0.22941573387056177),\n",
       " ('coding quiz one', 0.22941573387056177),\n",
       " ('practice lot case', 0.22941573387056177),\n",
       " ('find flow matrix', 0.22941573387056177),\n",
       " ('coding quiz needing', 0.22941573387056177),\n",
       " ('knowledge coding easy', 0.22941573387056177),\n",
       " ('pca questions metric', 0.22941573387056177),\n",
       " ('statistical knowledge coding', 0.22941573387056177),\n",
       " ('statistical models worked', 0.22941573387056177),\n",
       " ('sql coding quiz', 0.22941573387056177),\n",
       " ('study kind simple', 0.22941573387056177),\n",
       " ('went deep statistical', 0.22941573387056177),\n",
       " ('find linear trends', 0.22941573387056177),\n",
       " ('kind simple need', 0.22941573387056177),\n",
       " ('deep statistical models', 0.22941573387056177),\n",
       " ('coding problem one', 0.22941573387056177),\n",
       " ('sql categorical variable', 0.22941573387056177),\n",
       " ('interview month two', 0.223606797749979),\n",
       " ('times interview got', 0.223606797749979),\n",
       " ('general behavioral prepped', 0.223606797749979),\n",
       " ('explain month month', 0.223606797749979),\n",
       " ('write sql code', 0.223606797749979),\n",
       " ('code explain month', 0.223606797749979),\n",
       " ('rate machine learning', 0.223606797749979),\n",
       " ('machine learning question', 0.223606797749979),\n",
       " ('sql code explain', 0.223606797749979),\n",
       " ('interview got rescheduled', 0.223606797749979),\n",
       " ('prepped interview month', 0.223606797749979),\n",
       " ('two times interview', 0.223606797749979),\n",
       " ('question general behavioral', 0.223606797749979),\n",
       " ('learning question general', 0.223606797749979),\n",
       " ('month month user', 0.223606797749979),\n",
       " ('month two times', 0.223606797749979),\n",
       " ('month user retention', 0.223606797749979),\n",
       " ('behavioral prepped interview', 0.223606797749979),\n",
       " ('user retention rate', 0.223606797749979),\n",
       " ('retention rate machine', 0.223606797749979),\n",
       " ('grid search cv', 0.2189743298130236),\n",
       " ('variable bootstrapping difference', 0.2189743298130236),\n",
       " ('difference grid search', 0.2189743298130236),\n",
       " ('handle categorical variable', 0.2189743298130236),\n",
       " ('search cv random', 0.2189743298130236),\n",
       " ('simple easy hope', 0.2189743298130236),\n",
       " ('regression overfit vs', 0.2189743298130236),\n",
       " ('bootstrapping difference grid', 0.2189743298130236),\n",
       " ('hope helps someone', 0.2189743298130236),\n",
       " ('hard simple easy', 0.2189743298130236),\n",
       " ('easy hope helps', 0.2189743298130236),\n",
       " ('underfit hard simple', 0.2189743298130236),\n",
       " ('search cv assumptions', 0.2189743298130236),\n",
       " ('random search cv', 0.2189743298130236),\n",
       " ('cv random search', 0.2189743298130236),\n",
       " ('categorical variable bootstrapping', 0.2189743298130236),\n",
       " ('cv assumptions linear', 0.2189743298130236),\n",
       " ('linear regression overfit', 0.2189743298130236),\n",
       " ('overfit vs underfit', 0.2189743298130236),\n",
       " ('vs underfit hard', 0.2189743298130236),\n",
       " ('roses roses red', 0.20412414523193154),\n",
       " ('fitting unbalanced data', 0.20412414523193154),\n",
       " ('code recognizing entries', 0.20412414523193154),\n",
       " ('ate fish cat', 0.20412414523193154),\n",
       " ('sentences eg input', 0.20412414523193154),\n",
       " ('code job description', 0.20412414523193154),\n",
       " ('strlist cat ate', 0.20412414523193154),\n",
       " ('complicated sql code', 0.20412414523193154),\n",
       " ('solvable postgresql code', 0.20412414523193154),\n",
       " ('saw roses roses', 0.20412414523193154),\n",
       " ('strings english sentence', 0.20412414523193154),\n",
       " ('computation complexity right', 0.20412414523193154),\n",
       " ('right complicated sql', 0.20412414523193154),\n",
       " ('fish cat saw', 0.20412414523193154),\n",
       " ('occur different sentences', 0.20412414523193154),\n",
       " ('python code recognizing', 0.20412414523193154),\n",
       " ('key list words', 0.20412414523193154),\n",
       " ('actually solvable postgresql', 0.20412414523193154),\n",
       " ('suppose list strings', 0.20412414523193154),\n",
       " ('job description fitting', 0.20412414523193154),\n",
       " ('dictionary outdict maps', 0.20412414523193154),\n",
       " ('characters computation complexity', 0.20412414523193154),\n",
       " ('different sentences eg', 0.20412414523193154),\n",
       " ('eg input strlist', 0.20412414523193154),\n",
       " ('right python code', 0.20412414523193154),\n",
       " ('sentence output dictionary', 0.20412414523193154),\n",
       " ('maps key list', 0.20412414523193154),\n",
       " ('english sentence output', 0.20412414523193154),\n",
       " ('words occur different', 0.20412414523193154),\n",
       " ('description fitting unbalanced', 0.20412414523193154),\n",
       " ('recognizing entries list', 0.20412414523193154),\n",
       " ('cat ate fish', 0.20412414523193154),\n",
       " ('postgresql code job', 0.20412414523193154),\n",
       " ('later actually solvable', 0.20412414523193154),\n",
       " ('regression regularizations right', 0.20412414523193154),\n",
       " ('cat saw roses', 0.20412414523193154),\n",
       " ('input strlist cat', 0.20412414523193154),\n",
       " ('code turned later', 0.20412414523193154),\n",
       " ('output dictionary outdict', 0.20412414523193154),\n",
       " ('regularizations right python', 0.20412414523193154),\n",
       " ('list words occur', 0.20412414523193154),\n",
       " ('outdict maps key', 0.20412414523193154),\n",
       " ('sql code turned', 0.20412414523193154),\n",
       " ('entries list characters', 0.20412414523193154),\n",
       " ('list characters computation', 0.20412414523193154),\n",
       " ('turned later actually', 0.20412414523193154),\n",
       " ('list strings english', 0.20412414523193154),\n",
       " ('complexity right complicated', 0.20412414523193154),\n",
       " ('used data come', 0.17960530202677497),\n",
       " ('group clause iii', 0.17960530202677497),\n",
       " ('experience follow questions', 0.17960530202677497),\n",
       " ('findings sql questions', 0.17960530202677497),\n",
       " ('normal select distinct', 0.17960530202677497),\n",
       " ('upperlower case condition', 0.17960530202677497),\n",
       " ('sorry remember questions', 0.17960530202677497),\n",
       " ('sql questions sorry', 0.17960530202677497),\n",
       " ('join statement upperlower', 0.17960530202677497),\n",
       " ('clause iii join', 0.17960530202677497),\n",
       " ('statistics present findings', 0.17960530202677497),\n",
       " ('behavioral tell time', 0.17960530202677497),\n",
       " ('present findings sql', 0.17960530202677497),\n",
       " ('statement ii group', 0.17960530202677497),\n",
       " ('come datadriven statistics', 0.17960530202677497),\n",
       " ('datadriven statistics present', 0.17960530202677497),\n",
       " ('statement upperlower case', 0.17960530202677497),\n",
       " ('data come datadriven', 0.17960530202677497),\n",
       " ('ii group clause', 0.17960530202677497),\n",
       " ('iii join statement', 0.17960530202677497),\n",
       " ('distinct statement ii', 0.17960530202677497),\n",
       " ('remember questions related', 0.17960530202677497),\n",
       " ('questions related normal', 0.17960530202677497),\n",
       " ('questions behavioral tell', 0.17960530202677497),\n",
       " ('tell time used', 0.17960530202677497),\n",
       " ('related normal select', 0.17960530202677497),\n",
       " ('questions sorry remember', 0.17960530202677497),\n",
       " ('intership experience follow', 0.17960530202677497),\n",
       " ('follow questions behavioral', 0.17960530202677497),\n",
       " ('time used data', 0.17960530202677497),\n",
       " ('select distinct statement', 0.17960530202677497),\n",
       " ('fields id salary', 0.17566367863256455),\n",
       " ('given users table', 0.17566367863256455),\n",
       " ('reset every month', 0.17566367863256455),\n",
       " ('every month two', 0.17566367863256455),\n",
       " ('total reset every', 0.17566367863256455),\n",
       " ('table mean salary', 0.17566367863256455),\n",
       " ('two fields id', 0.17566367863256455),\n",
       " ('salary median salary', 0.17566367863256455),\n",
       " ('number new users', 0.17566367863256455),\n",
       " ('table write query', 0.17566367863256455),\n",
       " ('query get cumulative', 0.17566367863256455),\n",
       " ('month two tables', 0.17566367863256455),\n",
       " ('new users added', 0.17566367863256455),\n",
       " ('added day total', 0.17566367863256455),\n",
       " ('users added day', 0.17566367863256455),\n",
       " ('salary table mean', 0.17566367863256455),\n",
       " ('write query get', 0.17566367863256455),\n",
       " ('cumulative number new', 0.17566367863256455),\n",
       " ('users table write', 0.17566367863256455),\n",
       " ('get cumulative number', 0.17566367863256455),\n",
       " ('id salary table', 0.17566367863256455),\n",
       " ('mean salary median', 0.17566367863256455),\n",
       " ('day total reset', 0.17566367863256455),\n",
       " ('bagging versus boosting', 0.14285714285714282),\n",
       " ('algorithm efficient blah', 0.14285714285714282),\n",
       " ('explain bagging versus', 0.14285714285714282),\n",
       " ('write code different', 0.14285714285714282),\n",
       " ('types search binary', 0.14285714285714282),\n",
       " ('efficient blah blah', 0.14285714285714282),\n",
       " ('different types search', 0.14285714285714282),\n",
       " ('versus boosting write', 0.14285714285714282),\n",
       " ('code different types', 0.14285714285714282),\n",
       " ('binary search algorithm', 0.14285714285714282),\n",
       " ('search binary search', 0.14285714285714282),\n",
       " ('search algorithm efficient', 0.14285714285714282),\n",
       " ('boosting write code', 0.14285714285714282),\n",
       " ('sample deal class', 0.1195228609334393),\n",
       " ('rounds always ask', 0.1195228609334393),\n",
       " ('fundamentals ml statistics', 0.1195228609334393),\n",
       " ('gans detail bunch', 0.1195228609334393),\n",
       " ('idea approach sure', 0.1195228609334393),\n",
       " ('gans somewhere resume', 0.1195228609334393),\n",
       " ('may also ask', 0.1195228609334393),\n",
       " ('generate dataset select', 0.1195228609334393),\n",
       " ('interviewers rounds always', 0.1195228609334393),\n",
       " ('always ask followup', 0.1195228609334393),\n",
       " ('temporal effects split', 0.1195228609334393),\n",
       " ('science case study', 0.1195228609334393),\n",
       " ('questions answers suggest', 0.1195228609334393),\n",
       " ('ml statistics science', 0.1195228609334393),\n",
       " ('example wrote gans', 0.1195228609334393),\n",
       " ('model use interviewers', 0.1195228609334393),\n",
       " ('questions also presented', 0.1195228609334393),\n",
       " ('deal class imbalance', 0.1195228609334393),\n",
       " ('case exercise would', 0.1195228609334393),\n",
       " ('effects split trainvaltest', 0.1195228609334393),\n",
       " ('questions make sure', 0.1195228609334393),\n",
       " ('would process dataset', 0.1195228609334393),\n",
       " ('follow website httpsmlengineerio', 0.1195228609334393),\n",
       " ('case study describe', 0.1195228609334393),\n",
       " ('followup questions answers', 0.1195228609334393),\n",
       " ('wrote resume example', 0.1195228609334393),\n",
       " ('followup questions make', 0.1195228609334393),\n",
       " ('wrote gans somewhere', 0.1195228609334393),\n",
       " ('trainvaltest follow website', 0.1195228609334393),\n",
       " ('dataset training would', 0.1195228609334393),\n",
       " ('dataset select unbiased', 0.1195228609334393),\n",
       " ('form simple case', 0.1195228609334393),\n",
       " ('ask explain gans', 0.1195228609334393),\n",
       " ('ask followup questions', 0.1195228609334393),\n",
       " ('detail bunch followup', 0.1195228609334393),\n",
       " ('ask keywords wrote', 0.1195228609334393),\n",
       " ('make sure brush', 0.1195228609334393),\n",
       " ('imbalance consider temporal', 0.1195228609334393),\n",
       " ('resume example wrote', 0.1195228609334393),\n",
       " ('resume surprised ask', 0.1195228609334393),\n",
       " ('describe generate dataset', 0.1195228609334393),\n",
       " ('also ask keywords', 0.1195228609334393),\n",
       " ('also presented form', 0.1195228609334393),\n",
       " ('training would decide', 0.1195228609334393),\n",
       " ('presented form simple', 0.1195228609334393),\n",
       " ('would decide model', 0.1195228609334393),\n",
       " ('study describe generate', 0.1195228609334393),\n",
       " ('somewhere resume surprised', 0.1195228609334393),\n",
       " ('split trainvaltest follow', 0.1195228609334393),\n",
       " ('process dataset training', 0.1195228609334393),\n",
       " ('suggest idea approach', 0.1195228609334393),\n",
       " ('unbiased sample deal', 0.1195228609334393),\n",
       " ('class imbalance consider', 0.1195228609334393),\n",
       " ('simple case exercise', 0.1195228609334393),\n",
       " ('sure brush fundamentals', 0.1195228609334393),\n",
       " ('sure familiar may', 0.1195228609334393),\n",
       " ('decide model use', 0.1195228609334393),\n",
       " ('keywords wrote resume', 0.1195228609334393),\n",
       " ('brush fundamentals ml', 0.1195228609334393),\n",
       " ('answers suggest idea', 0.1195228609334393),\n",
       " ('approach sure familiar', 0.1195228609334393),\n",
       " ('select unbiased sample', 0.1195228609334393),\n",
       " ('explain gans detail', 0.1195228609334393),\n",
       " ('exercise would process', 0.1195228609334393),\n",
       " ('consider temporal effects', 0.1195228609334393),\n",
       " ('statistics science case', 0.1195228609334393),\n",
       " ('bunch followup questions', 0.1195228609334393),\n",
       " ('familiar may also', 0.1195228609334393),\n",
       " ('use interviewers rounds', 0.1195228609334393),\n",
       " ('surprised ask explain', 0.1195228609334393),\n",
       " ('whats probability picks', 0.07602859212697048),\n",
       " ('xgboost hyperparameter tuning', 0.07602859212697048),\n",
       " ('explain difference ridge', 0.07602859212697048),\n",
       " ('explain different time', 0.07602859212697048),\n",
       " ('whats probability kids', 0.07602859212697048),\n",
       " ('explain hypothesis testing', 0.07602859212697048),\n",
       " ('explained forward selection', 0.07602859212697048),\n",
       " ('value svm would', 0.07602859212697048),\n",
       " ('values explain difference', 0.07602859212697048),\n",
       " ('values vif used', 0.07602859212697048),\n",
       " ...]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_vectorizer = TfidfVectorizer(ngram_range=(3,3), min_df=0.001, max_df = 0.75)\n",
    "amazon_vectorized_questions = pd.DataFrame(amazon_vectorizer.fit_transform(amazon_interview_questions_df['Interview Questions']).toarray(), columns = amazon_vectorizer.get_feature_names_out())\n",
    "amazon_vectorized_questions.loc['Total'] = amazon_vectorized_questions.sum(numeric_only=True, axis=0)\n",
    "amazon_vectorized_questions = amazon_vectorized_questions.sort_values(amazon_vectorized_questions.last_valid_index(), axis=1, ascending=False)\n",
    "amazon_sorted_word_list = [(col, amazon_vectorized_questions[col].iloc[-1]) for col in amazon_vectorized_questions.columns]\n",
    "amazon_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta TFIDF Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would measure', 2.4971994749000714),\n",
       " ('measure success', 2.0430502577651692),\n",
       " ('case study', 1.9100900205807525),\n",
       " ('ab testing', 1.8776597451386603),\n",
       " ('sql question', 1.8524711067702948),\n",
       " ('sql python', 1.5122788943595629),\n",
       " ('sql questions', 1.4609428111647118),\n",
       " ('asked questions', 1.4247006615168336),\n",
       " ('best friends', 1.4040395444209968),\n",
       " ('product sense', 1.3738917729995306),\n",
       " ('ab test', 1.355154562631638),\n",
       " ('retention rate', 1.3528927912958457),\n",
       " ('success product', 1.2966906420113546),\n",
       " ('machine learning', 1.2358010292559645),\n",
       " ('previous experience', 1.2254876110717614),\n",
       " ('determine best', 1.2241900740786422),\n",
       " ('sql product', 1.1973458852211027),\n",
       " ('news feed', 1.1509704440164734),\n",
       " ('would estimate', 1.0980377384727014),\n",
       " ('tell time', 1.0979293949709037),\n",
       " ('career goals', 1.0),\n",
       " ('lot experiences', 1.0),\n",
       " ('subject studied', 1.0),\n",
       " ('please tell', 1.0),\n",
       " ('prove assumption', 1.0),\n",
       " ('sql case', 0.9808538366521404),\n",
       " ('business case', 0.9554282317149649),\n",
       " ('interview process', 0.9412426890906769),\n",
       " ('given table', 0.9024723778621848),\n",
       " ('write sql', 0.8580304812885358),\n",
       " ('sql query', 0.8580304812885358),\n",
       " ('would create', 0.8524699873820585),\n",
       " ('question one', 0.8513902859352189),\n",
       " ('questions like', 0.8487611882893525),\n",
       " ('questions sql', 0.8355421281746778),\n",
       " ('python questions', 0.8098698877416824),\n",
       " ('question using', 0.7837082826022813),\n",
       " ('case question', 0.7553823981168675),\n",
       " ('product question', 0.7514792356694485),\n",
       " ('fb would', 0.7438710629219512),\n",
       " ('time questions', 0.7345225957917237),\n",
       " ('experience field', 0.7345225957917237),\n",
       " ('question case', 0.7252203007683632),\n",
       " ('one sql', 0.7199533708315938),\n",
       " ('want ask', 0.7071067811865476),\n",
       " ('questions tables', 0.7071067811865476),\n",
       " ('tell technical', 0.7071067811865476),\n",
       " ('want go', 0.7071067811865476),\n",
       " ('notification rate', 0.7071067811865476),\n",
       " ('want join', 0.7071067811865476),\n",
       " ('network facebook', 0.7071067811865476),\n",
       " ('regression assumptions', 0.7071067811865476),\n",
       " ('long ago', 0.7071067811865476),\n",
       " ('linear regression', 0.7071067811865476),\n",
       " ('know good', 0.7071067811865476),\n",
       " ('join fb', 0.7071067811865476),\n",
       " ('im allowed', 0.7071067811865476),\n",
       " ('good fit', 0.7071067811865476),\n",
       " ('go meta', 0.7071067811865476),\n",
       " ('rate drops', 0.7071067811865476),\n",
       " ('usual questions', 0.7071067811865476),\n",
       " ('asked usual', 0.7071067811865476),\n",
       " ('allowed share', 0.7071067811865476),\n",
       " ('analyze network', 0.7071067811865476),\n",
       " ('technical background', 0.7071067811865476),\n",
       " ('tables show', 0.7071067811865476),\n",
       " ('ago remember', 0.7071067811865476),\n",
       " ('anything want', 0.7071067811865476),\n",
       " ('apply data', 0.6882309008072731),\n",
       " ('groups gone', 0.6868083007025813),\n",
       " ('facebook user', 0.6868083007025813),\n",
       " ('user groups', 0.6868083007025813),\n",
       " ('given list', 0.6825536012406945),\n",
       " ('product analysis', 0.6722715821211377),\n",
       " ('would build', 0.6671508112268931),\n",
       " ('cant share', 0.6513709201282812),\n",
       " ('like would', 0.6427200581955896),\n",
       " ('applied data', 0.6399818982093881),\n",
       " ('measure health', 0.6350658664684438),\n",
       " ('mainly sql', 0.627591264189062),\n",
       " ('would investigate', 0.6192322728001087),\n",
       " ('close friend', 0.6106658655382156),\n",
       " ('product quetions', 0.6102309177725996),\n",
       " ('lot sql', 0.6102309177725996),\n",
       " ('one product', 0.6101478079993874),\n",
       " ('query find', 0.6077960388141008),\n",
       " ('two sql', 0.6077960388141008),\n",
       " ('sql would', 0.6075419389362474),\n",
       " ('self previous', 0.5919867781547494),\n",
       " ('introduce self', 0.5919867781547494),\n",
       " ('newsfeed would', 0.5919867781547494),\n",
       " ('daus newsfeed', 0.5919867781547494),\n",
       " ('challenging working', 0.5773502691896258),\n",
       " ('many questions', 0.5773502691896258),\n",
       " ('background ideal', 0.5773502691896258),\n",
       " ('relevant experience', 0.5773502691896258),\n",
       " ('sql scale', 0.5773502691896258),\n",
       " ('leetcode ml', 0.5773502691896258),\n",
       " ('find spam', 0.5773502691896258),\n",
       " ('facebook timeline', 0.5773502691896258),\n",
       " ('complex binary', 0.5773502691896258),\n",
       " ('experience role', 0.5773502691896258),\n",
       " ('evaluate notifications', 0.5773502691896258),\n",
       " ('tell background', 0.5773502691896258),\n",
       " ('describe relevant', 0.5773502691896258),\n",
       " ('deign questions', 0.5773502691896258),\n",
       " ('define meaningful', 0.5773502691896258),\n",
       " ('ideal role', 0.5773502691896258),\n",
       " ('meaningful social', 0.5773502691896258),\n",
       " ('data leetcode', 0.5773502691896258),\n",
       " ('spam request', 0.5773502691896258),\n",
       " ('social interaction', 0.5773502691896258),\n",
       " ('skills sql', 0.5773502691896258),\n",
       " ('productexperimental deign', 0.5773502691896258),\n",
       " ('questions probability', 0.5773502691896258),\n",
       " ('search question', 0.5773502691896258),\n",
       " ('prior launch', 0.5773502691896258),\n",
       " ('something challenging', 0.5773502691896258),\n",
       " ('tell something', 0.5773502691896258),\n",
       " ('probability statistics', 0.5773502691896258),\n",
       " ('binary search', 0.5773502691896258),\n",
       " ('regarding facebook', 0.5773502691896258),\n",
       " ('one data', 0.5773502691896258),\n",
       " ('notifications prior', 0.5773502691896258),\n",
       " ('sql productexperimental', 0.5773502691896258),\n",
       " ('timeline features', 0.5773502691896258),\n",
       " ('request friends', 0.5773502691896258),\n",
       " ('rate skills', 0.5773502691896258),\n",
       " ('eazy sql', 0.5751475611720579),\n",
       " ('best friend', 0.5750945941120821),\n",
       " ('design metrics', 0.5731693427163465),\n",
       " ('health news', 0.5692540095253004),\n",
       " ('sql table', 0.5461923322603951),\n",
       " ('given sql', 0.5461923322603951),\n",
       " ('use data', 0.5450139732243291),\n",
       " ('case studies', 0.5430699497259026),\n",
       " ('bayes theorem', 0.5429802337344),\n",
       " ('product interpretation', 0.5360692213682002),\n",
       " ('estimate metrics', 0.5315763250866309),\n",
       " ('metrics ab', 0.5315763250866309),\n",
       " ('related probability', 0.5281648486175048),\n",
       " ('math case', 0.5281648486175048),\n",
       " ('questions solve', 0.5281648486175048),\n",
       " ('complicated sql', 0.5281648486175048),\n",
       " ('study related', 0.5281648486175048),\n",
       " ('solve immediately', 0.5281648486175048),\n",
       " ('would design', 0.5209028540741715),\n",
       " ('design ab', 0.5209028540741715),\n",
       " ('test experiment', 0.5209028540741715),\n",
       " ('coding machine', 0.5159460102821726),\n",
       " ('sql coding', 0.5159460102821726),\n",
       " ('learning questions', 0.5159460102821726),\n",
       " ('create product', 0.5094165126424341),\n",
       " ('probability theory', 0.5094165126424341),\n",
       " ('videos interview', 0.5094165126424341),\n",
       " ('technical question', 0.5094165126424341),\n",
       " ('experience move', 0.5094165126424341),\n",
       " ('think facebook', 0.5094165126424341),\n",
       " ('using probability', 0.5094165126424341),\n",
       " ('similiar youtube', 0.5094165126424341),\n",
       " ('facebook would', 0.5094165126424341),\n",
       " ('move interview', 0.5094165126424341),\n",
       " ('professional experience', 0.5094165126424341),\n",
       " ('youtube videos', 0.5094165126424341),\n",
       " ('business problem', 0.5046423770174864),\n",
       " ('ml concepts', 0.5),\n",
       " ('medium level', 0.5),\n",
       " ('would problem', 0.5),\n",
       " ('design interview', 0.5),\n",
       " ('python stepp', 0.5),\n",
       " ('visa status', 0.5),\n",
       " ('level questions', 0.5),\n",
       " ('basic resume', 0.5),\n",
       " ('questions provided', 0.5),\n",
       " ('basic ml', 0.5),\n",
       " ('similar sample', 0.5),\n",
       " ('questions visa', 0.5),\n",
       " ('tool facebook', 0.5),\n",
       " ('sql related', 0.5),\n",
       " ('identify close', 0.5),\n",
       " ('close friends', 0.5),\n",
       " ('highdimensional dataset', 0.5),\n",
       " ('approach highdimensional', 0.5),\n",
       " ('related medium', 0.5),\n",
       " ('whats favorite', 0.5),\n",
       " ('social media', 0.5),\n",
       " ('sample questions', 0.5),\n",
       " ('friends social', 0.5),\n",
       " ('facebook marketplace', 0.5),\n",
       " ('friend requests', 0.5),\n",
       " ('around basic', 0.5),\n",
       " ('fake friend', 0.5),\n",
       " ('validation tool', 0.5),\n",
       " ('resume questions', 0.5),\n",
       " ('fb product', 0.5),\n",
       " ('stepp step', 0.5),\n",
       " ('questions around', 0.5),\n",
       " ('favorite fb', 0.5),\n",
       " ('create validation', 0.5),\n",
       " ('data python', 0.5),\n",
       " ('system design', 0.5),\n",
       " ('would yhou', 0.5),\n",
       " ('modeling data', 0.5),\n",
       " ('yhou approach', 0.5),\n",
       " ('nda similar', 0.5),\n",
       " ('problem fake', 0.5),\n",
       " ('product improve', 0.5),\n",
       " ('success like', 0.489295955206672),\n",
       " ('like emoji', 0.489295955206672),\n",
       " ('emoji feature', 0.489295955206672),\n",
       " ('one strategy', 0.48825091466568493),\n",
       " ('strategy question', 0.48825091466568493),\n",
       " ('python machine', 0.48803393745253276),\n",
       " ('technical questions', 0.48803393745253276),\n",
       " ('sense business', 0.48564610521846874),\n",
       " ('case applied', 0.48564610521846874),\n",
       " ('joining fb', 0.47670278878905326),\n",
       " ('parents joining', 0.47670278878905326),\n",
       " ('impact parents', 0.47670278878905326),\n",
       " ('metrics would', 0.4733613072452524),\n",
       " ('data real', 0.46985174214016334),\n",
       " ('high school', 0.46985174214016334),\n",
       " ('probability case', 0.46702629596649287),\n",
       " ('question easy', 0.46702629596649287),\n",
       " ('conditional probability', 0.46702629596649287),\n",
       " ('study fb', 0.46702629596649287),\n",
       " ('medium leetcode', 0.46702629596649287),\n",
       " ('fb products', 0.46702629596649287),\n",
       " ('leetcode level', 0.46702629596649287),\n",
       " ('easy medium', 0.46702629596649287),\n",
       " ('would see', 0.4640177997196599),\n",
       " ('case behaviors', 0.46198291869765545),\n",
       " ('ml case', 0.46198291869765545),\n",
       " ('stats ml', 0.46198291869765545),\n",
       " ('python stats', 0.46198291869765545),\n",
       " ('analysis question', 0.4609237081495712),\n",
       " ('technical one', 0.4609237081495712),\n",
       " ('one technical', 0.4609237081495712),\n",
       " ('two users', 0.45851447954931124),\n",
       " ('users best', 0.45851447954931124),\n",
       " ('asked determine', 0.45851447954931124),\n",
       " ('determine two', 0.45851447954931124),\n",
       " ('share anything', 0.4539134366921656),\n",
       " ('friend fb', 0.4539134366921656),\n",
       " ('python sql', 0.4539134366921656),\n",
       " ('data influence', 0.4539134366921656),\n",
       " ('used data', 0.4539134366921656),\n",
       " ('measure two', 0.4539134366921656),\n",
       " ('data analysis', 0.4539134366921656),\n",
       " ('case statement', 0.4539134366921656),\n",
       " ('two people', 0.4539134366921656),\n",
       " ('opportunity facebook', 0.4539134366921656),\n",
       " ('time used', 0.4539134366921656),\n",
       " ('people close', 0.4539134366921656),\n",
       " ('included materials', 0.4539134366921656),\n",
       " ('influence decision', 0.4539134366921656),\n",
       " ('anything included', 0.4539134366921656),\n",
       " ('ttest python', 0.4539134366921656),\n",
       " ('nda cant', 0.4539134366921656),\n",
       " ('analysis opportunity', 0.4539134366921656),\n",
       " ('write ttest', 0.4539134366921656),\n",
       " ('attracts apply', 0.4539134366921656),\n",
       " ('want use', 0.4501868293952136),\n",
       " ('unique conversation', 0.44835353312118437),\n",
       " ('fries mcdonalds', 0.4472135954999579),\n",
       " ('orders fries', 0.4472135954999579),\n",
       " ('product questions', 0.4472135954999579),\n",
       " ('people many', 0.4472135954999579),\n",
       " ('sql combine', 0.4472135954999579),\n",
       " ('friends facebook', 0.4472135954999579),\n",
       " ('problem people', 0.4472135954999579),\n",
       " ('sql easy', 0.4472135954999579),\n",
       " ('functionalities would', 0.4472135954999579),\n",
       " ('combine two', 0.4472135954999579),\n",
       " ('mcdonalds sell', 0.4472135954999579),\n",
       " ('keeping info', 0.4472135954999579),\n",
       " ('coding product', 0.4472135954999579),\n",
       " ('helpful creation', 0.4472135954999579),\n",
       " ('python standard', 0.4472135954999579),\n",
       " ('reactions facebook', 0.4472135954999579),\n",
       " ('standard interview', 0.4472135954999579),\n",
       " ('many orders', 0.4472135954999579),\n",
       " ('many friends', 0.4472135954999579),\n",
       " ('intro coding', 0.4472135954999579),\n",
       " ('behaviorals sql', 0.4472135954999579),\n",
       " ('questions end', 0.4472135954999579),\n",
       " ('quick intro', 0.4472135954999579),\n",
       " ('two dataset', 0.4472135954999579),\n",
       " ('easy python', 0.4472135954999579),\n",
       " ('whats problem', 0.4472135954999579),\n",
       " ('dataset keeping', 0.4472135954999579),\n",
       " ('would helpful', 0.4472135954999579),\n",
       " ('creation reactions', 0.4472135954999579),\n",
       " ('sell year', 0.4472135954999579),\n",
       " ('questions data', 0.4379123797645716),\n",
       " ('manipulation product', 0.4379123797645716),\n",
       " ('data manipulation', 0.4379123797645716),\n",
       " ('sense questions', 0.4379123797645716),\n",
       " ('basic questions', 0.42270363838621616),\n",
       " ('leetcode type', 0.4167907826048692),\n",
       " ('type questions', 0.4167907826048692),\n",
       " ('learning probability', 0.4167907826048692),\n",
       " ('aggregated two', 0.4167907826048692),\n",
       " ('questions machine', 0.4167907826048692),\n",
       " ('probability questions', 0.4167907826048692),\n",
       " ('find table', 0.4167907826048692),\n",
       " ('two columns', 0.4167907826048692),\n",
       " ('table aggregated', 0.4167907826048692),\n",
       " ('table find', 0.4167907826048692),\n",
       " ('previous projects', 0.413325928043174),\n",
       " ('bad sellers', 0.413325928043174),\n",
       " ('describe previous', 0.413325928043174),\n",
       " ('model find', 0.413325928043174),\n",
       " ('projects sql', 0.413325928043174),\n",
       " ('instagram describe', 0.413325928043174),\n",
       " ('sellers marketplace', 0.413325928043174),\n",
       " ('create model', 0.413325928043174),\n",
       " ('find bad', 0.413325928043174),\n",
       " ('metrics instagram', 0.413325928043174),\n",
       " ('product case', 0.4116057876481483),\n",
       " ('min interview', 0.4116057876481483),\n",
       " ('interview product', 0.4116057876481483),\n",
       " ('goal would', 0.408248290463863),\n",
       " ('figuring adress', 0.408248290463863),\n",
       " ('joins subqueries', 0.408248290463863),\n",
       " ('self join', 0.408248290463863),\n",
       " ('fb goes', 0.408248290463863),\n",
       " ('complex joins', 0.408248290463863),\n",
       " ('go figuring', 0.408248290463863),\n",
       " ('place mainly', 0.408248290463863),\n",
       " ('question requires', 0.408248290463863),\n",
       " ('goes might', 0.408248290463863),\n",
       " ('goes xx', 0.408248290463863),\n",
       " ('mainly work', 0.408248290463863),\n",
       " ('would go', 0.408248290463863),\n",
       " ('join table', 0.408248290463863),\n",
       " ('adress problem', 0.408248290463863),\n",
       " ('happening right', 0.408248290463863),\n",
       " ('requires complex', 0.408248290463863),\n",
       " ('sql self', 0.408248290463863),\n",
       " ('pandas calculate', 0.408248290463863),\n",
       " ('business question', 0.408248290463863),\n",
       " ('calculate score', 0.408248290463863),\n",
       " ('table pandas', 0.408248290463863),\n",
       " ('might reason', 0.408248290463863),\n",
       " ('xx goes', 0.408248290463863),\n",
       " ('hence prepared', 0.408248290463863),\n",
       " ('product goal', 0.408248290463863),\n",
       " ('sql business', 0.408248290463863),\n",
       " ('right hence', 0.408248290463863),\n",
       " ('work happening', 0.408248290463863),\n",
       " ('xxx fb', 0.408248290463863),\n",
       " ('testing experiment', 0.39570360216494715),\n",
       " ('got related', 0.39570360216494715),\n",
       " ('case got', 0.39570360216494715),\n",
       " ('related ab', 0.39570360216494715),\n",
       " ('experiment design', 0.39570360216494715),\n",
       " ('users high', 0.390420635242426),\n",
       " ('confirm users', 0.390420635242426),\n",
       " ('data confirm', 0.390420635242426),\n",
       " ('school data', 0.390420635242426),\n",
       " ('distinct etc', 0.3889532275437715),\n",
       " ('table sql', 0.3889532275437715),\n",
       " ('join count', 0.3889532275437715),\n",
       " ('would join', 0.3889532275437715),\n",
       " ('count distinct', 0.3889532275437715),\n",
       " ('would determine', 0.38732512509587863),\n",
       " ('whether news', 0.38675485955517624),\n",
       " ('tell whether', 0.38675485955517624),\n",
       " ('feed feature', 0.38675485955517624),\n",
       " ('app success', 0.38675485955517624),\n",
       " ('facebook app', 0.38675485955517624),\n",
       " ('feature facebook', 0.38675485955517624),\n",
       " ('interview meta', 0.3819831317941118),\n",
       " ('rate product', 0.3819831317941118),\n",
       " ('meta products', 0.3819831317941118),\n",
       " ('common items', 0.3819831317941118),\n",
       " ('things find', 0.3819831317941118),\n",
       " ('list people', 0.3819831317941118),\n",
       " ('people things', 0.3819831317941118),\n",
       " ('products calculate', 0.3819831317941118),\n",
       " ('people common', 0.3819831317941118),\n",
       " ('case interview', 0.3819831317941118),\n",
       " ('find people', 0.3819831317941118),\n",
       " ('calculate retention', 0.3819831317941118),\n",
       " ('join vs', 0.37796447300922725),\n",
       " ('rate decrease', 0.37796447300922725),\n",
       " ('accept rate', 0.37796447300922725),\n",
       " ('new notification', 0.37796447300922725),\n",
       " ('launching new', 0.37796447300922725),\n",
       " ('decrease launching', 0.37796447300922725),\n",
       " ('difference left', 0.37796447300922725),\n",
       " ('left join', 0.37796447300922725),\n",
       " ('notification system', 0.37796447300922725),\n",
       " ('vs union', 0.37796447300922725),\n",
       " ('friends accept', 0.37796447300922725),\n",
       " ('vs right', 0.37796447300922725),\n",
       " ('right join', 0.37796447300922725),\n",
       " ('union vs', 0.37796447300922725),\n",
       " ('user best', 0.3707560352909493),\n",
       " ('questions majorly', 0.3697292733855079),\n",
       " ('around three', 0.3697292733855079),\n",
       " ('sense statistics', 0.3697292733855079),\n",
       " ('majorly around', 0.3697292733855079),\n",
       " ('three topics', 0.3697292733855079),\n",
       " ('topics sql', 0.3697292733855079),\n",
       " ('success news', 0.36202698732322885),\n",
       " ('feeds kind', 0.36202698732322885),\n",
       " ('feature wish', 0.36202698732322885),\n",
       " ('wish add', 0.36202698732322885),\n",
       " ('news feeds', 0.36202698732322885),\n",
       " ('add instagram', 0.36202698732322885),\n",
       " ('kind feature', 0.36202698732322885),\n",
       " ('search consecutive', 0.356836046863163),\n",
       " ('whose sum', 0.356836046863163),\n",
       " ('numbers whose', 0.356836046863163),\n",
       " ('equal given', 0.356836046863163),\n",
       " ('list search', 0.356836046863163),\n",
       " ('consecutive numbers', 0.356836046863163),\n",
       " ('sum equal', 0.356836046863163),\n",
       " ('questions easy', 0.348619092168865),\n",
       " ('test case', 0.3477302085411906),\n",
       " ('perform sql', 0.3477302085411906),\n",
       " ('sql join', 0.3477302085411906),\n",
       " ('deep dive', 0.3477302085411906),\n",
       " ('resume deep', 0.3477302085411906),\n",
       " ('study resume', 0.3477302085411906),\n",
       " ('join ab', 0.3477302085411906),\n",
       " ('problem sql', 0.3442497799832726),\n",
       " ('approach specific', 0.3442497799832726),\n",
       " ('asking would', 0.3442497799832726),\n",
       " ('would approach', 0.3442497799832726),\n",
       " ('walking case', 0.3442497799832726),\n",
       " ('studies asking', 0.3442497799832726),\n",
       " ('specific problem', 0.3442497799832726),\n",
       " ('including determine', 0.34273236163056897),\n",
       " ('users sqlrelated', 0.34273236163056897),\n",
       " ('facebook users', 0.34273236163056897),\n",
       " ('questions including', 0.34273236163056897),\n",
       " ('sqlrelated questions', 0.34273236163056897),\n",
       " ('across facebook', 0.34273236163056897),\n",
       " ('friends across', 0.34273236163056897),\n",
       " ('confidence interval', 0.3388959255406246),\n",
       " ('using bayes', 0.3388959255406246),\n",
       " ('find set', 0.3388959255406246),\n",
       " ('solve estimation', 0.3388959255406246),\n",
       " ('theorem answer', 0.3388959255406246),\n",
       " ('messages find', 0.3388959255406246),\n",
       " ('table messages', 0.3388959255406246),\n",
       " ('variants theme', 0.3388959255406246),\n",
       " ('set unique', 0.3388959255406246),\n",
       " ('communicators variants', 0.3388959255406246),\n",
       " ('answer confidence', 0.3388959255406246),\n",
       " ('estimation question', 0.3388959255406246),\n",
       " ('interval questions', 0.3388959255406246),\n",
       " ('unique communicators', 0.3388959255406246),\n",
       " ('parents children', 0.33333333333333337),\n",
       " ('child block', 0.33333333333333337),\n",
       " ('design product', 0.33333333333333337),\n",
       " ('block parents', 0.33333333333333337),\n",
       " ('could share', 0.33333333333333337),\n",
       " ('even details', 0.33333333333333337),\n",
       " ('product child', 0.33333333333333337),\n",
       " ('share even', 0.33333333333333337),\n",
       " ('children could', 0.33333333333333337),\n",
       " ('news fb', 0.328488491039979),\n",
       " ('much fake', 0.328488491039979),\n",
       " ('fake news', 0.328488491039979),\n",
       " ('estimate much', 0.328488491039979),\n",
       " ('estimate impact', 0.328488491039979),\n",
       " ('date searchid', 0.32835063853630414),\n",
       " ('use help', 0.3230049703414304),\n",
       " ('meta could', 0.3230049703414304),\n",
       " ('may available', 0.3230049703414304),\n",
       " ('could use', 0.3230049703414304),\n",
       " ('across meta', 0.3230049703414304),\n",
       " ('help case', 0.3230049703414304),\n",
       " ('data may', 0.3230049703414304),\n",
       " ('available across', 0.3230049703414304),\n",
       " ('sources data', 0.3230049703414304),\n",
       " ('related also', 0.3209652691567209),\n",
       " ('query related', 0.3209652691567209),\n",
       " ('also asked', 0.3209652691567209),\n",
       " ('help improve', 0.3209652691567209),\n",
       " ('random product', 0.3209652691567209),\n",
       " ('could help', 0.3209652691567209),\n",
       " ('asked random', 0.3209652691567209),\n",
       " ('product could', 0.3209652691567209),\n",
       " ('similar facebook', 0.3193273076306978),\n",
       " ('feature similar', 0.3193273076306978),\n",
       " ('success newly', 0.3193273076306978),\n",
       " ('newly released', 0.3193273076306978),\n",
       " ('group chat', 0.3193273076306978),\n",
       " ('sense would', 0.3193273076306978),\n",
       " ('facebook group', 0.3193273076306978),\n",
       " ('released feature', 0.3193273076306978),\n",
       " ('restaurants better', 0.31622776601683794),\n",
       " ('work yelp', 0.31622776601683794),\n",
       " ('lets say', 0.31622776601683794),\n",
       " ('would make', 0.31622776601683794),\n",
       " ('recommendation system', 0.31622776601683794),\n",
       " ('make recommendation', 0.31622776601683794),\n",
       " ('system restaurants', 0.31622776601683794),\n",
       " ('say work', 0.31622776601683794),\n",
       " ('better top', 0.31622776601683794),\n",
       " ('yelp would', 0.31622776601683794),\n",
       " ('unique identifier', 0.31316498381793273),\n",
       " ('int unique', 0.31316498381793273),\n",
       " ('question product', 0.2931508879679356),\n",
       " ('case questions', 0.2910510436603115),\n",
       " ('two case', 0.2910510436603115),\n",
       " ('questions product', 0.2910510436603115),\n",
       " ('interpretation apply', 0.2910510436603115),\n",
       " ('data one', 0.2910510436603115),\n",
       " ('probability question', 0.2910510436603115),\n",
       " ('one probability', 0.2910510436603115),\n",
       " ('onsite two', 0.2910510436603115),\n",
       " ('drop metric', 0.28518545287927105),\n",
       " ('would take', 0.28518545287927105),\n",
       " ('nda signed', 0.28518545287927105),\n",
       " ('take decision', 0.28518545287927105),\n",
       " ('prepare questions', 0.28518545287927105),\n",
       " ('rolling product', 0.28518545287927105),\n",
       " ('decision rolling', 0.28518545287927105),\n",
       " ('metric would', 0.28518545287927105),\n",
       " ('see drop', 0.28518545287927105),\n",
       " ('signed prepare', 0.28518545287927105),\n",
       " ('hypothetical schema', 0.2773500981126146),\n",
       " ('using hypothetical', 0.2773500981126146),\n",
       " ('schema portal', 0.2773500981126146),\n",
       " ('unique active', 0.2773500981126146),\n",
       " ('identify number', 0.2773500981126146),\n",
       " ('given country', 0.2773500981126146),\n",
       " ('active users', 0.2773500981126146),\n",
       " ('country given', 0.2773500981126146),\n",
       " ('given day', 0.2773500981126146),\n",
       " ('users given', 0.2773500981126146),\n",
       " ('portal product', 0.2773500981126146),\n",
       " ('number unique', 0.2773500981126146),\n",
       " ('product identify', 0.2773500981126146),\n",
       " ('good idea', 0.2728798459526811),\n",
       " ('categories purchase', 0.2686707825102609),\n",
       " ('broken categories', 0.2686707825102609),\n",
       " ('rolling day', 0.2686707825102609),\n",
       " ('using sql', 0.2686707825102609),\n",
       " ('person broken', 0.2686707825102609),\n",
       " ('distribution rolling', 0.2686707825102609),\n",
       " ('average money', 0.2686707825102609),\n",
       " ('day average', 0.2686707825102609),\n",
       " ('money spent', 0.2686707825102609),\n",
       " ('would provide', 0.2686707825102609),\n",
       " ('provide distribution', 0.2686707825102609),\n",
       " ('spent per', 0.2686707825102609),\n",
       " ('per person', 0.2686707825102609),\n",
       " ('fb launched', 0.2667658641192222),\n",
       " ('feature ig', 0.2667658641192222),\n",
       " ('parts questions', 0.2667658641192222),\n",
       " ('ig fb', 0.2667658641192222),\n",
       " ('room feature', 0.2667658641192222),\n",
       " ('question whether', 0.2667658641192222),\n",
       " ('two parts', 0.2667658641192222),\n",
       " ('analysis product', 0.2667658641192222),\n",
       " ('whether launch', 0.2667658641192222),\n",
       " ('launched feature', 0.2667658641192222),\n",
       " ('launch room', 0.2667658641192222),\n",
       " ('cases whether', 0.2588760473601129),\n",
       " ('would pick', 0.2588760473601129),\n",
       " ('business cases', 0.2588760473601129),\n",
       " ('leecode business', 0.2588760473601129),\n",
       " ('whether implement', 0.2588760473601129),\n",
       " ('kinds metrics', 0.2588760473601129),\n",
       " ('function kinds', 0.2588760473601129),\n",
       " ('easy mode', 0.2588760473601129),\n",
       " ('mode leecode', 0.2588760473601129),\n",
       " ('would ab', 0.2588760473601129),\n",
       " ('pick would', 0.2588760473601129),\n",
       " ('implement function', 0.2588760473601129),\n",
       " ('familiar window', 0.25675201545953574),\n",
       " ('level familiar', 0.25675201545953574),\n",
       " ('window function', 0.25675201545953574),\n",
       " ('study notification', 0.25675201545953574),\n",
       " ('question medium', 0.25675201545953574),\n",
       " ('need lots', 0.25675201545953574),\n",
       " ('lots brainstorming', 0.25675201545953574),\n",
       " ('medium difficulty', 0.25675201545953574),\n",
       " ('evaluate notification', 0.25675201545953574),\n",
       " ('function case', 0.25675201545953574),\n",
       " ('notification need', 0.25675201545953574),\n",
       " ('brainstorming evaluate', 0.25675201545953574),\n",
       " ('difficulty level', 0.25675201545953574),\n",
       " ('notification success', 0.25675201545953574),\n",
       " ('days many', 0.2560217474956421),\n",
       " ('last days', 0.2560217474956421),\n",
       " ('many users', 0.2560217474956421),\n",
       " ('number users', 0.2545392706632501),\n",
       " ('userid int', 0.2545392706632501),\n",
       " ('weekly predict', 0.2544769330809184),\n",
       " ('phone salesnot', 0.2544769330809184),\n",
       " ('recall metric', 0.2544769330809184),\n",
       " ('monthly weekly', 0.2544769330809184),\n",
       " ('rate recall', 0.2544769330809184),\n",
       " ('salesnot mentioned', 0.2544769330809184),\n",
       " ('predict samsong', 0.2544769330809184),\n",
       " ('churn rate', 0.2544769330809184),\n",
       " ('samsong phone', 0.2544769330809184),\n",
       " ('metric explain', 0.2544769330809184),\n",
       " ('explain scratch', 0.2544769330809184),\n",
       " ('like predict', 0.2544769330809184),\n",
       " ('predict churn', 0.2544769330809184),\n",
       " ('mentioned monthly', 0.2544769330809184),\n",
       " ('pull unique', 0.2535062938821885),\n",
       " ('sql metrics', 0.2535062938821885),\n",
       " ('measure user', 0.2535062938821885),\n",
       " ('chat feature', 0.2535062938821885),\n",
       " ('database sql', 0.2535062938821885),\n",
       " ('conversation events', 0.2535062938821885),\n",
       " ('new video', 0.2535062938821885),\n",
       " ('engagement new', 0.2535062938821885),\n",
       " ('video chat', 0.2535062938821885),\n",
       " ('events database', 0.2535062938821885),\n",
       " ('would want', 0.2535062938821885),\n",
       " ('user engagement', 0.2535062938821885),\n",
       " ('use measure', 0.2535062938821885),\n",
       " ('give answer', 0.2523211885087432),\n",
       " ('table business', 0.2523211885087432),\n",
       " ('answer need', 0.2523211885087432),\n",
       " ('would give', 0.2523211885087432),\n",
       " ('problem write', 0.2523211885087432),\n",
       " ('need business', 0.2523211885087432),\n",
       " ('queries would', 0.2523211885087432),\n",
       " ('various queries', 0.2523211885087432),\n",
       " ('write various', 0.2523211885087432),\n",
       " ('problem data', 0.2523211885087432),\n",
       " ('metric question', 0.25174586770947815),\n",
       " ('project ab', 0.25174586770947815),\n",
       " ('project metric', 0.25174586770947815),\n",
       " ('impact project', 0.25174586770947815),\n",
       " ('testing impact', 0.25174586770947815),\n",
       " ('question determine', 0.25174586770947815),\n",
       " ('location past', 0.25174586770947815),\n",
       " ('like rate', 0.25174586770947815),\n",
       " ('friend max', 0.25174586770947815),\n",
       " ('rate location', 0.25174586770947815),\n",
       " ('max metrics', 0.25174586770947815),\n",
       " ('past project', 0.25174586770947815),\n",
       " ('need prepared', 0.2511525498261658),\n",
       " ('straight forward', 0.2511525498261658),\n",
       " ('qs need', 0.2511525498261658),\n",
       " ('qs stat', 0.2511525498261658),\n",
       " ('prepared advanced', 0.2511525498261658),\n",
       " ('stat straight', 0.2511525498261658),\n",
       " ('advanced sql', 0.2511525498261658),\n",
       " ('sql qs', 0.2511525498261658),\n",
       " ('specific qs', 0.2511525498261658),\n",
       " ('bayes probabilities', 0.2511525498261658),\n",
       " ('qs depth', 0.2511525498261658),\n",
       " ('share specific', 0.2511525498261658),\n",
       " ('product qs', 0.2511525498261658),\n",
       " ('forward bayes', 0.2511525498261658),\n",
       " ('depth product', 0.2511525498261658),\n",
       " ('stages coding', 0.25),\n",
       " ('interview behavioural', 0.25),\n",
       " ('five stages', 0.25),\n",
       " ('coding sessions', 0.25),\n",
       " ('interview ml', 0.25),\n",
       " ('ml system', 0.25),\n",
       " ('behavioural interview', 0.25),\n",
       " ('sessions system', 0.25),\n",
       " ('questions chose', 0.24903938312264845),\n",
       " ('choose sql', 0.24903938312264845),\n",
       " ('simple sql', 0.24903938312264845),\n",
       " ('want choose', 0.24903938312264845),\n",
       " ('whether want', 0.24903938312264845),\n",
       " ('sql simple', 0.24903938312264845),\n",
       " ('questions start', 0.24903938312264845),\n",
       " ('chose sql', 0.24903938312264845),\n",
       " ('lasted around', 0.24903938312264845),\n",
       " ('interview lasted', 0.24903938312264845),\n",
       " ('around mins', 0.24903938312264845),\n",
       " ('recruiter asked', 0.24903938312264845),\n",
       " ('start interview', 0.24903938312264845),\n",
       " ('asked whether', 0.24903938312264845),\n",
       " ('system news', 0.24884430407002917),\n",
       " ('theorem stats', 0.24884430407002917),\n",
       " ('restaurants may', 0.24884430407002917),\n",
       " ('like recommender', 0.24884430407002917),\n",
       " ('groups would', 0.24884430407002917),\n",
       " ('stats question', 0.24884430407002917),\n",
       " ('determine health', 0.24884430407002917),\n",
       " ('recommender system', 0.24884430407002917),\n",
       " ('build restaurants', 0.24884430407002917),\n",
       " ('health fb', 0.24884430407002917),\n",
       " ('fb groups', 0.24884430407002917),\n",
       " ('feed bayes', 0.24884430407002917),\n",
       " ('may like', 0.24884430407002917),\n",
       " ('thought process', 0.24358756126086148),\n",
       " ('finish explain', 0.24358756126086148),\n",
       " ('explain thought', 0.24358756126086148),\n",
       " ('solve meta', 0.24358756126086148),\n",
       " ('analytical methods', 0.24358756126086148),\n",
       " ('related question', 0.24358756126086148),\n",
       " ('meta related', 0.24358756126086148),\n",
       " ('methods used', 0.24358756126086148),\n",
       " ('need solve', 0.24358756126086148),\n",
       " ('question start', 0.24358756126086148),\n",
       " ('sql statistics', 0.24358756126086148),\n",
       " ('start finish', 0.24358756126086148),\n",
       " ('statistics analytical', 0.24358756126086148),\n",
       " ('studies need', 0.24358756126086148),\n",
       " ('process analytical', 0.24358756126086148),\n",
       " ('analytical case', 0.24358756126086148),\n",
       " ('fb comment', 0.23665118601142182),\n",
       " ('build experiment', 0.23665118601142182),\n",
       " ('emotions bottom', 0.23665118601142182),\n",
       " ('build ab', 0.23665118601142182),\n",
       " ('bottom added', 0.23665118601142182),\n",
       " ('sad exc', 0.23665118601142182),\n",
       " ('experiment check', 0.23665118601142182),\n",
       " ('check emotions', 0.23665118601142182),\n",
       " ('saying fb', 0.23665118601142182),\n",
       " ('exc would', 0.23665118601142182),\n",
       " ('comment like', 0.23665118601142182),\n",
       " ('added care', 0.23665118601142182),\n",
       " ('care sad', 0.23665118601142182),\n",
       " ('sponsored posts', 0.23632566728439697),\n",
       " ('posts would', 0.23632566728439697),\n",
       " ('use dataframes', 0.23379120616983234),\n",
       " ('practiced beforehand', 0.23379120616983234),\n",
       " ('needed rather', 0.23379120616983234),\n",
       " ('rather rather', 0.23379120616983234),\n",
       " ('rather basic', 0.23379120616983234),\n",
       " ('similar ones', 0.23379120616983234),\n",
       " ('ones practiced', 0.23379120616983234),\n",
       " ('python answer', 0.23379120616983234),\n",
       " ('questions questions', 0.23379120616983234),\n",
       " ('beforehand leetcode', 0.23379120616983234),\n",
       " ('like interviewers', 0.23379120616983234),\n",
       " ('answer questions', 0.23379120616983234),\n",
       " ('interviewers want', 0.23379120616983234),\n",
       " ('leetcode needed', 0.23379120616983234),\n",
       " ('basic python', 0.23379120616983234),\n",
       " ('questions similar', 0.23379120616983234),\n",
       " ('one thread', 0.23180678407470073),\n",
       " ('table massengersends', 0.23180678407470073),\n",
       " ('conversation threads', 0.23180678407470073),\n",
       " ('threads note', 0.23180678407470073),\n",
       " ('hasreaction many', 0.23180678407470073),\n",
       " ('note threads', 0.23180678407470073),\n",
       " ('threads senderid', 0.23180678407470073),\n",
       " ('senderid receiver', 0.23180678407470073),\n",
       " ('messageid hasreaction', 0.23180678407470073),\n",
       " ('receiverid messageid', 0.23180678407470073),\n",
       " ('receiver inverse', 0.23180678407470073),\n",
       " ('date ts', 0.23180678407470073),\n",
       " ('many unique', 0.23180678407470073),\n",
       " ('inverse one', 0.23180678407470073),\n",
       " ('massengersends date', 0.23180678407470073),\n",
       " ('ts senderid', 0.23180678407470073),\n",
       " ('senderid receiverid', 0.23180678407470073),\n",
       " ('specific questions', 0.2170831587697965),\n",
       " ('xyz good', 0.2170831587697965),\n",
       " ('framed like', 0.2170831587697965),\n",
       " ('date manipulation', 0.2170831587697965),\n",
       " ('ended questions', 0.2170831587697965),\n",
       " ('see xyz', 0.2170831587697965),\n",
       " ('manipulation business', 0.2170831587697965),\n",
       " ('sql joins', 0.2170831587697965),\n",
       " ('joins group', 0.2170831587697965),\n",
       " ('idea specific', 0.2170831587697965),\n",
       " ('questions framed', 0.2170831587697965),\n",
       " ('metric movements', 0.2170831587697965),\n",
       " ('case mix', 0.2170831587697965),\n",
       " ('mix open', 0.2170831587697965),\n",
       " ('questions metric', 0.2170831587697965),\n",
       " ('group date', 0.2170831587697965),\n",
       " ('movements experimentation', 0.2170831587697965),\n",
       " ('open ended', 0.2170831587697965),\n",
       " ('questioncase questioncase', 0.2098555008370134),\n",
       " ('preference relative', 0.2098555008370134),\n",
       " ('round min', 0.2098555008370134),\n",
       " ('ask background', 0.2098555008370134),\n",
       " ('questionquantitativestatistics question', 0.2098555008370134),\n",
       " ('background location', 0.2098555008370134),\n",
       " ('skills video', 0.2098555008370134),\n",
       " ('question virtual', 0.2098555008370134),\n",
       " ('min coding', 0.2098555008370134),\n",
       " ('question round', 0.2098555008370134),\n",
       " ('location preference', 0.2098555008370134),\n",
       " ('onsite coding', 0.2098555008370134),\n",
       " ('prescreen ask', 0.2098555008370134),\n",
       " ('relative skills', 0.2098555008370134),\n",
       " ('questioncase questionquantitativestatistics', 0.2098555008370134),\n",
       " ('time min', 0.2098555008370134),\n",
       " ('video total', 0.2098555008370134),\n",
       " ('coding questioncase', 0.2098555008370134),\n",
       " ('virtual onsite', 0.2098555008370134),\n",
       " ('total time', 0.2098555008370134),\n",
       " ('coding question', 0.2098555008370134),\n",
       " ('recommendation facebook', 0.20709201751812992),\n",
       " ('design implement', 0.20709201751812992),\n",
       " ('metrics metric', 0.20709201751812992),\n",
       " ('story function', 0.20709201751812992),\n",
       " ('case instagram', 0.20709201751812992),\n",
       " ('metric interpretation', 0.20709201751812992),\n",
       " ('case restaurant', 0.20709201751812992),\n",
       " ('onsite applied', 0.20709201751812992),\n",
       " ('restaurant recommendation', 0.20709201751812992),\n",
       " ('function design', 0.20709201751812992),\n",
       " ('implement algorithms', 0.20709201751812992),\n",
       " ('instagram close', 0.20709201751812992),\n",
       " ('interpretation case', 0.20709201751812992),\n",
       " ('data case', 0.20709201751812992),\n",
       " ('facebook feed', 0.20709201751812992),\n",
       " ('feed design', 0.20709201751812992),\n",
       " ('algorithms use', 0.20709201751812992),\n",
       " ('use product', 0.20709201751812992),\n",
       " ('rounds onsite', 0.20709201751812992),\n",
       " ('friend story', 0.20709201751812992),\n",
       " ('call recruiter', 0.20580289382407416),\n",
       " ('questions basic', 0.20580289382407416),\n",
       " ('sql min', 0.20580289382407416),\n",
       " ('sql programming', 0.20580289382407416),\n",
       " ('recruiter behavioral', 0.20580289382407416),\n",
       " ('statistical questions', 0.20580289382407416),\n",
       " ('case sql', 0.20580289382407416),\n",
       " ('case statistical', 0.20580289382407416),\n",
       " ('behavioral questions', 0.20580289382407416),\n",
       " ('programming min', 0.20580289382407416),\n",
       " ('another ab', 0.19952098300176666),\n",
       " ('answers sql', 0.19952098300176666),\n",
       " ('well answers', 0.19952098300176666),\n",
       " ('want design', 0.19952098300176666),\n",
       " ('product design', 0.19952098300176666),\n",
       " ('page use', 0.19952098300176666),\n",
       " ('facebook want', 0.19952098300176666),\n",
       " ('design local', 0.19952098300176666),\n",
       " ('refer page', 0.19952098300176666),\n",
       " ('questions search', 0.19952098300176666),\n",
       " ('product need', 0.19952098300176666),\n",
       " ('round interview', 0.19952098300176666),\n",
       " ('organize well', 0.19952098300176666),\n",
       " ('design facebook', 0.19952098300176666),\n",
       " ('search product', 0.19952098300176666),\n",
       " ('local refer', 0.19952098300176666),\n",
       " ('interview sql', 0.19952098300176666),\n",
       " ('need organize', 0.19952098300176666),\n",
       " ('first round', 0.19952098300176666),\n",
       " ('data another', 0.19952098300176666),\n",
       " ('openended product', 0.19883538096434192),\n",
       " ('worried engagement', 0.19883538096434192),\n",
       " ('users searches', 0.19883538096434192),\n",
       " ('question decrease', 0.19883538096434192),\n",
       " ('fb worried', 0.19883538096434192),\n",
       " ('searchid last', 0.19883538096434192),\n",
       " ('table date', 0.19883538096434192),\n",
       " ('date userid', 0.19883538096434192),\n",
       " ('would address', 0.19883538096434192),\n",
       " ('ecosystem would', 0.19883538096434192),\n",
       " ('tables date', 0.19883538096434192),\n",
       " ('reshares fb', 0.19883538096434192),\n",
       " ('searches openended', 0.19883538096434192),\n",
       " ('decrease reshares', 0.19883538096434192),\n",
       " ('address question', 0.19883538096434192),\n",
       " ('userid table', 0.19883538096434192),\n",
       " ('two tables', 0.19883538096434192),\n",
       " ('engagement ecosystem', 0.19883538096434192),\n",
       " ('string datestring', 0.1972306977369802),\n",
       " ('sql features', 0.1972306977369802),\n",
       " ('usersdisabled userid', 0.1972306977369802),\n",
       " ('realise user', 0.1972306977369802),\n",
       " ('question sql', 0.1972306977369802),\n",
       " ('us realise', 0.1972306977369802),\n",
       " ('probabilityofsameuserdouble count', 0.1972306977369802),\n",
       " ('disablereason past', 0.1972306977369802),\n",
       " ('disabledreason string', 0.1972306977369802),\n",
       " ('int disabledreason', 0.1972306977369802),\n",
       " ('past days', 0.1972306977369802),\n",
       " ('actors useridint', 0.1972306977369802),\n",
       " ('table actors', 0.1972306977369802),\n",
       " ('users disablereason', 0.1972306977369802),\n",
       " ('useridint probabilityofsameuserdouble', 0.1972306977369802),\n",
       " ('make us', 0.1972306977369802),\n",
       " ('useridint useridint', 0.1972306977369802),\n",
       " ('table usersdisabled', 0.1972306977369802),\n",
       " ('user returning', 0.1972306977369802),\n",
       " ('count number', 0.1972306977369802),\n",
       " ('features make', 0.1972306977369802),\n",
       " ('returning one', 0.1972306977369802),\n",
       " ('datestring table', 0.1972306977369802),\n",
       " ('days question', 0.1972306977369802),\n",
       " ('signals metrics', 0.18537801764547465),\n",
       " ('want figure', 0.18537801764547465),\n",
       " ('content news', 0.18537801764547465),\n",
       " ('max would', 0.18537801764547465),\n",
       " ('please max', 0.18537801764547465),\n",
       " ('would use', 0.18537801764547465),\n",
       " ('metrics please', 0.18537801764547465),\n",
       " ('say want', 0.18537801764547465),\n",
       " ('product signals', 0.18537801764547465),\n",
       " ('facebook instagram', 0.18537801764547465),\n",
       " ('instagram user', 0.18537801764547465),\n",
       " ('showing content', 0.18537801764547465),\n",
       " ('determine user', 0.18537801764547465),\n",
       " ('let say', 0.18537801764547465),\n",
       " ('use determine', 0.18537801764547465),\n",
       " ('addition important', 0.18537801764547465),\n",
       " ('friend prioritize', 0.18537801764547465),\n",
       " ('friend addition', 0.18537801764547465),\n",
       " ('feed product', 0.18537801764547465),\n",
       " ('figure facebook', 0.18537801764547465),\n",
       " ('prioritize showing', 0.18537801764547465),\n",
       " ('rows date', 0.15658249190896636),\n",
       " ('date search', 0.15658249190896636),\n",
       " ('event false', 0.15658249190896636),\n",
       " ('columns date', 0.15658249190896636),\n",
       " ('sample rows', 0.15658249190896636),\n",
       " ('searchid int', 0.15658249190896636),\n",
       " ('date string', 0.15658249190896636),\n",
       " ('string date', 0.15658249190896636),\n",
       " ('identifier search', 0.15658249190896636),\n",
       " ('take phone', 0.11848108748213339),\n",
       " ('kind joins', 0.11848108748213339),\n",
       " ('nice say', 0.11848108748213339),\n",
       " ('even fit', 0.11848108748213339),\n",
       " ('screening lightly', 0.11848108748213339),\n",
       " ('talk resume', 0.11848108748213339),\n",
       " ('natural sorting', 0.11848108748213339),\n",
       " ('much wish', 0.11848108748213339),\n",
       " ('sees helps', 0.11848108748213339),\n",
       " ('wish could', 0.11848108748213339),\n",
       " ('simple messed', 0.11848108748213339),\n",
       " ('lightly got', 0.11848108748213339),\n",
       " ('hope someone', 0.11848108748213339),\n",
       " ('joins get', 0.11848108748213339),\n",
       " ('company forget', 0.11848108748213339),\n",
       " ('fit small', 0.11848108748213339),\n",
       " ('forget facebook', 0.11848108748213339),\n",
       " ('creation facebook', 0.11848108748213339),\n",
       " ('general talk', 0.11848108748213339),\n",
       " ('sense completely', 0.11848108748213339),\n",
       " ('get common', 0.11848108748213339),\n",
       " ('gone sounds', 0.11848108748213339),\n",
       " ('got rejected', 0.11848108748213339),\n",
       " ('expecting sql', 0.11848108748213339),\n",
       " ('completely unprepared', 0.11848108748213339),\n",
       " ('unstructured way', 0.11848108748213339),\n",
       " ('unprepared creation', 0.11848108748213339),\n",
       " ('facebook recruiter', 0.11848108748213339),\n",
       " ('hear answer', 0.11848108748213339),\n",
       " ('helps sql', 0.11848108748213339),\n",
       " ('way sounded', 0.11848108748213339),\n",
       " ('asked question', 0.11848108748213339),\n",
       " ('could prepared', 0.11848108748213339),\n",
       " ('sounds simple', 0.11848108748213339),\n",
       " ('please dont', 0.11848108748213339),\n",
       " ('stupid even', 0.11848108748213339),\n",
       " ('prepared hope', 0.11848108748213339),\n",
       " ('someone sees', 0.11848108748213339),\n",
       " ('sorting order', 0.11848108748213339),\n",
       " ('sounded stupid', 0.11848108748213339),\n",
       " ('blabbering anything', 0.11848108748213339),\n",
       " ('answer would', 0.11848108748213339),\n",
       " ('questions general', 0.11848108748213339),\n",
       " ('resume asked', 0.11848108748213339),\n",
       " ('anything hear', 0.11848108748213339),\n",
       " ('badly blabbering', 0.11848108748213339),\n",
       " ('anything unstructured', 0.11848108748213339),\n",
       " ('would reject', 0.11848108748213339),\n",
       " ('recruiter nice', 0.11848108748213339),\n",
       " ('regret much', 0.11848108748213339),\n",
       " ('reject spot', 0.11848108748213339),\n",
       " ('rejected expecting', 0.11848108748213339),\n",
       " ('spot regret', 0.11848108748213339),\n",
       " ('correctly kind', 0.11848108748213339),\n",
       " ('answer correctly', 0.11848108748213339),\n",
       " ('messed badly', 0.11848108748213339),\n",
       " ('common rows', 0.11848108748213339),\n",
       " ('small company', 0.11848108748213339),\n",
       " ('phone screening', 0.11848108748213339),\n",
       " ('order etc', 0.11848108748213339),\n",
       " ('rows natural', 0.11848108748213339),\n",
       " ('easy answer', 0.11848108748213339),\n",
       " ('dont take', 0.11848108748213339),\n",
       " ('say anything', 0.11848108748213339),\n",
       " ('school would', 0.11816283364219848),\n",
       " ('newsfeed technical', 0.11816283364219848),\n",
       " ('real product', 0.11816283364219848),\n",
       " ('get high', 0.11816283364219848),\n",
       " ('several years', 0.11816283364219848),\n",
       " ('newsfeed product', 0.11816283364219848),\n",
       " ('would size', 0.11816283364219848),\n",
       " ('would redo', 0.11816283364219848),\n",
       " ('based table', 0.11816283364219848),\n",
       " ('questions would', 0.11816283364219848),\n",
       " ('technical analysis', 0.11816283364219848),\n",
       " ('schools time', 0.11816283364219848),\n",
       " ('question several', 0.11816283364219848),\n",
       " ('redo sizing', 0.11816283364219848),\n",
       " ('users fill', 0.11816283364219848),\n",
       " ('would quantify', 0.11816283364219848),\n",
       " ...]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_vectorizer = TfidfVectorizer(ngram_range=(2,2), min_df=0.001, max_df = 0.75)\n",
    "meta_vectorized_questions = pd.DataFrame(meta_vectorizer.fit_transform(meta_interview_questions_df['Interview Questions']).toarray(), columns = meta_vectorizer.get_feature_names_out())\n",
    "meta_vectorized_questions.loc['Total'] = meta_vectorized_questions.sum(numeric_only=True, axis=0)\n",
    "meta_vectorized_questions = meta_vectorized_questions.sort_values(meta_vectorized_questions.last_valid_index(), axis=1, ascending=False)\n",
    "meta_sorted_word_list = [(col, meta_vectorized_questions[col].iloc[-1]) for col in meta_vectorized_questions.columns]\n",
    "meta_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft TFIDF Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('question overfitting underfitting', 2.0),\n",
       " ('technical questions asked', 2.0),\n",
       " ('experience data science', 1.8972878104868651),\n",
       " ('questions data science', 1.6138547091337885),\n",
       " ('prior experience data', 1.4551079118247503),\n",
       " ('tell time lead', 1.4142135623730951),\n",
       " ('basic probability statistics', 1.4142135623730951),\n",
       " ('probability statistics programming', 1.4142135623730951),\n",
       " ('find patterns came', 1.4142135623730951),\n",
       " ('system design improvement', 1.4142135623730951),\n",
       " ('recommendation system design', 1.4142135623730951),\n",
       " ('code spiral within', 1.4142135623730951),\n",
       " ('coding talk modelsdata', 1.4142135623730951),\n",
       " ('much coding talk', 1.4142135623730951),\n",
       " ('spiral within grid', 1.4142135623730951),\n",
       " ('matrix leet code', 1.4142135623730951),\n",
       " ('spiral matrix leet', 1.4142135623730951),\n",
       " ('time lead team', 1.4142135623730951),\n",
       " ('anomalies find patterns', 1.4142135623730951),\n",
       " ('describe experiences interest', 1.1547005383792515),\n",
       " ('compose pipeline obtaining', 1.1547005383792515),\n",
       " ('difficulties faced model', 1.1547005383792515),\n",
       " ('interest data science', 1.1547005383792515),\n",
       " ('algorithms abbastanza difficili', 1.1547005383792515),\n",
       " ('structures algorithms abbastanza', 1.1547005383792515),\n",
       " ('faced model lot', 1.1547005383792515),\n",
       " ('pipeline obtaining data', 1.1547005383792515),\n",
       " ('experiences interest data', 1.1547005383792515),\n",
       " ('mcq machine learning', 1.1547005383792515),\n",
       " ('examples deal conflicts', 1.1547005383792515),\n",
       " ('deal conflicts manager', 1.1547005383792515),\n",
       " ('coding question mcq', 1.1547005383792515),\n",
       " ('data structures algorithms', 1.1547005383792515),\n",
       " ('obtaining data vm', 1.1547005383792515),\n",
       " ('question examples deal', 1.1547005383792515),\n",
       " ('model lot layers', 1.1547005383792515),\n",
       " ('questions around trees', 1.1547005383792515),\n",
       " ('around trees bagging', 1.1547005383792515),\n",
       " ('trees bagging boosting', 1.1547005383792515),\n",
       " ('question mcq machine', 1.1547005383792515),\n",
       " ('general questions data', 1.0141492763249513),\n",
       " ('data science case', 1.0141492763249513),\n",
       " ('science case studies', 1.0141492763249513),\n",
       " ('solve coding problems', 1.0),\n",
       " ('tp fn tn', 1.0),\n",
       " ('core questions related', 1.0),\n",
       " ('performance one resume', 1.0),\n",
       " ('challenging questions fp', 1.0),\n",
       " ('algorithmic questions ask', 1.0),\n",
       " ('know machine learning', 1.0),\n",
       " ('data scientist core', 1.0),\n",
       " ('choose use neural', 1.0),\n",
       " ('use neural network', 1.0),\n",
       " ('know norm norm', 1.0),\n",
       " ('one resume project', 1.0),\n",
       " ('questions related feild', 1.0),\n",
       " ('maximum product subarray', 1.0),\n",
       " ('network versus svm', 1.0),\n",
       " ('distribute coupon people', 1.0),\n",
       " ('neural network versus', 1.0),\n",
       " ('please webcam device', 1.0),\n",
       " ('model performance one', 1.0),\n",
       " ('work domain knowledge', 1.0),\n",
       " ('basic statistical questions', 1.0),\n",
       " ('project work domain', 1.0),\n",
       " ('value avoid overfitting', 1.0),\n",
       " ('mainly project work', 1.0),\n",
       " ('asked phd research', 1.0),\n",
       " ('questions fp tp', 1.0),\n",
       " ('ask randomforest lasso', 1.0),\n",
       " ('fp tp fn', 1.0),\n",
       " ('talked ml techniques', 1.0),\n",
       " ('questions mainly project', 1.0),\n",
       " ('scientist core questions', 1.0),\n",
       " ('question sorting array', 1.0),\n",
       " ('improve model performance', 1.0),\n",
       " ('asked mainly projects', 0.9902857004117134),\n",
       " ('focused search text', 0.8944271909999159),\n",
       " ('text manipualtion sql', 0.8944271909999159),\n",
       " ('python coding focused', 0.8944271909999159),\n",
       " ('model best performance', 0.8944271909999159),\n",
       " ('learning model best', 0.8944271909999159),\n",
       " ('nontechnical person team', 0.8944271909999159),\n",
       " ('pvalue would explain', 0.8944271909999159),\n",
       " ('coding focused search', 0.8944271909999159),\n",
       " ('machine learning model', 0.8944271909999159),\n",
       " ('pvalue nontechnical person', 0.8944271909999159),\n",
       " ('would explain pvalue', 0.8944271909999159),\n",
       " ('best performance achieve', 0.8944271909999159),\n",
       " ('build machine learning', 0.8944271909999159),\n",
       " ('search text manipualtion', 0.8944271909999159),\n",
       " ('explain pvalue nontechnical', 0.8944271909999159),\n",
       " ('questions multiple choice', 0.8528028654224417),\n",
       " ('multiple choice questions', 0.8528028654224417),\n",
       " ('interviewer asked approach', 0.8164965809277259),\n",
       " ('designing system bing', 0.8164965809277259),\n",
       " ('approach designing system', 0.8164965809277259),\n",
       " ('asked approach designing', 0.8164965809277259),\n",
       " ('bing image search', 0.8164965809277259),\n",
       " ('system bing image', 0.8164965809277259),\n",
       " ('review resume machine', 0.7559289460184544),\n",
       " ('learning models boosting', 0.7559289460184544),\n",
       " ('resume machine learning', 0.7559289460184544),\n",
       " ('science design questions', 0.7559289460184544),\n",
       " ('probability data science', 0.7559289460184544),\n",
       " ('data science design', 0.7559289460184544),\n",
       " ('involved statistics probability', 0.7559289460184544),\n",
       " ('test review resume', 0.7559289460184544),\n",
       " ('models boosting bagging', 0.7559289460184544),\n",
       " ('hypothesis test review', 0.7559289460184544),\n",
       " ('statistics probability data', 0.7559289460184544),\n",
       " ('leetcode questions involved', 0.7559289460184544),\n",
       " ('machine learning models', 0.7559289460184544),\n",
       " ('questions involved statistics', 0.7559289460184544),\n",
       " ('data science probability', 0.7534040818072745),\n",
       " ('mainly projects resume', 0.73388631642754),\n",
       " ('distance data point', 0.7071067811865476),\n",
       " ('mechanisms including recommender', 0.7071067811865476),\n",
       " ('measure distance data', 0.7071067811865476),\n",
       " ('describe experience work', 0.7071067811865476),\n",
       " ('describe current role', 0.7071067811865476),\n",
       " ('design ab testing', 0.7071067811865476),\n",
       " ('design optimize elevator', 0.7071067811865476),\n",
       " ('optimize elevator question', 0.7071067811865476),\n",
       " ('current role looking', 0.7071067811865476),\n",
       " ('experience work team', 0.7071067811865476),\n",
       " ('asked interview experience', 0.7071067811865476),\n",
       " ('support vector machine', 0.7071067811865476),\n",
       " ('would summarize twitter', 0.7071067811865476),\n",
       " ('find percentile write', 0.7071067811865476),\n",
       " ('bias variance tradeoff', 0.7071067811865476),\n",
       " ('summarize twitter feed', 0.7071067811865476),\n",
       " ('including recommender systems', 0.7071067811865476),\n",
       " ('explain support vector', 0.7071067811865476),\n",
       " ('interview experience nlp', 0.7071067811865476),\n",
       " ('experiment design ab', 0.7071067811865476),\n",
       " ('thing asked interview', 0.7071067811865476),\n",
       " ('percentile write code', 0.7071067811865476),\n",
       " ('experience nlp mechanisms', 0.7071067811865476),\n",
       " ('one thing asked', 0.7071067811865476),\n",
       " ('one obstacles acedamic', 0.7071067811865476),\n",
       " ('obstacles acedamic experience', 0.7071067811865476),\n",
       " ('nlp mechanisms including', 0.7071067811865476),\n",
       " ('empty cells median', 0.7071067811865476),\n",
       " ('replace empty cells', 0.7071067811865476),\n",
       " ('explain bias variance', 0.7071067811865476),\n",
       " ('explain key difference', 0.6666666666666666),\n",
       " ('tabular models model', 0.6666666666666666),\n",
       " ('given pairs characters', 0.6666666666666666),\n",
       " ('split two sets', 0.6666666666666666),\n",
       " ('judge characters could', 0.6666666666666666),\n",
       " ('difference multidimensional tabular', 0.6666666666666666),\n",
       " ('key difference multidimensional', 0.6666666666666666),\n",
       " ('supported azure analysis', 0.6666666666666666),\n",
       " ('models model supported', 0.6666666666666666),\n",
       " ('characters judge characters', 0.6666666666666666),\n",
       " ('azure analysis services', 0.6666666666666666),\n",
       " ('characters could split', 0.6666666666666666),\n",
       " ('pairs characters judge', 0.6666666666666666),\n",
       " ('multidimensional tabular models', 0.6666666666666666),\n",
       " ('could split two', 0.6666666666666666),\n",
       " ('two sets graph', 0.6666666666666666),\n",
       " ('sets graph barpartite', 0.6666666666666666),\n",
       " ('model supported azure', 0.6666666666666666),\n",
       " ('encontrado con un', 0.6030226891555273),\n",
       " ('en ambiente laboral', 0.6030226891555273),\n",
       " ('problema de inclusión', 0.6030226891555273),\n",
       " ('inclusión social en', 0.6030226891555273),\n",
       " ('laboral explicación solución', 0.6030226891555273),\n",
       " ('con un problema', 0.6030226891555273),\n",
       " ('de inclusión social', 0.6030226891555273),\n",
       " ('un problema de', 0.6030226891555273),\n",
       " ('social en ambiente', 0.6030226891555273),\n",
       " ('ambiente laboral explicación', 0.6030226891555273),\n",
       " ('te encontrado con', 0.6030226891555273),\n",
       " ('many years experience', 0.601738623345223),\n",
       " ('years experience data', 0.601738623345223),\n",
       " ('builds ads model', 0.5773502691896257),\n",
       " ('explain difference type', 0.5773502691896257),\n",
       " ('explain deep learning', 0.5773502691896257),\n",
       " ('stats questions theory', 0.5773502691896257),\n",
       " ('many case study', 0.5773502691896257),\n",
       " ('best ways solve', 0.5773502691896257),\n",
       " ('project worked made', 0.5773502691896257),\n",
       " ('provided best ways', 0.5773502691896257),\n",
       " ('asked two three', 0.5773502691896257),\n",
       " ('worked made difference', 0.5773502691896257),\n",
       " ('resume many case', 0.5773502691896257),\n",
       " ('function checks word', 0.5773502691896257),\n",
       " ('hard stats questions', 0.5773502691896257),\n",
       " ('questions theory relevant', 0.5773502691896257),\n",
       " ('ads model basic', 0.5773502691896257),\n",
       " ('basic stats machine', 0.5773502691896257),\n",
       " ('stats machine learning', 0.5773502691896257),\n",
       " ('checks word palindrome', 0.5773502691896257),\n",
       " ('go resume many', 0.5773502691896257),\n",
       " ('difference type type', 0.5773502691896257),\n",
       " ('differences panel data', 0.5773502691896257),\n",
       " ('describe project worked', 0.5773502691896257),\n",
       " ('machine learning questions', 0.5773502691896257),\n",
       " ('deep learning model', 0.5773502691896257),\n",
       " ('situations provided best', 0.5773502691896257),\n",
       " ('model basic algorithms', 0.5773502691896257),\n",
       " ('three business cases', 0.5773502691896257),\n",
       " ('data crosssectional data', 0.5773502691896257),\n",
       " ('panel data crosssectional', 0.5773502691896257),\n",
       " ('learning model customers', 0.5773502691896257),\n",
       " ('create function checks', 0.5773502691896257),\n",
       " ('type type error', 0.5773502691896257),\n",
       " ('two three business', 0.5773502691896257),\n",
       " ('machine learning algorithms', 0.5434629192079349),\n",
       " ('missed call vice', 0.5345224838248487),\n",
       " ('platform would account', 0.5345224838248487),\n",
       " ('cases user missed', 0.5345224838248487),\n",
       " ('account cases user', 0.5345224838248487),\n",
       " ('another user video', 0.5345224838248487),\n",
       " ('calling another user', 0.5345224838248487),\n",
       " ('would account cases', 0.5345224838248487),\n",
       " ('call vice versa', 0.5345224838248487),\n",
       " ('given user calling', 0.5345224838248487),\n",
       " ('call platform would', 0.5345224838248487),\n",
       " ('user calling another', 0.5345224838248487),\n",
       " ('video call platform', 0.5345224838248487),\n",
       " ('user missed call', 0.5345224838248487),\n",
       " ('user video call', 0.5345224838248487),\n",
       " ('hyperparameters de xgboost', 0.5),\n",
       " ('les hyperparameters de', 0.5),\n",
       " ('sequence integer list', 0.5),\n",
       " ('sub sequence integer', 0.5),\n",
       " ('observation outlier biasvariance', 0.5),\n",
       " ('outlier biasvariance trade', 0.5),\n",
       " ('new observation outlier', 0.5),\n",
       " ('maximum sub sequence', 0.5),\n",
       " ('detect new observation', 0.5),\n",
       " ('ajuster les hyperparameters', 0.5),\n",
       " ('find maximum sub', 0.5),\n",
       " ('comment ajuster les', 0.5),\n",
       " ('codificar em tempo', 0.4999999999999999),\n",
       " ('reta por exemplo', 0.4999999999999999),\n",
       " ('em tempo real', 0.4999999999999999),\n",
       " ('em uma reta', 0.4999999999999999),\n",
       " ('de um problema', 0.4999999999999999),\n",
       " ('solucao de um', 0.4999999999999999),\n",
       " ('de otimizacao simples', 0.4999999999999999),\n",
       " ('simples ajustar pontos', 0.4999999999999999),\n",
       " ('pontos em uma', 0.4999999999999999),\n",
       " ('problema de otimizacao', 0.4999999999999999),\n",
       " ('um problema de', 0.4999999999999999),\n",
       " ('uma reta por', 0.4999999999999999),\n",
       " ('ajustar pontos em', 0.4999999999999999),\n",
       " ('tempo real solucao', 0.4999999999999999),\n",
       " ('real solucao de', 0.4999999999999999),\n",
       " ('otimizacao simples ajustar', 0.4999999999999999),\n",
       " ('describe one data', 0.447213595499958),\n",
       " ('randomly select sample', 0.447213595499958),\n",
       " ('lasso ridge introduce', 0.447213595499958),\n",
       " ('around evaluation metric', 0.447213595499958),\n",
       " ('delivery quality end', 0.447213595499958),\n",
       " ('ridge introduce dimension', 0.447213595499958),\n",
       " ('select sample product', 0.447213595499958),\n",
       " ('leet code medium', 0.447213595499958),\n",
       " ('prioritise speed delivery', 0.447213595499958),\n",
       " ('speed delivery quality', 0.447213595499958),\n",
       " ('questions similar leet', 0.447213595499958),\n",
       " ('basic questions around', 0.447213595499958),\n",
       " ('difference lasso ridge', 0.447213595499958),\n",
       " ('dimension reduction technique', 0.447213595499958),\n",
       " ('metric overfitting etc', 0.447213595499958),\n",
       " ('project youve worked', 0.447213595499958),\n",
       " ('code medium level', 0.447213595499958),\n",
       " ('would prioritise speed', 0.447213595499958),\n",
       " ('product user population', 0.447213595499958),\n",
       " ('coding questions similar', 0.447213595499958),\n",
       " ('similar leet code', 0.447213595499958),\n",
       " ('one data science', 0.447213595499958),\n",
       " ('sample product user', 0.447213595499958),\n",
       " ('evaluation metric overfitting', 0.447213595499958),\n",
       " ('discuss randomly select', 0.447213595499958),\n",
       " ('science project youve', 0.447213595499958),\n",
       " ('introduce dimension reduction', 0.447213595499958),\n",
       " ('quality end product', 0.447213595499958),\n",
       " ('data science project', 0.447213595499958),\n",
       " ('questions around evaluation', 0.447213595499958),\n",
       " ('around theories programming', 0.42640143271122083),\n",
       " ('two programming questions', 0.42640143271122083),\n",
       " ('choice questions around', 0.42640143271122083),\n",
       " ('questions around theories', 0.42640143271122083),\n",
       " ('patterns time enough', 0.42640143271122083),\n",
       " ('time enough answer', 0.42640143271122083),\n",
       " ('choice questions two', 0.42640143271122083),\n",
       " ('set questions multiple', 0.42640143271122083),\n",
       " ('theories programming eda', 0.42640143271122083),\n",
       " ('eda finding patterns', 0.42640143271122083),\n",
       " ('programming questions multiple', 0.42640143271122083),\n",
       " ('questions two programming', 0.42640143271122083),\n",
       " ('programming eda finding', 0.42640143271122083),\n",
       " ('finding patterns time', 0.42640143271122083),\n",
       " ('logic behind steps', 0.408248290463863),\n",
       " ('terms like bagging', 0.408248290463863),\n",
       " ('th largest element', 0.408248290463863),\n",
       " ('faster playing around', 0.408248290463863),\n",
       " ('ml terms like', 0.408248290463863),\n",
       " ('mldl deep questions', 0.408248290463863),\n",
       " ('questions system design', 0.408248290463863),\n",
       " ('experience resume difficult', 0.408248290463863),\n",
       " ('inverse matrix faster', 0.408248290463863),\n",
       " ('took delivering results', 0.408248290463863),\n",
       " ('array questionfind th', 0.408248290463863),\n",
       " ('playing around computational', 0.408248290463863),\n",
       " ('boosting linear regression', 0.408248290463863),\n",
       " ('much responsibilities took', 0.408248290463863),\n",
       " ('calculator logic behind', 0.408248290463863),\n",
       " ('question past experience', 0.408248290463863),\n",
       " ('calculations without calculator', 0.408248290463863),\n",
       " ('compute inverse matrix', 0.408248290463863),\n",
       " ('bagging boosting linear', 0.408248290463863),\n",
       " ('around computational tricks', 0.408248290463863),\n",
       " ('largest element arrayconditional', 0.408248290463863),\n",
       " ('one projects much', 0.408248290463863),\n",
       " ('leetcode questions mldl', 0.408248290463863),\n",
       " ('series calculations without', 0.408248290463863),\n",
       " ('past experience resume', 0.408248290463863),\n",
       " ('without calculator logic', 0.408248290463863),\n",
       " ('behavior question past', 0.408248290463863),\n",
       " ('projects much responsibilities', 0.408248290463863),\n",
       " ('difficult problem career', 0.408248290463863),\n",
       " ('questions mldl deep', 0.408248290463863),\n",
       " ('perform series calculations', 0.408248290463863),\n",
       " ('like bagging boosting', 0.408248290463863),\n",
       " ('deep questions system', 0.408248290463863),\n",
       " ('resume difficult problem', 0.408248290463863),\n",
       " ('easymedium leetcode questions', 0.408248290463863),\n",
       " ('sorting array questionfind', 0.408248290463863),\n",
       " ('basic ml terms', 0.408248290463863),\n",
       " ('questionfind th largest', 0.408248290463863),\n",
       " ('matrix faster playing', 0.408248290463863),\n",
       " ('describe one projects', 0.408248290463863),\n",
       " ('element arrayconditional probability', 0.408248290463863),\n",
       " ('responsibilities took delivering', 0.408248290463863),\n",
       " ('code code sql', 0.37796447300922725),\n",
       " ('set threshold explain', 0.37796447300922725),\n",
       " ('good discussion paper', 0.37796447300922725),\n",
       " ('code sql code', 0.37796447300922725),\n",
       " ('normal distribution prediction', 0.37796447300922725),\n",
       " ('fundamentals set threshold', 0.37796447300922725),\n",
       " ('code problem python', 0.37796447300922725),\n",
       " ('code code code', 0.37796447300922725),\n",
       " ('explain mapreduce works', 0.37796447300922725),\n",
       " ('prediction model good', 0.37796447300922725),\n",
       " ('science database related', 0.37796447300922725),\n",
       " ('lots statistics probability', 0.37796447300922725),\n",
       " ('bayes fundamentals set', 0.37796447300922725),\n",
       " ('bayesian prob normal', 0.37796447300922725),\n",
       " ('threshold explain mapreduce', 0.37796447300922725),\n",
       " ('probability math computer', 0.37796447300922725),\n",
       " ('sql code hadoop', 0.37796447300922725),\n",
       " ('prob normal distribution', 0.37796447300922725),\n",
       " ('math computer science', 0.37796447300922725),\n",
       " ('statistics probability math', 0.37796447300922725),\n",
       " ('python code code', 0.37796447300922725),\n",
       " ('problem python code', 0.37796447300922725),\n",
       " ('database related questions', 0.37796447300922725),\n",
       " ('model good discussion', 0.37796447300922725),\n",
       " ('distribution prediction model', 0.37796447300922725),\n",
       " ('explain naive bayes', 0.37796447300922725),\n",
       " ('computer science database', 0.37796447300922725),\n",
       " ('naive bayes fundamentals', 0.37796447300922725),\n",
       " ('power explain nonstatistics', 0.3535533905932738),\n",
       " ('person whats false', 0.3535533905932738),\n",
       " ('positive false negative', 0.3535533905932738),\n",
       " ('probability needle intersects', 0.3535533905932738),\n",
       " ('probability brain teaser', 0.3535533905932738),\n",
       " ('whats power explain', 0.3535533905932738),\n",
       " ('sampling numbers randomly', 0.3535533905932738),\n",
       " ('whats false positive', 0.3535533905932738),\n",
       " ('numbers randomly stream', 0.3535533905932738),\n",
       " ('question probability brain', 0.3535533905932738),\n",
       " ('microsoft etc technical', 0.3535533905932738),\n",
       " ('technical question probability', 0.3535533905932738),\n",
       " ('randomly stream compute', 0.3535533905932738),\n",
       " ('false positive false', 0.3535533905932738),\n",
       " ('stream compute probability', 0.3535533905932738),\n",
       " ('intersects vertical line', 0.3535533905932738),\n",
       " ('explain nonstatistics person', 0.3535533905932738),\n",
       " ('etc technical question', 0.3535533905932738),\n",
       " ('standard questions resume', 0.3535533905932738),\n",
       " ('questions resume microsoft', 0.3535533905932738),\n",
       " ('nonstatistics person whats', 0.3535533905932738),\n",
       " ('compute probability needle', 0.3535533905932738),\n",
       " ('needle intersects vertical', 0.3535533905932738),\n",
       " ('resume microsoft etc', 0.3535533905932738),\n",
       " ('mainly projects listed', 0.3360190977745941),\n",
       " ('puzzles technical questions', 0.3360190977745941),\n",
       " ('technical questions machine', 0.3360190977745941),\n",
       " ('listed cv puzzles', 0.3360190977745941),\n",
       " ('projects listed cv', 0.3360190977745941),\n",
       " ('questions machine learning', 0.3360190977745941),\n",
       " ('questions asked mainly', 0.3360190977745941),\n",
       " ('cv puzzles technical', 0.3360190977745941),\n",
       " ('friends seattle told', 0.33333333333333337),\n",
       " ('interview back back', 0.33333333333333337),\n",
       " ('rainy probability lying', 0.33333333333333337),\n",
       " ('told rainy probability', 0.33333333333333337),\n",
       " ('frame questions linked', 0.33333333333333337),\n",
       " ('data frame questions', 0.33333333333333337),\n",
       " ('project data frame', 0.33333333333333337),\n",
       " ('three friends seattle', 0.33333333333333337),\n",
       " ('probability seattle rainy', 0.33333333333333337),\n",
       " ('back questions project', 0.33333333333333337),\n",
       " ('linked list questions', 0.33333333333333337),\n",
       " ('probability lying whats', 0.33333333333333337),\n",
       " ('questions project data', 0.33333333333333337),\n",
       " ('lying whats probability', 0.33333333333333337),\n",
       " ('back back questions', 0.33333333333333337),\n",
       " ('questions linked list', 0.33333333333333337),\n",
       " ('seattle told rainy', 0.33333333333333337),\n",
       " ('whats probability seattle', 0.33333333333333337),\n",
       " ('wrangling cleaning applying', 0.3185181367110795),\n",
       " ('unbalanced binary classification', 0.3185181367110795),\n",
       " ('data wrangling cleaning', 0.3185181367110795),\n",
       " ('steps data wrangling', 0.3185181367110795),\n",
       " ('learning algorithms deal', 0.3185181367110795),\n",
       " ('cleaning applying machine', 0.3185181367110795),\n",
       " ('algorithms deal unbalanced', 0.3185181367110795),\n",
       " ('deal unbalanced binary', 0.3185181367110795),\n",
       " ('applying machine learning', 0.3185181367110795),\n",
       " ('article implement algorithm', 0.316227766016838),\n",
       " ('article legitimate news', 0.316227766016838),\n",
       " ('questions deep learning', 0.316227766016838),\n",
       " ('algorithm would use', 0.316227766016838),\n",
       " ('would use separate', 0.316227766016838),\n",
       " ('going past experiences', 0.316227766016838),\n",
       " ('news article legitimate', 0.316227766016838),\n",
       " ('mostly behavioral going', 0.316227766016838),\n",
       " ('sql questions deep', 0.316227766016838),\n",
       " ('behavioral going past', 0.316227766016838),\n",
       " ('projects couple stats', 0.316227766016838),\n",
       " ('separate fake news', 0.316227766016838),\n",
       " ('use separate fake', 0.316227766016838),\n",
       " ('past experiences projects', 0.316227766016838),\n",
       " ('legitimate news article', 0.316227766016838),\n",
       " ('fake news article', 0.316227766016838),\n",
       " ('experiences projects couple', 0.316227766016838),\n",
       " ('couple stats sql', 0.316227766016838),\n",
       " ('news article implement', 0.316227766016838),\n",
       " ('stats sql questions', 0.316227766016838),\n",
       " ('questions short one', 0.2886751345948129),\n",
       " ('solve lregularized regression', 0.2886751345948129),\n",
       " ('interview describe time', 0.2886751345948129),\n",
       " ('disclose questions short', 0.2886751345948129),\n",
       " ('interview describe gradient', 0.2886751345948129),\n",
       " ('final interview describe', 0.2886751345948129),\n",
       " ('flavor solve lregularized', 0.2886751345948129),\n",
       " ('gradient boost works', 0.2886751345948129),\n",
       " ('technical interview describe', 0.2886751345948129),\n",
       " ('lregularized regression problem', 0.2886751345948129),\n",
       " ('regression problem many', 0.2886751345948129),\n",
       " ('time convince client', 0.2886751345948129),\n",
       " ('convince client follow', 0.2886751345948129),\n",
       " ('problem many follow', 0.2886751345948129),\n",
       " ('boost works final', 0.2886751345948129),\n",
       " ('client follow strategy', 0.2886751345948129),\n",
       " ('one similar flavor', 0.2886751345948129),\n",
       " ('short one similar', 0.2886751345948129),\n",
       " ('similar flavor solve', 0.2886751345948129),\n",
       " ('works final interview', 0.2886751345948129),\n",
       " ('many follow questions', 0.2886751345948129),\n",
       " ('allowed disclose questions', 0.2886751345948129),\n",
       " ('describe gradient boost', 0.2886751345948129),\n",
       " ('describe time convince', 0.2886751345948129),\n",
       " ('topics include ab', 0.2686396092171166),\n",
       " ('testing data engineering', 0.2686396092171166),\n",
       " ('sql coding machine', 0.2686396092171166),\n",
       " ('working probability distributions', 0.2686396092171166),\n",
       " ('ab testing data', 0.2686396092171166),\n",
       " ('learning algorithms working', 0.2686396092171166),\n",
       " ('engineering sql coding', 0.2686396092171166),\n",
       " ('data engineering sql', 0.2686396092171166),\n",
       " ('include ab testing', 0.2686396092171166),\n",
       " ('coding machine learning', 0.2686396092171166),\n",
       " ('distributions behavioral questions', 0.2686396092171166),\n",
       " ('algorithms working probability', 0.2686396092171166),\n",
       " ('probability distributions behavioral', 0.2686396092171166),\n",
       " ('marble placed back', 0.26726124191242445),\n",
       " ('white reach bag', 0.26726124191242445),\n",
       " ('white marble least', 0.26726124191242445),\n",
       " ('back bag probability', 0.26726124191242445),\n",
       " ('bag probability drawing', 0.26726124191242445),\n",
       " ('placed back bag', 0.26726124191242445),\n",
       " ('bag times drawing', 0.26726124191242445),\n",
       " ('bag white reach', 0.26726124191242445),\n",
       " ('probability drawing white', 0.26726124191242445),\n",
       " ('marbles bag white', 0.26726124191242445),\n",
       " ('reach bag times', 0.26726124191242445),\n",
       " ('drawing white marble', 0.26726124191242445),\n",
       " ('drawing marble placed', 0.26726124191242445),\n",
       " ('times drawing marble', 0.26726124191242445),\n",
       " ('two consecutive heads', 0.25000000000000006),\n",
       " ('contains least one', 0.25000000000000006),\n",
       " ('logloss regression formula', 0.25000000000000006),\n",
       " ('list letters find', 0.25000000000000006),\n",
       " ('tossing coin nlp', 0.25000000000000006),\n",
       " ('letters find shortest', 0.25000000000000006),\n",
       " ('leetcode question given', 0.25000000000000006),\n",
       " ('least one letter', 0.25000000000000006),\n",
       " ('interviews probability two', 0.25000000000000006),\n",
       " ('embedding outside resume', 0.25000000000000006),\n",
       " ('coin nlp questions', 0.25000000000000006),\n",
       " ('find shortest substring', 0.25000000000000006),\n",
       " ('substring contains least', 0.25000000000000006),\n",
       " ('heads tossing coin', 0.25000000000000006),\n",
       " ('three interviews probability', 0.25000000000000006),\n",
       " ('given string list', 0.25000000000000006),\n",
       " ('regression formula repeated', 0.25000000000000006),\n",
       " ('medium leetcode question', 0.25000000000000006),\n",
       " ('classic medium leetcode', 0.25000000000000006),\n",
       " ('formula repeated three', 0.25000000000000006),\n",
       " ('string list letters', 0.25000000000000006),\n",
       " ('consecutive heads tossing', 0.25000000000000006),\n",
       " ('onsite questions classic', 0.25000000000000006),\n",
       " ('question given string', 0.25000000000000006),\n",
       " ('one onsite questions', 0.25000000000000006),\n",
       " ('shortest substring contains', 0.25000000000000006),\n",
       " ('nlp questions embedding', 0.25000000000000006),\n",
       " ('questions classic medium', 0.25000000000000006),\n",
       " ('write logloss regression', 0.25000000000000006),\n",
       " ('questions embedding outside', 0.25000000000000006),\n",
       " ('repeated three interviews', 0.25000000000000006),\n",
       " ('probability two consecutive', 0.25000000000000006),\n",
       " ('buy make prediction', 0.223606797749979),\n",
       " ('product real buying', 0.223606797749979),\n",
       " ('graph showing different', 0.223606797749979),\n",
       " ('different step client', 0.223606797749979),\n",
       " ('client interested microsoft', 0.223606797749979),\n",
       " ('clients boughtdidnt buy', 0.223606797749979),\n",
       " ('buying act dataset', 0.223606797749979),\n",
       " ('interested microsoft product', 0.223606797749979),\n",
       " ('science graph showing', 0.223606797749979),\n",
       " ('boughtdidnt buy make', 0.223606797749979),\n",
       " ('step client interested', 0.223606797749979),\n",
       " ('previous clients boughtdidnt', 0.223606797749979),\n",
       " ('dataset previous clients', 0.223606797749979),\n",
       " ('showing different step', 0.223606797749979),\n",
       " ('data science graph', 0.223606797749979),\n",
       " ('real buying act', 0.223606797749979),\n",
       " ('make prediction new', 0.223606797749979),\n",
       " ('microsoft product real', 0.223606797749979),\n",
       " ('act dataset previous', 0.223606797749979),\n",
       " ('prediction new clients', 0.223606797749979),\n",
       " ('fair coin biased', 0.1856953381770518),\n",
       " ('equal probability function', 0.1856953381770518),\n",
       " ('worded way essentially', 0.1856953381770518),\n",
       " ('probability worded way', 0.1856953381770518),\n",
       " ('thing wants since', 0.1856953381770518),\n",
       " ('returns probability worded', 0.1856953381770518),\n",
       " ('questions could ask', 0.1856953381770518),\n",
       " ('coin biased one', 0.1856953381770518),\n",
       " ('could ask picked', 0.1856953381770518),\n",
       " ('fair interviewer ask', 0.1856953381770518),\n",
       " ('generate fair coin', 0.1856953381770518),\n",
       " ('biased one ii', 0.1856953381770518),\n",
       " ('way essentially question', 0.1856953381770518),\n",
       " ('ask thing wants', 0.1856953381770518),\n",
       " ('ask picked following', 0.1856953381770518),\n",
       " ('since interview generate', 0.1856953381770518),\n",
       " ('one ii generate', 0.1856953381770518),\n",
       " ('interviewer ask thing', 0.1856953381770518),\n",
       " ('interview generate fair', 0.1856953381770518),\n",
       " ('ones although fair', 0.1856953381770518),\n",
       " ('integers equal probability', 0.1856953381770518),\n",
       " ('following ones although', 0.1856953381770518),\n",
       " ('ii generate integers', 0.1856953381770518),\n",
       " ('generate integers equal', 0.1856953381770518),\n",
       " ('although fair interviewer', 0.1856953381770518),\n",
       " ('function returns probability', 0.1856953381770518),\n",
       " ('picked following ones', 0.1856953381770518),\n",
       " ('wants since interview', 0.1856953381770518),\n",
       " ('probability function returns', 0.1856953381770518),\n",
       " ('appears microsoft many', 0.14142135623730945),\n",
       " ('coin toss didnt', 0.14142135623730945),\n",
       " ('asked projects tell', 0.14142135623730945),\n",
       " ('ask even single', 0.14142135623730945),\n",
       " ('advice would teams', 0.14142135623730945),\n",
       " ('assess seems like', 0.14142135623730945),\n",
       " ('apart project also', 0.14142135623730945),\n",
       " ('company years may', 0.14142135623730945),\n",
       " ('also appears microsoft', 0.14142135623730945),\n",
       " ('waste time sure', 0.14142135623730945),\n",
       " ('would teams good', 0.14142135623730945),\n",
       " ('appear energetic advice', 0.14142135623730945),\n",
       " ('really smart energetic', 0.14142135623730945),\n",
       " ('trying assess seems', 0.14142135623730945),\n",
       " ('like random coin', 0.14142135623730945),\n",
       " ('may really smart', 0.14142135623730945),\n",
       " ('microsoft many people', 0.14142135623730945),\n",
       " ('smart energetic people', 0.14142135623730945),\n",
       " ('smart didnt appear', 0.14142135623730945),\n",
       " ('single question apart', 0.14142135623730945),\n",
       " ('microsoft teams interiviewed', 0.14142135623730945),\n",
       " ('past really smart', 0.14142135623730945),\n",
       " ('people company years', 0.14142135623730945),\n",
       " ('seems like hiring', 0.14142135623730945),\n",
       " ('process like random', 0.14142135623730945),\n",
       " ('project also appears', 0.14142135623730945),\n",
       " ('projects tell exact', 0.14142135623730945),\n",
       " ('question apart project', 0.14142135623730945),\n",
       " ('random coin toss', 0.14142135623730945),\n",
       " ('really smart didnt', 0.14142135623730945),\n",
       " ('many people company', 0.14142135623730945),\n",
       " ('like hiring process', 0.14142135623730945),\n",
       " ('toss didnt ask', 0.14142135623730945),\n",
       " ('interviewers asked projects', 0.14142135623730945),\n",
       " ('times waste time', 0.14142135623730945),\n",
       " ('time sure trying', 0.14142135623730945),\n",
       " ('didnt appear energetic', 0.14142135623730945),\n",
       " ('didnt ask even', 0.14142135623730945),\n",
       " ('thing times waste', 0.14142135623730945),\n",
       " ('energetic advice would', 0.14142135623730945),\n",
       " ('even single question', 0.14142135623730945),\n",
       " ('exact thing times', 0.14142135623730945),\n",
       " ('tell exact thing', 0.14142135623730945),\n",
       " ('teams interiviewed past', 0.14142135623730945),\n",
       " ('teams good microsoft', 0.14142135623730945),\n",
       " ('good microsoft teams', 0.14142135623730945),\n",
       " ('sure trying assess', 0.14142135623730945),\n",
       " ('hiring process like', 0.14142135623730945),\n",
       " ('interiviewed past really', 0.14142135623730945),\n",
       " ('years may really', 0.14142135623730945)]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microsoft_vectorizer = TfidfVectorizer(ngram_range=(3,3), min_df=0.001, max_df = 0.75)\n",
    "microsoft_vectorized_questions = pd.DataFrame(microsoft_vectorizer.fit_transform(microsoft_interview_questions_df['Interview Questions']).toarray(), columns = microsoft_vectorizer.get_feature_names_out())\n",
    "microsoft_vectorized_questions.loc['Total'] = microsoft_vectorized_questions.sum(numeric_only=True, axis=0)\n",
    "microsoft_vectorized_questions = microsoft_vectorized_questions.sort_values(microsoft_vectorized_questions.last_valid_index(), axis=1, ascending=False)\n",
    "microsoft_sorted_word_list = [(col, microsoft_vectorized_questions[col].iloc[-1]) for col in microsoft_vectorized_questions.columns]\n",
    "microsoft_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of interview process for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_df = interviews_df_cleaned[['Company', 'Process']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>It wa s avery smooth interviw . I really liked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>They asked me about my technical skills and st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>brainstorm some statistics question with the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>Few relatively simple technical questions. Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>There is s a tech screen and then an onsite. Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company                                            Process\n",
       "0  Google  It wa s avery smooth interviw . I really liked...\n",
       "1  Google  They asked me about my technical skills and st...\n",
       "2  Google  brainstorm some statistics question with the i...\n",
       "3  Google  Few relatively simple technical questions. Ver...\n",
       "4  Google  There is s a tech screen and then an onsite. Y..."
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26340/110647210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meta_process_df['Process'] = meta_process_df['Process'].apply(cleaning)\n",
      "/tmp/ipykernel_26340/110647210.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  apple_process_df['Process'] = apple_process_df['Process'].apply(cleaning)\n",
      "/tmp/ipykernel_26340/110647210.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  google_process_df['Process'] = google_process_df['Process'].apply(cleaning)\n",
      "/tmp/ipykernel_26340/110647210.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  microsoft_process_df['Process'] = microsoft_process_df['Process'].apply(cleaning)\n"
     ]
    }
   ],
   "source": [
    "# Meta df and clean\n",
    "meta_process_df = process_df[(process_df['Company'] == 'Meta')]\n",
    "meta_process_df['Process'] = meta_process_df['Process'].apply(cleaning)\n",
    "# Apple df and clean\n",
    "apple_process_df = process_df[(process_df['Company'] == 'Apple')]\n",
    "apple_process_df['Process'] = apple_process_df['Process'].apply(cleaning)\n",
    "# Google df and clean\n",
    "google_process_df = process_df[(process_df['Company'] == 'Google')]\n",
    "google_process_df['Process'] = google_process_df['Process'].apply(cleaning)\n",
    "# Microsoft df and clean\n",
    "microsoft_process_df = process_df[(process_df['Company'] == 'Microsoft')]\n",
    "microsoft_process_df['Process'] = microsoft_process_df['Process'].apply(cleaning)\n",
    "# Amazon df and clean\n",
    "amazon_process_df = process_df[(process_df['Company'] == 'Amazon')]\n",
    "amazon_process_df = amazon_process_df.dropna().copy()\n",
    "amazon_process_df['Process'] = amazon_process_df['Process'].apply(cleaning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta TFIDF Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('job experience wanted know salary', 0.33333333333333337),\n",
       " ('interview many question previous job', 0.33333333333333337),\n",
       " ('question previous job experience wanted', 0.33333333333333337),\n",
       " ('interview process difficult interview many', 0.33333333333333337),\n",
       " ('experience wanted know salary expectations', 0.33333333333333337),\n",
       " ('process difficult interview many question', 0.33333333333333337),\n",
       " ('previous job experience wanted know', 0.33333333333333337),\n",
       " ('many question previous job experience', 0.33333333333333337),\n",
       " ('difficult interview many question previous', 0.33333333333333337),\n",
       " ('metrics please max would use', 0.32075886286137795),\n",
       " ('content news feed product signals', 0.32075886286137795),\n",
       " ('let say want figure facebook', 0.32075886286137795),\n",
       " ('max would use determine user', 0.32075886286137795),\n",
       " ('please max would use determine', 0.32075886286137795),\n",
       " ('want figure facebook instagram user', 0.32075886286137795),\n",
       " ('user best friend prioritize showing', 0.32075886286137795),\n",
       " ('prioritize showing content news feed', 0.32075886286137795),\n",
       " ('product signals metrics please max', 0.32075886286137795),\n",
       " ('best friend prioritize showing content', 0.32075886286137795),\n",
       " ('say want figure facebook instagram', 0.32075886286137795),\n",
       " ('instagram user best friend prioritize', 0.32075886286137795),\n",
       " ('news feed product signals metrics', 0.32075886286137795),\n",
       " ('friend prioritize showing content news', 0.32075886286137795),\n",
       " ('use determine user best friend', 0.32075886286137795),\n",
       " ('feed product signals metrics please', 0.32075886286137795),\n",
       " ('facebook instagram user best friend', 0.32075886286137795),\n",
       " ('signals metrics please max would', 0.32075886286137795),\n",
       " ('showing content news feed product', 0.32075886286137795),\n",
       " ('figure facebook instagram user best', 0.32075886286137795),\n",
       " ('would use determine user best', 0.32075886286137795),\n",
       " ('recruiter qualifications position wasnt match', 0.31622776601683794),\n",
       " ('emails scheduled call another recruiter', 0.31622776601683794),\n",
       " ('recuiter linkedin one round sr', 0.31622776601683794),\n",
       " ('failed get interview invites recuiter', 0.31622776601683794),\n",
       " ('step process get harder position', 0.31622776601683794),\n",
       " ('process get harder position became', 0.31622776601683794),\n",
       " ('wasnt match recruiter professional left', 0.31622776601683794),\n",
       " ('call another recruiter specific role', 0.31622776601683794),\n",
       " ('processes several interviews recruters enthousiastic', 0.31622776601683794),\n",
       " ('recruters enthousiastic engaged test personnality', 0.31622776601683794),\n",
       " ('environmentjob details needed step process', 0.31622776601683794),\n",
       " ('professional left door open connect', 0.31622776601683794),\n",
       " ('exchanged emails scheduled call another', 0.31622776601683794),\n",
       " ('position wasnt match recruiter professional', 0.31622776601683794),\n",
       " ('engaged test personnality see motivated', 0.31622776601683794),\n",
       " ('sr data scientist failed get', 0.31622776601683794),\n",
       " ('recruiter specific role coding test', 0.31622776601683794),\n",
       " ('recruiter exchanged emails scheduled call', 0.31622776601683794),\n",
       " ('recruiter professional left door open', 0.31622776601683794),\n",
       " ('qualifications position wasnt match recruiter', 0.31622776601683794),\n",
       " ('grasp environmentjob details needed step', 0.31622776601683794),\n",
       " ('personnality see motivated suitable position', 0.31622776601683794),\n",
       " ('details needed step process get', 0.31622776601683794),\n",
       " ('harder position became vague went', 0.31622776601683794),\n",
       " ('test personnality see motivated suitable', 0.31622776601683794),\n",
       " ('initial conversation recruiter qualifications position',\n",
       "  0.31622776601683794),\n",
       " ('data scientist failed get interview', 0.31622776601683794),\n",
       " ('throught processes several interviews recruters', 0.31622776601683794),\n",
       " ('go throught processes several interviews', 0.31622776601683794),\n",
       " ('conversation recruiter qualifications position wasnt', 0.31622776601683794),\n",
       " ('contacted recuiter linkedin one round', 0.31622776601683794),\n",
       " ('interviews recruters enthousiastic engaged test', 0.31622776601683794),\n",
       " ('round sr data scientist failed', 0.31622776601683794),\n",
       " ('confusing difficult grasp environmentjob details', 0.31622776601683794),\n",
       " ('left door open connect talk', 0.31622776601683794),\n",
       " ('linkedin one round sr data', 0.31622776601683794),\n",
       " ('get interview invites recuiter prefessional', 0.31622776601683794),\n",
       " ('match recruiter professional left door', 0.31622776601683794),\n",
       " ('get harder position became vague', 0.31622776601683794),\n",
       " ('difficult grasp environmentjob details needed', 0.31622776601683794),\n",
       " ('needed step process get harder', 0.31622776601683794),\n",
       " ('one round sr data scientist', 0.31622776601683794),\n",
       " ('role coding test asked questions', 0.31622776601683794),\n",
       " ('enthousiastic engaged test personnality see', 0.31622776601683794),\n",
       " ('scientist failed get interview invites', 0.31622776601683794),\n",
       " ('scheduled call another recruiter specific', 0.31622776601683794),\n",
       " ('spoke recruiter exchanged emails scheduled', 0.31622776601683794),\n",
       " ('specific role coding test asked', 0.31622776601683794),\n",
       " ('several interviews recruters enthousiastic engaged', 0.31622776601683794),\n",
       " ('another recruiter specific role coding', 0.31622776601683794),\n",
       " ('area leaders never asked thought', 0.30151134457776363),\n",
       " ('process expressed thought good fit', 0.30151134457776363),\n",
       " ('company opportunity process expressed thought', 0.30151134457776363),\n",
       " ('several area leaders never asked', 0.30151134457776363),\n",
       " ('opportunity process expressed thought good', 0.30151134457776363),\n",
       " ('interviews several area leaders never', 0.30151134457776363),\n",
       " ('asked thought company opportunity process', 0.30151134457776363),\n",
       " ('thought company opportunity process expressed', 0.30151134457776363),\n",
       " ('expressed thought good fit position', 0.30151134457776363),\n",
       " ('never asked thought company opportunity', 0.30151134457776363),\n",
       " ('leaders never asked thought company', 0.30151134457776363),\n",
       " ('interview rounds technical computational interviewers', 0.2886751345948129),\n",
       " ('minute call guess next round', 0.2886751345948129),\n",
       " ('interview python questions answer fast', 0.2886751345948129),\n",
       " ('python questions answer fast time', 0.2886751345948129),\n",
       " ('scheduled interview call interviewer show', 0.2886751345948129),\n",
       " ('interview see math statistics experience', 0.2886751345948129),\n",
       " ('following week minute call guess', 0.2886751345948129),\n",
       " ('statistics experience pass technical interview', 0.2886751345948129),\n",
       " ('punctual asked questions understand wanted', 0.2886751345948129),\n",
       " ('hard hear questions looking specific', 0.2886751345948129),\n",
       " ('questions answer fast time crunch', 0.2886751345948129),\n",
       " ('discussed salary moving experience explained', 0.2886751345948129),\n",
       " ('unprepared called tell role interested', 0.2886751345948129),\n",
       " ('questions first round interview python', 0.2886751345948129),\n",
       " ('uk interviewer called middle day', 0.2886751345948129),\n",
       " ('questions looking specific answer response', 0.2886751345948129),\n",
       " ('middle day quite expect quite', 0.2886751345948129),\n",
       " ('first round interview python questions', 0.2886751345948129),\n",
       " ('based london uk interviewer called', 0.2886751345948129),\n",
       " ('interviewer called middle day quite', 0.2886751345948129),\n",
       " ('see math statistics experience pass', 0.2886751345948129),\n",
       " ('questions understand wanted job motivations', 0.2886751345948129),\n",
       " ('math statistics experience pass technical', 0.2886751345948129),\n",
       " ('materials preparation transparent process however', 0.2886751345948129),\n",
       " ('provided lot initial materials preparation', 0.2886751345948129),\n",
       " ('next scheduled interview call interviewer', 0.2886751345948129),\n",
       " ('moving experience explained job process', 0.2886751345948129),\n",
       " ('time punctual asked questions understand', 0.2886751345948129),\n",
       " ('screening interview see math statistics', 0.2886751345948129),\n",
       " ('phone interview following week minute', 0.2886751345948129),\n",
       " ('wanted job motivations inclinations interest', 0.2886751345948129),\n",
       " ('set phone interview following week', 0.2886751345948129),\n",
       " ('called middle day quite expect', 0.2886751345948129),\n",
       " ('pass technical interview discussed salary', 0.2886751345948129),\n",
       " ('initial materials preparation transparent process', 0.2886751345948129),\n",
       " ('day quite expect quite unprepared', 0.2886751345948129),\n",
       " ('screening call questions first round', 0.2886751345948129),\n",
       " ('overall process good recruiter screening', 0.2886751345948129),\n",
       " ('however next scheduled interview call', 0.2886751345948129),\n",
       " ('preparation transparent process however next', 0.2886751345948129),\n",
       " ('call questions first round interview', 0.2886751345948129),\n",
       " ('helpful provided lot initial materials', 0.2886751345948129),\n",
       " ('call guess next round would', 0.2886751345948129),\n",
       " ('hear questions looking specific answer', 0.2886751345948129),\n",
       " ('interview discussed salary moving experience', 0.2886751345948129),\n",
       " ('process good recruiter screening call', 0.2886751345948129),\n",
       " ('process hard hear questions looking', 0.2886751345948129),\n",
       " ('process however next scheduled interview', 0.2886751345948129),\n",
       " ('guess next round would hiring', 0.2886751345948129),\n",
       " ('week minute call guess next', 0.2886751345948129),\n",
       " ('interview following week minute call', 0.2886751345948129),\n",
       " ('good recruiter screening call questions', 0.2886751345948129),\n",
       " ('quite unprepared called tell role', 0.2886751345948129),\n",
       " ('next round would hiring manager', 0.2886751345948129),\n",
       " ('professional time punctual asked questions', 0.2886751345948129),\n",
       " ('quite expect quite unprepared called', 0.2886751345948129),\n",
       " ('understand wanted job motivations inclinations', 0.2886751345948129),\n",
       " ('registering short interview feel good', 0.2886751345948129),\n",
       " ('technical interview discussed salary moving', 0.2886751345948129),\n",
       " ('interviewer seemed rushing process hard', 0.2886751345948129),\n",
       " ('recruiter contacted email set phone', 0.2886751345948129),\n",
       " ('rounds technical computational interviewers professional',\n",
       "  0.2886751345948129),\n",
       " ('recruiter helpful provided lot initial', 0.2886751345948129),\n",
       " ('looking specific answer response registering', 0.2886751345948129),\n",
       " ('round interview python questions answer', 0.2886751345948129),\n",
       " ('interviewers professional time punctual asked', 0.2886751345948129),\n",
       " ('asked questions understand wanted job', 0.2886751345948129),\n",
       " ('rushing process hard hear questions', 0.2886751345948129),\n",
       " ('specific answer response registering short', 0.2886751345948129),\n",
       " ('london uk interviewer called middle', 0.2886751345948129),\n",
       " ('email set phone interview following', 0.2886751345948129),\n",
       " ('expect quite unprepared called tell', 0.2886751345948129),\n",
       " ('experience pass technical interview discussed', 0.2886751345948129),\n",
       " ('recruiter screening call questions first', 0.2886751345948129),\n",
       " ('seemed rushing process hard hear', 0.2886751345948129),\n",
       " ('contacted email set phone interview', 0.2886751345948129),\n",
       " ('transparent process however next scheduled', 0.2886751345948129),\n",
       " ('salary moving experience explained job', 0.2886751345948129),\n",
       " ('answer response registering short interview', 0.2886751345948129),\n",
       " ('role based london uk interviewer', 0.2886751345948129),\n",
       " ('response registering short interview feel', 0.2886751345948129),\n",
       " ('technical computational interviewers professional time',\n",
       "  0.2886751345948129),\n",
       " ('computational interviewers professional time punctual', 0.2886751345948129),\n",
       " ('lot initial materials preparation transparent', 0.2886751345948129),\n",
       " ('talk culture meta job responsibilities', 0.2773500981126146),\n",
       " ('testing question facebook app feature', 0.2773500981126146),\n",
       " ('professional interview fraud data scientist', 0.2773500981126146),\n",
       " ('headhunter contacted linkedin said would', 0.2773500981126146),\n",
       " ('linkedin said would good fit', 0.2773500981126146),\n",
       " ('cases whether implement function kinds', 0.2773500981126146),\n",
       " ('experience professional interview fraud data', 0.2773500981126146),\n",
       " ('app feature gave overview team', 0.2773500981126146),\n",
       " ('still waiting second round technical', 0.2773500981126146),\n",
       " ('level interview finalize whatever works', 0.2773500981126146),\n",
       " ('spoke recruiter background experience professional', 0.2773500981126146),\n",
       " ('culture meta job responsibilities bit', 0.2773500981126146),\n",
       " ('call resume questions one hypothesis', 0.2773500981126146),\n",
       " ('mode leecode business cases whether', 0.2773500981126146),\n",
       " ('experience interest role lots talk', 0.2773500981126146),\n",
       " ('one hypothesis testing question facebook', 0.2773500981126146),\n",
       " ('completed behavioral interview bad emphasis', 0.2773500981126146),\n",
       " ('role lots talk culture meta', 0.2773500981126146),\n",
       " ('internal headhunter contacted linkedin said', 0.2773500981126146),\n",
       " ('interview finalize whatever works data', 0.2773500981126146),\n",
       " ('business cases whether implement function', 0.2773500981126146),\n",
       " ('emphasis past experience interest role', 0.2773500981126146),\n",
       " ('sql questions easy mode leecode', 0.2773500981126146),\n",
       " ('resume questions one hypothesis testing', 0.2773500981126146),\n",
       " ('interest role lots talk culture', 0.2773500981126146),\n",
       " ('interview fraud data scientist received', 0.2773500981126146),\n",
       " ('leecode business cases whether implement', 0.2773500981126146),\n",
       " ('product level interview finalize whatever', 0.2773500981126146),\n",
       " ('brief interview schedule technical interview', 0.2773500981126146),\n",
       " ('interview bad emphasis past experience', 0.2773500981126146),\n",
       " ('round interview still waiting second', 0.2773500981126146),\n",
       " ('good fit gave brief interview', 0.2773500981126146),\n",
       " ('technical product level interview finalize', 0.2773500981126146),\n",
       " ('scientist received lot information learn', 0.2773500981126146),\n",
       " ('gave brief interview schedule technical', 0.2773500981126146),\n",
       " ('said would good fit gave', 0.2773500981126146),\n",
       " ('gave overview team process look', 0.2773500981126146),\n",
       " ('recruiter call resume questions one', 0.2773500981126146),\n",
       " ('feature gave overview team process', 0.2773500981126146),\n",
       " ('bad emphasis past experience interest', 0.2773500981126146),\n",
       " ('questions one hypothesis testing question', 0.2773500981126146),\n",
       " ('second round technical product level', 0.2773500981126146),\n",
       " ('whatever works data set coming', 0.2773500981126146),\n",
       " ('meta job responsibilities bit vague', 0.2773500981126146),\n",
       " ('implement function kinds metrics would', 0.2773500981126146),\n",
       " ('whether implement function kinds metrics', 0.2773500981126146),\n",
       " ('past experience interest role lots', 0.2773500981126146),\n",
       " ('information learn professional interview irrelevant', 0.2773500981126146),\n",
       " ('recruiter background experience professional interview',\n",
       "  0.2773500981126146),\n",
       " ('background experience professional interview fraud', 0.2773500981126146),\n",
       " ('received lot information learn professional', 0.2773500981126146),\n",
       " ('lot information learn professional interview', 0.2773500981126146),\n",
       " ('st round interview still waiting', 0.2773500981126146),\n",
       " ('finalize whatever works data set', 0.2773500981126146),\n",
       " ('kinds metrics would pick would', 0.2773500981126146),\n",
       " ('lots talk culture meta job', 0.2773500981126146),\n",
       " ('would pick would ab testing', 0.2773500981126146),\n",
       " ('easy mode leecode business cases', 0.2773500981126146),\n",
       " ('metrics would pick would ab', 0.2773500981126146),\n",
       " ('waiting second round technical product', 0.2773500981126146),\n",
       " ('hypothesis testing question facebook app', 0.2773500981126146),\n",
       " ('behavioral interview bad emphasis past', 0.2773500981126146),\n",
       " ('technical interview data science employee', 0.2773500981126146),\n",
       " ('function kinds metrics would pick', 0.2773500981126146),\n",
       " ('overview team process look hiring', 0.2773500981126146),\n",
       " ('round technical product level interview', 0.2773500981126146),\n",
       " ('contacted linkedin said would good', 0.2773500981126146),\n",
       " ('facebook app feature gave overview', 0.2773500981126146),\n",
       " ('question facebook app feature gave', 0.2773500981126146),\n",
       " ('data scientist received lot information', 0.2773500981126146),\n",
       " ('interview schedule technical interview data', 0.2773500981126146),\n",
       " ('fraud data scientist received lot', 0.2773500981126146),\n",
       " ('schedule technical interview data science', 0.2773500981126146),\n",
       " ('would good fit gave brief', 0.2773500981126146),\n",
       " ('interview still waiting second round', 0.2773500981126146),\n",
       " ('fit gave brief interview schedule', 0.2773500981126146),\n",
       " ('questions easy mode leecode business', 0.2773500981126146),\n",
       " ('first spoke recruiter background experience', 0.2773500981126146),\n",
       " ('july got rejected filling survey', 0.2672612419124244),\n",
       " ('online scheduled recruiter phone interview', 0.2672612419124244),\n",
       " ('spent product mindset would solve', 0.2672612419124244),\n",
       " ('selfintroduction time theres minutes left', 0.2672612419124244),\n",
       " ('interview canceled without providing supporting', 0.2672612419124244),\n",
       " ('manager interview technical component product', 0.2672612419124244),\n",
       " ('interview cool sql questions lot', 0.2672612419124244),\n",
       " ('minutes one minutes total selfintroduction', 0.2672612419124244),\n",
       " ('lot time spent product mindset', 0.2672612419124244),\n",
       " ('cool nice questions interview cool', 0.2672612419124244),\n",
       " ('cool sql questions lot time', 0.2672612419124244),\n",
       " ('messed algorithm question didnt make', 0.2672612419124244),\n",
       " ('interview tests sql algorithms ml', 0.2672612419124244),\n",
       " ('might layoffs coming however recruiter', 0.2672612419124244),\n",
       " ('interview technical component product question', 0.2672612419124244),\n",
       " ('mindset would solve problem part', 0.2672612419124244),\n",
       " ('contacted recruiter linkedin scheduled phone', 0.2672612419124244),\n",
       " ('coming however recruiter unprofessional dealings', 0.2672612419124244),\n",
       " ('survey visa status good encourage', 0.2672612419124244),\n",
       " ('technical interview tests sql algorithms', 0.2672612419124244),\n",
       " ('supporting reasons accommodations hindsight understand',\n",
       "  0.2672612419124244),\n",
       " ('study minutes one minutes total', 0.2672612419124244),\n",
       " ('minutes total selfintroduction time theres', 0.2672612419124244),\n",
       " ('linkedin scheduled phone call spoke', 0.2672612419124244),\n",
       " ('ml stats felt messed algorithm', 0.2672612419124244),\n",
       " ('visa status good encourage ed', 0.2672612419124244),\n",
       " ('super cool nice questions interview', 0.2672612419124244),\n",
       " ('interview manager interview technical component', 0.2672612419124244),\n",
       " ('interview july got rejected filling', 0.2672612419124244),\n",
       " ('next stage interview manager interview', 0.2672612419124244),\n",
       " ('interview includes sql question case', 0.2672612419124244),\n",
       " ('nice questions interview cool sql', 0.2672612419124244),\n",
       " ('case study minutes one minutes', 0.2672612419124244),\n",
       " ('one minutes total selfintroduction time', 0.2672612419124244),\n",
       " ('includes sql question case study', 0.2672612419124244),\n",
       " ('sql question case study minutes', 0.2672612419124244),\n",
       " ('canceled without providing supporting reasons', 0.2672612419124244),\n",
       " ('time theres minutes left questions', 0.2672612419124244),\n",
       " ('stage interview manager interview technical', 0.2672612419124244),\n",
       " ('questions lot time spent product', 0.2672612419124244),\n",
       " ('questions interview cool sql questions', 0.2672612419124244),\n",
       " ('understand reason might layoffs coming', 0.2672612419124244),\n",
       " ('question didnt make next round', 0.2672612419124244),\n",
       " ('question case study minutes one', 0.2672612419124244),\n",
       " ('time spent product mindset would', 0.2672612419124244),\n",
       " ('first round interview includes sql', 0.2672612419124244),\n",
       " ('scheduled phone call spoke bit', 0.2672612419124244),\n",
       " ('providing supporting reasons accommodations hindsight', 0.2672612419124244),\n",
       " ('bit background next stage interview', 0.2672612419124244),\n",
       " ('stats felt messed algorithm question', 0.2672612419124244),\n",
       " ('algorithm question didnt make next', 0.2672612419124244),\n",
       " ('scheduled recruiter phone interview july', 0.2672612419124244),\n",
       " ('background next stage interview manager', 0.2672612419124244),\n",
       " ('filling survey visa status good', 0.2672612419124244),\n",
       " ('algorithms ml stats felt messed', 0.2672612419124244),\n",
       " ('without providing supporting reasons accommodations', 0.2672612419124244),\n",
       " ('spoke bit background next stage', 0.2672612419124244),\n",
       " ('round interview includes sql question', 0.2672612419124244),\n",
       " ('applied online scheduled recruiter phone', 0.2672612419124244),\n",
       " ('sql questions lot time spent', 0.2672612419124244),\n",
       " ('accommodations hindsight understand reason might', 0.2672612419124244),\n",
       " ('rejected filling survey visa status', 0.2672612419124244),\n",
       " ('recruiter phone interview july got', 0.2672612419124244),\n",
       " ('sql algorithms ml stats felt', 0.2672612419124244),\n",
       " ('recruiter linkedin scheduled phone call', 0.2672612419124244),\n",
       " ('recruiter call technical interview tests', 0.2672612419124244),\n",
       " ('reasons accommodations hindsight understand reason', 0.2672612419124244),\n",
       " ('reason might layoffs coming however', 0.2672612419124244),\n",
       " ('total selfintroduction time theres minutes', 0.2672612419124244),\n",
       " ('felt messed algorithm question didnt', 0.2672612419124244),\n",
       " ('good encourage ed apply later', 0.2672612419124244),\n",
       " ('layoffs coming however recruiter unprofessional', 0.2672612419124244),\n",
       " ('day interview canceled without providing', 0.2672612419124244),\n",
       " ('phone interview july got rejected', 0.2672612419124244),\n",
       " ('call technical interview tests sql', 0.2672612419124244),\n",
       " ('would solve problem part team', 0.2672612419124244),\n",
       " ('usual recruiter call technical interview', 0.2672612419124244),\n",
       " ('phone call spoke bit background', 0.2672612419124244),\n",
       " ('hindsight understand reason might layoffs', 0.2672612419124244),\n",
       " ('call spoke bit background next', 0.2672612419124244),\n",
       " ('got rejected filling survey visa', 0.2672612419124244),\n",
       " ('status good encourage ed apply', 0.2672612419124244),\n",
       " ('product mindset would solve problem', 0.2672612419124244),\n",
       " ('tests sql algorithms ml stats', 0.2672612419124244),\n",
       " ('facebook said since means like', 0.25819888974716115),\n",
       " ('two sql questions product sense', 0.25819888974716115),\n",
       " ('interviewer waiting interview end also', 0.25819888974716115),\n",
       " ('also machine learning mins answer', 0.25819888974716115),\n",
       " ('interview hr screening recruiter nice', 0.25819888974716115),\n",
       " ('interest learning experience felt like', 0.25819888974716115),\n",
       " ('solve sql problem interviewer even', 0.25819888974716115),\n",
       " ('contacted recruiter booked first round', 0.25819888974716115),\n",
       " ('however tried solve sql problem', 0.25819888974716115),\n",
       " ('solution development interview person lasted', 0.25819888974716115),\n",
       " ('feedback even entered last round', 0.25819888974716115),\n",
       " ('interviewer racist obviously terrible chances', 0.25819888974716115),\n",
       " ('interviewer nice helpful got stuck', 0.25819888974716115),\n",
       " ('seniority whiteboard questions ranked extremely', 0.25819888974716115),\n",
       " ('technical interview members small medium', 0.25819888974716115),\n",
       " ('terrible chances black latino good', 0.25819888974716115),\n",
       " ('felt like interviewer waiting interview', 0.25819888974716115),\n",
       " ('sql mins product cases mins', 0.25819888974716115),\n",
       " ('email interview asking feedback afterward', 0.25819888974716115),\n",
       " ('extremely easy obnoxiously difficult position', 0.25819888974716115),\n",
       " ('two rounds phone interviews onsite', 0.25819888974716115),\n",
       " ('entire process took two months', 0.25819888974716115),\n",
       " ('even entered last round interviewers', 0.25819888974716115),\n",
       " ('even went kitchen back made', 0.25819888974716115),\n",
       " ('includes interviews minutes long first', 0.25819888974716115),\n",
       " ('tried solve sql problem interviewer', 0.25819888974716115),\n",
       " ('invited site interview interview multiple', 0.25819888974716115),\n",
       " ('two months recruiter nice shared', 0.25819888974716115),\n",
       " ('sending good luck email interview', 0.25819888974716115),\n",
       " ('interviews onsite four persons entire', 0.25819888974716115),\n",
       " ('experience conducted smoothly allowing flexibility', 0.25819888974716115),\n",
       " ('end also asked like experience', 0.25819888974716115),\n",
       " ('experience facebook said since means', 0.25819888974716115),\n",
       " ('interviews minutes long first analytical', 0.25819888974716115),\n",
       " ('experience felt like interviewer waiting', 0.25819888974716115),\n",
       " ('hr screening recruiter nice sending', 0.25819888974716115),\n",
       " ('dates times role much analytical', 0.25819888974716115),\n",
       " ('interviewers overall nice one seemed', 0.25819888974716115),\n",
       " ('also asked like experience facebook', 0.25819888974716115),\n",
       " ('data scientist intern includes interviews', 0.25819888974716115),\n",
       " ('interviewer interest learning experience felt', 0.25819888974716115),\n",
       " ('interviewer even went kitchen back', 0.25819888974716115),\n",
       " ('hour tech interview sql product', 0.25819888974716115),\n",
       " ('interview end also asked like', 0.25819888974716115),\n",
       " ('small medium business team one', 0.25819888974716115),\n",
       " ('thirty minutes interviewer time get', 0.25819888974716115),\n",
       " ('slow get interview feedback even', 0.25819888974716115),\n",
       " ('interview process data scientist intern', 0.25819888974716115),\n",
       " ('interview person lasted hour mins', 0.25819888974716115),\n",
       " ('interview multiple meetings different members', 0.25819888974716115),\n",
       " ('get interview feedback even entered', 0.25819888974716115),\n",
       " ('allowing flexibility choosing dates times', 0.25819888974716115),\n",
       " ('interview feedback even entered last', 0.25819888974716115),\n",
       " ('different members team increasing seniority', 0.25819888974716115),\n",
       " ('interview members small medium business', 0.25819888974716115),\n",
       " ('sense questions two sql questions', 0.25819888974716115),\n",
       " ('site interview interview multiple meetings', 0.25819888974716115),\n",
       " ('got stuck whole interview process', 0.25819888974716115),\n",
       " ('vey standard big company ds', 0.25819888974716115),\n",
       " ('development interview person lasted hour', 0.25819888974716115),\n",
       " ('interview interview multiple meetings different', 0.25819888974716115),\n",
       " ('good experience conducted smoothly allowing', 0.25819888974716115),\n",
       " ('good luck email interview asking', 0.25819888974716115),\n",
       " ('interview process took thirty minutes', 0.25819888974716115),\n",
       " ('times role much analytical data', 0.25819888974716115),\n",
       " ('intern includes interviews minutes long', 0.25819888974716115),\n",
       " ('smoothly allowing flexibility choosing dates', 0.25819888974716115),\n",
       " ('took two months recruiter nice', 0.25819888974716115),\n",
       " ('good riddance thats culture guess', 0.25819888974716115),\n",
       " ('first analytical question sql questions', 0.25819888974716115),\n",
       " ('took thirty minutes interviewer time', 0.25819888974716115),\n",
       " ('first round hour tech interview', 0.25819888974716115),\n",
       " ('technical interview tested python sql', 0.25819888974716115),\n",
       " ('interview asian interviewer racist obviously', 0.25819888974716115),\n",
       " ('ds interview asian interviewer racist', 0.25819888974716115),\n",
       " ('interview tested python sql statistics', 0.25819888974716115),\n",
       " ('data science machine learning really', 0.25819888974716115),\n",
       " ('first round tech interview hr', 0.25819888974716115),\n",
       " ('tested python sql statistics also', 0.25819888974716115),\n",
       " ('first round technical interview tested', 0.25819888974716115),\n",
       " ('helpful got stuck whole interview', 0.25819888974716115),\n",
       " ('flexibility choosing dates times role', 0.25819888974716115),\n",
       " ('interview sql product sense questions', 0.25819888974716115),\n",
       " ('four persons entire process took', 0.25819888974716115),\n",
       " ('increasing seniority whiteboard questions ranked', 0.25819888974716115),\n",
       " ('last round interviewers overall nice', 0.25819888974716115),\n",
       " ('friend first round hour tech', 0.25819888974716115),\n",
       " ('learning experience felt like interviewer', 0.25819888974716115),\n",
       " ('analytical question sql questions second', 0.25819888974716115),\n",
       " ('asked like experience facebook said', 0.25819888974716115),\n",
       " ('questions two sql questions product', 0.25819888974716115),\n",
       " ('whiteboard questions ranked extremely easy', 0.25819888974716115),\n",
       " ('persons entire process took two', 0.25819888974716115),\n",
       " ('stuck whole interview process took', 0.25819888974716115),\n",
       " ('whole interview process took thirty', 0.25819888974716115),\n",
       " ('waiting interview end also asked', 0.25819888974716115),\n",
       " ('studies interviewer nice helpful got', 0.25819888974716115),\n",
       " ('racist obviously terrible chances black', 0.25819888974716115),\n",
       " ('ranked extremely easy obnoxiously difficult', 0.25819888974716115),\n",
       " ('overall nice one seemed impatient', 0.25819888974716115),\n",
       " ('onsite four persons entire process', 0.25819888974716115),\n",
       " ('really slow get interview feedback', 0.25819888974716115),\n",
       " ('recruiter booked first round tech', 0.25819888974716115),\n",
       " ('one sql one probability one', 0.25819888974716115),\n",
       " ('one solution development interview person', 0.25819888974716115),\n",
       " ('one seemed impatient really paying', 0.25819888974716115),\n",
       " ('screening recruiter nice sending good', 0.25819888974716115),\n",
       " ('one probability one solution development', 0.25819888974716115),\n",
       " ('recruiter nice sending good luck', 0.25819888974716115),\n",
       " ('recruiter nice shared prep guide', 0.25819888974716115),\n",
       " ('obviously terrible chances black latino', 0.25819888974716115),\n",
       " ('sql statistics also machine learning', 0.25819888974716115),\n",
       " ('nice sending good luck email', 0.25819888974716115),\n",
       " ('nice one seemed impatient really', 0.25819888974716115),\n",
       " ('nice helpful got stuck whole', 0.25819888974716115),\n",
       " ('entered last round interviewers overall', 0.25819888974716115),\n",
       " ('cases mins sa however tried', 0.25819888974716115),\n",
       " ('phone interviews onsite four persons', 0.25819888974716115),\n",
       " ('questions second product question statistics', 0.25819888974716115),\n",
       " ('questions ranked extremely easy obnoxiously', 0.25819888974716115),\n",
       " ('process took two months recruiter', 0.25819888974716115),\n",
       " ('big company ds interview asian', 0.25819888974716115),\n",
       " ('python sql statistics also machine', 0.25819888974716115),\n",
       " ('black latino good riddance thats', 0.25819888974716115),\n",
       " ('statistics also machine learning mins', 0.25819888974716115),\n",
       " ('science machine learning really used', 0.25819888974716115),\n",
       " ('product sense questions two sql', 0.25819888974716115),\n",
       " ('booked first round tech interview', 0.25819888974716115),\n",
       " ('product sense question interviewer patient', 0.25819888974716115),\n",
       " ('product cases mins sa however', 0.25819888974716115),\n",
       " ('went kitchen back made lunch', 0.25819888974716115),\n",
       " ('question sql questions second product', 0.25819888974716115),\n",
       " ('process two rounds phone interviews', 0.25819888974716115),\n",
       " ('process took thirty minutes interviewer', 0.25819888974716115),\n",
       " ('questions python like leetcode medium', 0.25819888974716115),\n",
       " ('process really slow get interview', 0.25819888974716115),\n",
       " ('questions case studies interviewer nice', 0.25819888974716115),\n",
       " ('business team one sql one', 0.25819888974716115),\n",
       " ('scientist intern includes interviews minutes', 0.25819888974716115),\n",
       " ('process data scientist intern includes', 0.25819888974716115),\n",
       " ('problem interviewer even went kitchen', 0.25819888974716115),\n",
       " ('latino good riddance thats culture', 0.25819888974716115),\n",
       " ('probability one solution development interview', 0.25819888974716115),\n",
       " ('sql product sense questions two', 0.25819888974716115),\n",
       " ('analytical data science machine learning', 0.25819888974716115),\n",
       " ('standard big company ds interview', 0.25819888974716115),\n",
       " ('questions product sense question interviewer', 0.25819888974716115),\n",
       " ('second product question statistics questions', 0.25819888974716115),\n",
       " ('case studies interviewer nice helpful', 0.25819888974716115),\n",
       " ('round hour tech interview sql', 0.25819888974716115),\n",
       " ('sql questions case studies interviewer', 0.25819888974716115),\n",
       " ('members small medium business team', 0.25819888974716115),\n",
       " ('meetings different members team increasing', 0.25819888974716115),\n",
       " ('medium business team one sql', 0.25819888974716115),\n",
       " ('role much analytical data science', 0.25819888974716115),\n",
       " ('sql problem interviewer even went', 0.25819888974716115),\n",
       " ('multiple meetings different members team', 0.25819888974716115),\n",
       " ('machine learning really used asked', 0.25819888974716115),\n",
       " ('machine learning mins answer questions', 0.25819888974716115),\n",
       " ('luck email interview asking feedback', 0.25819888974716115),\n",
       " ('team increasing seniority whiteboard questions', 0.25819888974716115),\n",
       " ('team one sql one probability', 0.25819888974716115),\n",
       " ('long process two rounds phone', 0.25819888974716115),\n",
       " ('round interviewers overall nice one', 0.25819888974716115),\n",
       " ('long first analytical question sql', 0.25819888974716115),\n",
       " ('company ds interview asian interviewer', 0.25819888974716115),\n",
       " ('round tech interview hr screening', 0.25819888974716115),\n",
       " ('seemed impatient really paying attention', 0.25819888974716115),\n",
       " ('round technical interview tested python', 0.25819888974716115),\n",
       " ('like interviewer waiting interview end', 0.25819888974716115),\n",
       " ('like experience facebook said since', 0.25819888974716115),\n",
       " ('sql one probability one solution', 0.25819888974716115),\n",
       " ('tech interview hr screening recruiter', 0.25819888974716115),\n",
       " ('conducted smoothly allowing flexibility choosing', 0.25819888974716115),\n",
       " ('rounds phone interviews onsite four', 0.25819888974716115),\n",
       " ('learning mins answer questions python', 0.25819888974716115),\n",
       " ('tech interview sql product sense', 0.25819888974716115),\n",
       " ('sa however tried solve sql', 0.25819888974716115),\n",
       " ('members team increasing seniority whiteboard', 0.25819888974716115),\n",
       " ('python like leetcode medium level', 0.25819888974716115),\n",
       " ('minutes interviewer time get offer', 0.25819888974716115),\n",
       " ('mins sa however tried solve', 0.25819888974716115),\n",
       " ('mins answer questions python like', 0.25819888974716115),\n",
       " ('months recruiter nice shared prep', 0.25819888974716115),\n",
       " ('referred friend first round hour', 0.25819888974716115),\n",
       " ('chances black latino good riddance', 0.25819888974716115),\n",
       " ('answer questions python like leetcode', 0.25819888974716115),\n",
       " ('minutes long first analytical question', 0.25819888974716115),\n",
       " ('mins sql mins product cases', 0.25819888974716115),\n",
       " ('much analytical data science machine', 0.25819888974716115),\n",
       " ('sql questions second product question', 0.25819888974716115),\n",
       " ('asian interviewer racist obviously terrible', 0.25819888974716115),\n",
       " ('choosing dates times role much', 0.25819888974716115),\n",
       " ('sql questions product sense question', 0.25819888974716115),\n",
       " ('mins product cases mins sa', 0.25819888974716115),\n",
       " ('question regarding pricing interview took', 0.25),\n",
       " ('samsong phone salesnot mentioned monthly', 0.25),\n",
       " ('quite bit process questions mostly', 0.25),\n",
       " ('regarding pricing interview took minutes', 0.25),\n",
       " ('question introduce related projects experiences', 0.25),\n",
       " ('related projects experiences academic work', 0.25),\n",
       " ('rounds first screening recruiter live', 0.25),\n",
       " ('related questions hr first question', 0.25),\n",
       " ('followed strategy question regarding pricing', 0.25),\n",
       " ('rounds people smart knowledgable learnt', 0.25),\n",
       " ('question followed strategy question regarding', 0.25),\n",
       " ('question determine best friends facebook', 0.25),\n",
       " ('question well sql part fine', 0.25),\n",
       " ('etc nice interview process overall', 0.25),\n",
       " ('question determine best friend max', 0.25),\n",
       " ('sql python questions tech screen', 0.25),\n",
       " ('pythonsql questions final third round', 0.25),\n",
       " ('rude attitude easy sql python', 0.25),\n",
       " ('experiences academic work asked metric', 0.25),\n",
       " ('smart knowledgable learnt quite bit', 0.25),\n",
       " ('recruiter live technical round pythonsql', 0.25),\n",
       " ('questions etc nice interview process', 0.25),\n",
       " ('recruiter helpful providing details need', 0.25),\n",
       " ('questions mostly related sql product', 0.25),\n",
       " ('final third round case study', 0.25),\n",
       " ('experience however interviewer seem totally', 0.25),\n",
       " ('questions sql coding product analysis', 0.25),\n",
       " ('rate location past project ab', 0.25),\n",
       " ('first asked sql question followed', 0.25),\n",
       " ('rate recall metric explain scratch', 0.25),\n",
       " ('took minutes overall positive experience', 0.25),\n",
       " ('first one questions werent difficult', 0.25),\n",
       " ('first question introduce related projects', 0.25),\n",
       " ('round case study style asking', 0.25),\n",
       " ('questions like rate location past', 0.25),\n",
       " ('round pythonsql questions final third', 0.25),\n",
       " ('questions like predict samsong phone', 0.25),\n",
       " ('first screening recruiter live technical', 0.25),\n",
       " ('questions hr first question introduce', 0.25),\n",
       " ('related sql product sense business', 0.25),\n",
       " ('failed tech screen cancel product', 0.25),\n",
       " ('questions final third round case', 0.25),\n",
       " ('python product sense behavior questions', 0.25),\n",
       " ('first self introduction interviewer main', 0.25),\n",
       " ('questions werent difficult though part', 0.25),\n",
       " ('questions challenging includes sql python', 0.25),\n",
       " ('salesnot mentioned monthly weekly predict', 0.25),\n",
       " ('tech screen cancel product sense', 0.25),\n",
       " ('providing details need interview questions', 0.25),\n",
       " ('part two questions sql coding', 0.25),\n",
       " ('sense interview min prepping days', 0.25),\n",
       " ('monthly weekly predict churn rate', 0.25),\n",
       " ('interview process challenging several rounds', 0.25),\n",
       " ('interview min prepping days canceled', 0.25),\n",
       " ('mostly related sql product sense', 0.25),\n",
       " ('need interview questions challenging includes', 0.25),\n",
       " ('interview long interview couldnt pass', 0.25),\n",
       " ('ab testing impact project metric', 0.25),\n",
       " ('style asking go finding information', 0.25),\n",
       " ('study style asking go finding', 0.25),\n",
       " ('one phone one technical zoom', 0.25),\n",
       " ('interview couldnt pass first one', 0.25),\n",
       " ('one questions werent difficult though', 0.25),\n",
       " ('interview asked questions like predict', 0.25),\n",
       " ('one technical zoom interview long', 0.25),\n",
       " ('intern basic questions like rate', 0.25),\n",
       " ('overall positive experience however interviewer', 0.25),\n",
       " ('minutes overall positive experience however', 0.25),\n",
       " ('interview questions challenging includes sql', 0.25),\n",
       " ('min prepping days canceled unprofessional', 0.25),\n",
       " ('live technical round pythonsql questions', 0.25),\n",
       " ('knowledgable learnt quite bit process', 0.25),\n",
       " ('self introduction interviewer main part', 0.25),\n",
       " ('learnt quite bit process questions', 0.25),\n",
       " ('introduction interviewer main part two', 0.25),\n",
       " ('introduce related projects experiences academic', 0.25),\n",
       " ('like predict samsong phone salesnot', 0.25),\n",
       " ('like rate location past project', 0.25),\n",
       " ('location past project ab testing', 0.25),\n",
       " ('metric question determine best friends', 0.25),\n",
       " ('long interview couldnt pass first', 0.25),\n",
       " ('interviewer main part two questions', 0.25),\n",
       " ('main part two questions sql', 0.25),\n",
       " ('sense behavior questions etc nice', 0.25),\n",
       " ('mentioned monthly weekly predict churn', 0.25),\n",
       " ('interview took minutes overall positive', 0.25),\n",
       " ('sql question followed strategy question', 0.25),\n",
       " ('technical round pythonsql questions final', 0.25),\n",
       " ('pass first one questions werent', 0.25),\n",
       " ('projects experiences academic work asked', 0.25),\n",
       " ('past project ab testing impact', 0.25),\n",
       " ('testing impact project metric question', 0.25),\n",
       " ('process challenging several rounds people', 0.25),\n",
       " ('screen cancel product sense interview', 0.25),\n",
       " ('several rounds people smart knowledgable', 0.25),\n",
       " ('process questions mostly related sql', 0.25),\n",
       " ('third round case study style', 0.25),\n",
       " ('though part return work interview', 0.25),\n",
       " ('sql python product sense behavior', 0.25),\n",
       " ('product analysis didnt answer product', 0.25),\n",
       " ('three rounds first screening recruiter', 0.25),\n",
       " ('product question well sql part', 0.25),\n",
       " ('product sense behavior questions etc', 0.25),\n",
       " ('product sense interview min prepping', 0.25),\n",
       " ('sql coding product analysis didnt', 0.25),\n",
       " ('project ab testing impact project', 0.25),\n",
       " ('given bunch related questions hr', 0.25),\n",
       " ('project metric question determine best', 0.25),\n",
       " ('helpful providing details need interview', 0.25),\n",
       " ('pricing interview took minutes overall', 0.25),\n",
       " ('prescreen intern basic questions like', 0.25),\n",
       " ('phone salesnot mentioned monthly weekly', 0.25),\n",
       " ('screening recruiter live technical round', 0.25),\n",
       " ('people smart knowledgable learnt quite', 0.25),\n",
       " ('includes sql python product sense', 0.25),\n",
       " ('phone interview asked questions like', 0.25),\n",
       " ('impact project metric question determine', 0.25),\n",
       " ('technical zoom interview long interview', 0.25),\n",
       " ('phone one technical zoom interview', 0.25),\n",
       " ('hr phone interview asked questions', 0.25),\n",
       " ('prepping days canceled unprofessional rude', 0.25),\n",
       " ('sql product sense business analytics', 0.25),\n",
       " ('hr first question introduce related', 0.25),\n",
       " ('strategy question regarding pricing interview', 0.25),\n",
       " ('positive experience however interviewer seem', 0.25),\n",
       " ('predict churn rate recall metric', 0.25),\n",
       " ('however interviewer seem totally engaged', 0.25),\n",
       " ('predict samsong phone salesnot mentioned', 0.25),\n",
       " ('metric question determine best friend', 0.25),\n",
       " ('zoom interview long interview couldnt', 0.25),\n",
       " ('coding product analysis didnt answer', 0.25),\n",
       " ('bit process questions mostly related', 0.25),\n",
       " ('determine best friend max metrics', 0.25),\n",
       " ('two questions sql coding product', 0.25),\n",
       " ('unprofessional rude attitude easy sql', 0.25),\n",
       " ('asked metric question determine best', 0.25),\n",
       " ('details need interview questions challenging', 0.25),\n",
       " ('couldnt pass first one questions', 0.25),\n",
       " ('days canceled unprofessional rude attitude', 0.25),\n",
       " ('churn rate recall metric explain', 0.25),\n",
       " ('analysis didnt answer product question', 0.25),\n",
       " ('difficult though part return work', 0.25),\n",
       " ('asked questions like predict samsong', 0.25),\n",
       " ('basic questions like rate location', 0.25),\n",
       " ('cancel product sense interview min', 0.25),\n",
       " ('easy sql python questions tech', 0.25),\n",
       " ('bunch related questions hr first', 0.25),\n",
       " ('werent difficult though part return', 0.25),\n",
       " ('canceled unprofessional rude attitude easy', 0.25),\n",
       " ('didnt answer product question well', 0.25),\n",
       " ('behavior questions etc nice interview', 0.25),\n",
       " ('work asked metric question determine', 0.25),\n",
       " ('academic work asked metric question', 0.25),\n",
       " ('answer product question well sql', 0.25),\n",
       " ('challenging several rounds people smart', 0.25),\n",
       " ('challenging includes sql python product', 0.25),\n",
       " ('asked sql question followed strategy', 0.25),\n",
       " ('weekly predict churn rate recall', 0.25),\n",
       " ('case study style asking go', 0.25),\n",
       " ('attitude easy sql python questions', 0.25),\n",
       " ('looked least interested stubborn clarifying', 0.24253562503633297),\n",
       " ('screen interviewer phone screen looked', 0.24253562503633297),\n",
       " ('process streamlined proceed final round', 0.24253562503633297),\n",
       " ('screen looked least interested stubborn', 0.24253562503633297),\n",
       " ('initial phone call mins asking', 0.24253562503633297),\n",
       " ('screen initial phone call mins', 0.24253562503633297),\n",
       " ('manager used shared screen recruiter', 0.24253562503633297),\n",
       " ('screen human resources simple sql', 0.24253562503633297),\n",
       " ('giving hints providing guidance sql', 0.24253562503633297),\n",
       " ('simple sql questions coding interview', 0.24253562503633297),\n",
       " ('long tedious overall pretty transparent', 0.24253562503633297),\n",
       " ('screen recruiter communicative helpful process', 0.24253562503633297),\n",
       " ('process smooth recommend stellarpeers leetcode', 0.24253562503633297),\n",
       " ('whole process smooth recommend stellarpeers', 0.24253562503633297),\n",
       " ('problems better prepared good communication', 0.24253562503633297),\n",
       " ('two technical sql rounds one', 0.24253562503633297),\n",
       " ('smooth interview process prepare structure', 0.24253562503633297),\n",
       " ('prepared good communication important problems', 0.24253562503633297),\n",
       " ('really try help pass process', 0.24253562503633297),\n",
       " ('type product question interviews whole', 0.24253562503633297),\n",
       " ('pretty transparent expect two technical', 0.24253562503633297),\n",
       " ('previous experience education also told', 0.24253562503633297),\n",
       " ('call mins asking previous experience', 0.24253562503633297),\n",
       " ('mins asking previous experience education', 0.24253562503633297),\n",
       " ('fluently articulate good structure logic', 0.24253562503633297),\n",
       " ('problems hard need speak fluently', 0.24253562503633297),\n",
       " ('screen followed tech screen initial', 0.24253562503633297),\n",
       " ('call discuss role background later', 0.24253562503633297),\n",
       " ('followed tech screen initial phone', 0.24253562503633297),\n",
       " ('process giving hints providing guidance', 0.24253562503633297),\n",
       " ('sql rounds one quantitative round', 0.24253562503633297),\n",
       " ('discuss role background later scheduled', 0.24253562503633297),\n",
       " ('coding interview manager used shared', 0.24253562503633297),\n",
       " ('told next steps remaining process', 0.24253562503633297),\n",
       " ('communicative helpful process streamlined proceed', 0.24253562503633297),\n",
       " ('friendly interviewers could practiced problems', 0.24253562503633297),\n",
       " ('process prepare structure every type', 0.24253562503633297),\n",
       " ('communication important problems hard need', 0.24253562503633297),\n",
       " ('least interested stubborn clarifying doubts', 0.24253562503633297),\n",
       " ('questions tricky interviewer really try', 0.24253562503633297),\n",
       " ('interviewer phone screen looked least', 0.24253562503633297),\n",
       " ('sql questions coding interview manager', 0.24253562503633297),\n",
       " ('hr phone call discuss role', 0.24253562503633297),\n",
       " ('providing guidance sql part fine', 0.24253562503633297),\n",
       " ('better prepared good communication important', 0.24253562503633297),\n",
       " ('questions coding interview manager used', 0.24253562503633297),\n",
       " ('interview process prepare structure every', 0.24253562503633297),\n",
       " ('resources simple sql questions coding', 0.24253562503633297),\n",
       " ('also told next steps remaining', 0.24253562503633297),\n",
       " ('sql part fine long know', 0.24253562503633297),\n",
       " ('human resources simple sql questions', 0.24253562503633297),\n",
       " ('interview manager used shared screen', 0.24253562503633297),\n",
       " ('python questions tricky interviewer really', 0.24253562503633297),\n",
       " ('tedious overall pretty transparent expect', 0.24253562503633297),\n",
       " ('technical phone screen interviewer phone', 0.24253562503633297),\n",
       " ('data analysis round productsensecase study', 0.24253562503633297),\n",
       " ('technical sql rounds one quantitative', 0.24253562503633297),\n",
       " ('important problems hard need speak', 0.24253562503633297),\n",
       " ('quantitative round one data analysis', 0.24253562503633297),\n",
       " ('sql questions smooth interview process', 0.24253562503633297),\n",
       " ('question interviews whole process smooth', 0.24253562503633297),\n",
       " ('technical round python questions tricky', 0.24253562503633297),\n",
       " ('could practiced problems better prepared', 0.24253562503633297),\n",
       " ('interviewer really try help pass', 0.24253562503633297),\n",
       " ('good communication important problems hard', 0.24253562503633297),\n",
       " ('contacted recruiter initial screen followed', 0.24253562503633297),\n",
       " ('questions smooth interview process prepare', 0.24253562503633297),\n",
       " ('good experience friendly interviewers could', 0.24253562503633297),\n",
       " ('used shared screen recruiter communicative', 0.24253562503633297),\n",
       " ('background later scheduled technical phone', 0.24253562503633297),\n",
       " ('prepare structure every type product', 0.24253562503633297),\n",
       " ('product question interviews whole process', 0.24253562503633297),\n",
       " ('later scheduled technical phone screen', 0.24253562503633297),\n",
       " ('tech screen initial phone call', 0.24253562503633297),\n",
       " ('shared screen recruiter communicative helpful', 0.24253562503633297),\n",
       " ('analysis round productsensecase study rounds', 0.24253562503633297),\n",
       " ('guidance sql part fine long', 0.24253562503633297),\n",
       " ('hard need speak fluently articulate', 0.24253562503633297),\n",
       " ('role background later scheduled technical', 0.24253562503633297),\n",
       " ('help pass process giving hints', 0.24253562503633297),\n",
       " ('interviews whole process smooth recommend', 0.24253562503633297),\n",
       " ('helpful process streamlined proceed final', 0.24253562503633297),\n",
       " ('product sql questions smooth interview', 0.24253562503633297),\n",
       " ('hints providing guidance sql part', 0.24253562503633297),\n",
       " ('responsive recruiter product sql questions', 0.24253562503633297),\n",
       " ('contacted hr phone call discuss', 0.24253562503633297),\n",
       " ('interviewers could practiced problems better', 0.24253562503633297),\n",
       " ('scheduled technical phone screen interviewer', 0.24253562503633297),\n",
       " ('initial screen followed tech screen', 0.24253562503633297),\n",
       " ('speak fluently articulate good structure', 0.24253562503633297),\n",
       " ('phone screen interviewer phone screen', 0.24253562503633297),\n",
       " ('round one data analysis round', 0.24253562503633297),\n",
       " ('recruiter product sql questions smooth', 0.24253562503633297),\n",
       " ('part fine long know basics', 0.24253562503633297),\n",
       " ('recruiter initial screen followed tech', 0.24253562503633297),\n",
       " ('recruiter communicative helpful process streamlined', 0.24253562503633297),\n",
       " ('expect two technical sql rounds', 0.24253562503633297),\n",
       " ('rounds one quantitative round one', 0.24253562503633297),\n",
       " ('phone screen human resources simple', 0.24253562503633297),\n",
       " ('one data analysis round productsensecase', 0.24253562503633297),\n",
       " ('phone call mins asking previous', 0.24253562503633297),\n",
       " ('every type product question interviews', 0.24253562503633297),\n",
       " ('phone call discuss role background', 0.24253562503633297),\n",
       " ('overall pretty transparent expect two', 0.24253562503633297),\n",
       " ('practiced problems better prepared good', 0.24253562503633297),\n",
       " ('try help pass process giving', 0.24253562503633297),\n",
       " ('transparent expect two technical sql', 0.24253562503633297),\n",
       " ('asking previous experience education also', 0.24253562503633297),\n",
       " ('structure every type product question', 0.24253562503633297),\n",
       " ('tricky interviewer really try help', 0.24253562503633297),\n",
       " ('round python questions tricky interviewer', 0.24253562503633297),\n",
       " ('pass process giving hints providing', 0.24253562503633297),\n",
       " ('education also told next steps', 0.24253562503633297),\n",
       " ('one quantitative round one data', 0.24253562503633297),\n",
       " ('experience friendly interviewers could practiced', 0.24253562503633297),\n",
       " ('need speak fluently articulate good', 0.24253562503633297),\n",
       " ('phone screen looked least interested', 0.24253562503633297),\n",
       " ('round productsensecase study rounds total', 0.24253562503633297),\n",
       " ('experience education also told next', 0.24253562503633297),\n",
       " ('screening team lead followed minute', 0.23570226039551584),\n",
       " ('asked research experience moved several', 0.23570226039551584),\n",
       " ('detail questions including algorithm machine', 0.23570226039551584),\n",
       " ('hard second phase much harder', 0.23570226039551584),\n",
       " ('onsite interview consists two applied', 0.23570226039551584),\n",
       " ('known kind questions would ask', 0.23570226039551584),\n",
       " ('knowledge must sql must well', 0.23570226039551584),\n",
       " ('last one hour site phase', 0.23570226039551584),\n",
       " ('harder first interview last one', 0.23570226039551584),\n",
       " ('experience moved several product behavioral', 0.23570226039551584),\n",
       " ('several product behavioral questions asked', 0.23570226039551584),\n",
       " ('basic behaviour questions basic sql', 0.23570226039551584),\n",
       " ('kind questions would ask beforehand', 0.23570226039551584),\n",
       " ('level inperson detail questions including', 0.23570226039551584),\n",
       " ('experimentation side statistical knowledge must', 0.23570226039551584),\n",
       " ('explicit behavioral interview part although', 0.23570226039551584),\n",
       " ('sql coding genearl simple average', 0.23570226039551584),\n",
       " ('team lead followed minute tech', 0.23570226039551584),\n",
       " ('phone screen site round combination', 0.23570226039551584),\n",
       " ('building really cool took months', 0.23570226039551584),\n",
       " ('long sql mlrelated questions wish', 0.23570226039551584),\n",
       " ('combination sql statisticsprobability productcase study',\n",
       "  0.23570226039551584),\n",
       " ('product behavioral questions asked questions', 0.23570226039551584),\n",
       " ('simple average level inperson detail', 0.23570226039551584),\n",
       " ('one stat one coding explicit', 0.23570226039551584),\n",
       " ('screen site round combination sql', 0.23570226039551584),\n",
       " ('sql question hard second phase', 0.23570226039551584),\n",
       " ('didnt get nothing else share', 0.23570226039551584),\n",
       " ('side statistical knowledge must sql', 0.23570226039551584),\n",
       " ('like identify close friends social', 0.23570226039551584),\n",
       " ('rush four mins interviews mainly', 0.23570226039551584),\n",
       " ('would watch mock interviews youtube', 0.23570226039551584),\n",
       " ('tech assessment covered sql theoretical', 0.23570226039551584),\n",
       " ('product experimentation side statistical knowledge', 0.23570226039551584),\n",
       " ('must well structured feedback session', 0.23570226039551584),\n",
       " ('second hours challenging sql one', 0.23570226039551584),\n",
       " ('tech assessment minute ds core', 0.23570226039551584),\n",
       " ('applied ds interview one stat', 0.23570226039551584),\n",
       " ('lead followed minute tech assessment', 0.23570226039551584),\n",
       " ('interviews youtube grab better sense', 0.23570226039551584),\n",
       " ('basic sql coding genearl simple', 0.23570226039551584),\n",
       " ('questions like identify close friends', 0.23570226039551584),\n",
       " ('beforehand would watch mock interviews', 0.23570226039551584),\n",
       " ('round total hr phone call', 0.23570226039551584),\n",
       " ('identify close friends social media', 0.23570226039551584),\n",
       " ('interview last one hour site', 0.23570226039551584),\n",
       " ('would ask beforehand would watch', 0.23570226039551584),\n",
       " ('qa minute case study tech', 0.23570226039551584),\n",
       " ('questions basic sql coding genearl', 0.23570226039551584),\n",
       " ('questions asked questions like identify', 0.23570226039551584),\n",
       " ('behaviour questions basic sql coding', 0.23570226039551584),\n",
       " ('research experience moved several product', 0.23570226039551584),\n",
       " ('statistical knowledge must sql must', 0.23570226039551584),\n",
       " ('behavioral questions asked questions like', 0.23570226039551584),\n",
       " ('sql mlrelated questions wish known', 0.23570226039551584),\n",
       " ('interview consists two applied ds', 0.23570226039551584),\n",
       " ('behavioral interview part although feel', 0.23570226039551584),\n",
       " ('ask beforehand would watch mock', 0.23570226039551584),\n",
       " ('went smooth quite long sql', 0.23570226039551584),\n",
       " ('sql must well structured feedback', 0.23570226039551584),\n",
       " ('question hard second phase much', 0.23570226039551584),\n",
       " ('intense process everyone friendly building', 0.23570226039551584),\n",
       " ('inperson detail questions including algorithm', 0.23570226039551584),\n",
       " ('stat one coding explicit behavioral', 0.23570226039551584),\n",
       " ('part although feel potentially failed', 0.23570226039551584),\n",
       " ('two applied ds interview one', 0.23570226039551584),\n",
       " ('consists two applied ds interview', 0.23570226039551584),\n",
       " ('phase much harder first interview', 0.23570226039551584),\n",
       " ('second phase much harder first', 0.23570226039551584),\n",
       " ('interviews mainly focused product experimentation', 0.23570226039551584),\n",
       " ('productcase study pretty intense process', 0.23570226039551584),\n",
       " ('questions including algorithm machine learning', 0.23570226039551584),\n",
       " ('recruiter nice interview process rush', 0.23570226039551584),\n",
       " ('asked questions like identify close', 0.23570226039551584),\n",
       " ('study pretty intense process everyone', 0.23570226039551584),\n",
       " ('wish known kind questions would', 0.23570226039551584),\n",
       " ('hour site phase second hours', 0.23570226039551584),\n",
       " ('cool took months finish whole', 0.23570226039551584),\n",
       " ('core qa minute case study', 0.23570226039551584),\n",
       " ('statisticsprobability productcase study pretty intense',\n",
       "  0.23570226039551584),\n",
       " ('hr phone call basic behaviour', 0.23570226039551584),\n",
       " ('phone call basic behaviour questions', 0.23570226039551584),\n",
       " ('phase sql question hard second', 0.23570226039551584),\n",
       " ('phase second hours challenging sql', 0.23570226039551584),\n",
       " ('interview process rush four mins', 0.23570226039551584),\n",
       " ('everyone friendly building really cool', 0.23570226039551584),\n",
       " ('although feel potentially failed culture', 0.23570226039551584),\n",
       " ('interview part although feel potentially', 0.23570226039551584),\n",
       " ('interview one stat one coding', 0.23570226039551584),\n",
       " ('questions wish known kind questions', 0.23570226039551584),\n",
       " ('passed first phase sql question', 0.23570226039551584),\n",
       " ('focused product experimentation side statistical', 0.23570226039551584),\n",
       " ('media didnt get nothing else', 0.23570226039551584),\n",
       " ('process rush four mins interviews', 0.23570226039551584),\n",
       " ('one coding explicit behavioral interview', 0.23570226039551584),\n",
       " ('phone screening team lead followed', 0.23570226039551584),\n",
       " ('feel potentially failed culture fit', 0.23570226039551584),\n",
       " ('assessment covered sql theoretical probabilitystats', 0.23570226039551584),\n",
       " ('virtual onsite interview consists two', 0.23570226039551584),\n",
       " ('minute case study tech assessment', 0.23570226039551584),\n",
       " ('watch mock interviews youtube grab', 0.23570226039551584),\n",
       " ('friendly building really cool took', 0.23570226039551584),\n",
       " ('minute ds core qa minute', 0.23570226039551584),\n",
       " ('first phase sql question hard', 0.23570226039551584),\n",
       " ('minute tech assessment minute ds', 0.23570226039551584),\n",
       " ('round combination sql statisticsprobability productcase',\n",
       "  0.23570226039551584),\n",
       " ('sql statisticsprobability productcase study pretty', 0.23570226039551584),\n",
       " ('site round combination sql statisticsprobability', 0.23570226039551584),\n",
       " ('nice interview process rush four', 0.23570226039551584),\n",
       " ('pretty intense process everyone friendly', 0.23570226039551584),\n",
       " ('study tech assessment covered sql', 0.23570226039551584),\n",
       " ('coding explicit behavioral interview part', 0.23570226039551584),\n",
       " ('coding genearl simple average level', 0.23570226039551584),\n",
       " ('minutes phone screening team lead', 0.23570226039551584),\n",
       " ('mock interviews youtube grab better', 0.23570226039551584),\n",
       " ('mlrelated questions wish known kind', 0.23570226039551584),\n",
       " ('ds interview one stat one', 0.23570226039551584),\n",
       " ('assessment minute ds core qa', 0.23570226039551584),\n",
       " ('case study tech assessment covered', 0.23570226039551584),\n",
       " ('ds core qa minute case', 0.23570226039551584),\n",
       " ('really cool took months finish', 0.23570226039551584),\n",
       " ('average level inperson detail questions', 0.23570226039551584),\n",
       " ('friends social media didnt get', 0.23570226039551584),\n",
       " ('four mins interviews mainly focused', 0.23570226039551584),\n",
       " ('one hour site phase second', 0.23570226039551584),\n",
       " ('much harder first interview last', 0.23570226039551584),\n",
       " ('call basic behaviour questions basic', 0.23570226039551584),\n",
       " ('first asked research experience moved', 0.23570226039551584),\n",
       " ('quite long sql mlrelated questions', 0.23570226039551584),\n",
       " ('mainly focused product experimentation side', 0.23570226039551584),\n",
       " ('process everyone friendly building really', 0.23570226039551584),\n",
       " ('close friends social media didnt', 0.23570226039551584),\n",
       " ('followed minute tech assessment minute', 0.23570226039551584),\n",
       " ('questions would ask beforehand would', 0.23570226039551584),\n",
       " ('site phase second hours challenging', 0.23570226039551584),\n",
       " ('genearl simple average level inperson', 0.23570226039551584),\n",
       " ('first interview last one hour', 0.23570226039551584),\n",
       " ('smooth quite long sql mlrelated', 0.23570226039551584),\n",
       " ('moved several product behavioral questions', 0.23570226039551584),\n",
       " ('total hr phone call basic', 0.23570226039551584),\n",
       " ('mins interviews mainly focused product', 0.23570226039551584),\n",
       " ('took months finish whole process', 0.23570226039551584),\n",
       " ('social media didnt get nothing', 0.23570226039551584),\n",
       " ('must sql must well structured', 0.23570226039551584),\n",
       " ('programming language walk problem answer', 0.22941573387056177),\n",
       " ('pretty structured knew expect interview', 0.22941573387056177),\n",
       " ('interview process step followed phone', 0.22941573387056177),\n",
       " ('step followed phone technical interview', 0.22941573387056177),\n",
       " ('case study related meta behavioral', 0.22941573387056177),\n",
       " ('interview process pick programming language', 0.22941573387056177),\n",
       " ('technical interview last session several', 0.22941573387056177),\n",
       " ('technical interview include sql product', 0.22941573387056177),\n",
       " ('projects two onsite interviews entire', 0.22941573387056177),\n",
       " ('mins interviewee ask interviewer questions', 0.22941573387056177),\n",
       " ('response hr two days phone', 0.22941573387056177),\n",
       " ('problem answer would address subquestion', 0.22941573387056177),\n",
       " ('video conference first session took', 0.22941573387056177),\n",
       " ('around one month get response', 0.22941573387056177),\n",
       " ('overall enjoyed process two rounds', 0.22941573387056177),\n",
       " ('round different hour rounds testing', 0.22941573387056177),\n",
       " ('clear indication felt like odds', 0.22941573387056177),\n",
       " ('round consisted technical behaviorial questions', 0.22941573387056177),\n",
       " ('choosing normal distribution questions panel', 0.22941573387056177),\n",
       " ('interviewee ask interviewer questions end', 0.22941573387056177),\n",
       " ('response rejection clear indication felt', 0.22941573387056177),\n",
       " ('interview really moving fast first', 0.22941573387056177),\n",
       " ('interviewer gave chance ask questions', 0.22941573387056177),\n",
       " ('couple days come back result', 0.22941573387056177),\n",
       " ('via video conference first session', 0.22941573387056177),\n",
       " ('rounds final round consisted technical', 0.22941573387056177),\n",
       " ('stats product sense problem solving', 0.22941573387056177),\n",
       " ('technical non technical variety skills', 0.22941573387056177),\n",
       " ('question final round rounds total', 0.22941573387056177),\n",
       " ('query along technical questions machine', 0.22941573387056177),\n",
       " ('behaviorial questions meet team members', 0.22941573387056177),\n",
       " ('behavioral questions beginning introduction mins', 0.22941573387056177),\n",
       " ('new job refused recruiter asked', 0.22941573387056177),\n",
       " ('interview consisting several rounds final', 0.22941573387056177),\n",
       " ('interview coding interview analyze network', 0.22941573387056177),\n",
       " ('network facebook would prepare data', 0.22941573387056177),\n",
       " ('moving fast first round technical', 0.22941573387056177),\n",
       " ('past projects two onsite interviews', 0.22941573387056177),\n",
       " ('round final interview consisting several', 0.22941573387056177),\n",
       " ('analytics questions business case study', 0.22941573387056177),\n",
       " ('multiple questions related past projects', 0.22941573387056177),\n",
       " ('interview analyze network facebook would', 0.22941573387056177),\n",
       " ('round rounds total sql stats', 0.22941573387056177),\n",
       " ('technical questions machine learning model', 0.22941573387056177),\n",
       " ('prepare data analyze questions followed', 0.22941573387056177),\n",
       " ...]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaprocess_vectorizer = TfidfVectorizer(ngram_range=(5,5), min_df=0.001, max_df = 0.75)\n",
    "meta_vectorized_process = pd.DataFrame(metaprocess_vectorizer.fit_transform(meta_process_df['Process']).toarray(), columns = metaprocess_vectorizer.get_feature_names_out())\n",
    "meta_vectorized_process.loc['Total'] = meta_vectorized_process.sum(numeric_only=True, axis=0)\n",
    "meta_vectorized_process = meta_vectorized_process.sort_values(meta_vectorized_process.last_valid_index(), axis=1, ascending=False)\n",
    "metaprocess_sorted_word_list = [(col, meta_vectorized_process[col].iloc[-1]) for col in meta_vectorized_process.columns]\n",
    "metaprocess_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple TFIDF Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process takes long get feedback', 0.31622776601683794),\n",
       " ('interviewer well prepared time short', 0.31622776601683794),\n",
       " ('rough process takes long get', 0.31622776601683794),\n",
       " ('well prepared time short rough', 0.31622776601683794),\n",
       " ('length questions broad interviewer well', 0.31622776601683794),\n",
       " ('questions broad interviewer well prepared', 0.31622776601683794),\n",
       " ('broad interviewer well prepared time', 0.31622776601683794),\n",
       " ('time short rough process takes', 0.31622776601683794),\n",
       " ('prepared time short rough process', 0.31622776601683794),\n",
       " ('short rough process takes long', 0.31622776601683794),\n",
       " ('people interviewed two days crazy', 0.2886751345948129),\n",
       " ('interviewed two days crazy variety', 0.2886751345948129),\n",
       " ('statistical questions liked smart interviewers', 0.2886751345948129),\n",
       " ('screening next stage coding interview', 0.2886751345948129),\n",
       " ('interview finally greeted hiring board', 0.2886751345948129),\n",
       " ('asked teasers programming questions statistical', 0.2886751345948129),\n",
       " ('interview followed whiteboard interview finally', 0.2886751345948129),\n",
       " ('crazy variety questions asked teasers', 0.2886751345948129),\n",
       " ('programming questions statistical questions liked', 0.2886751345948129),\n",
       " ('stage coding interview followed whiteboard', 0.2886751345948129),\n",
       " ('stage phone screening next stage', 0.2886751345948129),\n",
       " ('stages first stage phone screening', 0.2886751345948129),\n",
       " ('whiteboard interview finally greeted hiring', 0.2886751345948129),\n",
       " ('teasers programming questions statistical questions', 0.2886751345948129),\n",
       " ('questions statistical questions liked smart', 0.2886751345948129),\n",
       " ('first stage phone screening next', 0.2886751345948129),\n",
       " ('next stage coding interview followed', 0.2886751345948129),\n",
       " ('coding interview followed whiteboard interview', 0.2886751345948129),\n",
       " ('followed whiteboard interview finally greeted', 0.2886751345948129),\n",
       " ('two days crazy variety questions', 0.2886751345948129),\n",
       " ('questions asked teasers programming questions', 0.2886751345948129),\n",
       " ('days crazy variety questions asked', 0.2886751345948129),\n",
       " ('variety questions asked teasers programming', 0.2886751345948129),\n",
       " ('phone screening next stage coding', 0.2886751345948129),\n",
       " ('positive constructive communication positive interviewer',\n",
       "  0.2773500981126146),\n",
       " ('positive interviewer concept questions asked', 0.2773500981126146),\n",
       " ('interviewer concept questions asked identify', 0.2773500981126146),\n",
       " ('technical questions one week hiring', 0.2773500981126146),\n",
       " ('virtual onsite walk resume asking', 0.2773500981126146),\n",
       " ('asked identify issues relate data', 0.2773500981126146),\n",
       " ('relate data analysis apple good', 0.2773500981126146),\n",
       " ('internal reference list questions email', 0.2773500981126146),\n",
       " ('walk resume asking technical questions', 0.2773500981126146),\n",
       " ('issues relate data analysis apple', 0.2773500981126146),\n",
       " ('list questions email virtual onsite', 0.2773500981126146),\n",
       " ('data analysis apple good company', 0.2773500981126146),\n",
       " ('onsite walk resume asking technical', 0.2773500981126146),\n",
       " ('asking technical questions one week', 0.2773500981126146),\n",
       " ('reference list questions email virtual', 0.2773500981126146),\n",
       " ('email virtual onsite walk resume', 0.2773500981126146),\n",
       " ('questions asked identify issues relate', 0.2773500981126146),\n",
       " ('resume asking technical questions one', 0.2773500981126146),\n",
       " ('communication positive interviewer concept questions', 0.2773500981126146),\n",
       " ('questions email virtual onsite walk', 0.2773500981126146),\n",
       " ('constructive communication positive interviewer concept',\n",
       "  0.2773500981126146),\n",
       " ('one week hiring decision updated', 0.2773500981126146),\n",
       " ('analysis apple good company work', 0.2773500981126146),\n",
       " ('questions one week hiring decision', 0.2773500981126146),\n",
       " ('identify issues relate data analysis', 0.2773500981126146),\n",
       " ('concept questions asked identify issues', 0.2773500981126146),\n",
       " ('little bit ml overall experience', 0.25819888974716115),\n",
       " ('answer quickly quick brown fox', 0.25819888974716115),\n",
       " ('questions little bit ml overall', 0.25819888974716115),\n",
       " ('experience good took hour hard', 0.25819888974716115),\n",
       " ('compsys os managed answer quickly', 0.25819888974716115),\n",
       " ('good took hour hard ml', 0.25819888974716115),\n",
       " ('fairly generic questions dsa compsys', 0.25819888974716115),\n",
       " ('statistics sql questions little bit', 0.25819888974716115),\n",
       " ('set interview hiring manager onsite', 0.25819888974716115),\n",
       " ('bunch fairly generic questions dsa', 0.25819888974716115),\n",
       " ('hiring manager interview onsite interview', 0.25819888974716115),\n",
       " ('generic questions dsa compsys os', 0.25819888974716115),\n",
       " ('quick brown fox jumped lazy', 0.25819888974716115),\n",
       " ('ml overall experience good took', 0.25819888974716115),\n",
       " ('brown fox jumped lazy dog', 0.25819888974716115),\n",
       " ('fundamental statistics sql questions little', 0.25819888974716115),\n",
       " ('friendly questions fundamental statistics sql', 0.25819888974716115),\n",
       " ('bit ml overall experience good', 0.25819888974716115),\n",
       " ('quickly quick brown fox jumped', 0.25819888974716115),\n",
       " ('first called set interview hiring', 0.25819888974716115),\n",
       " ('smooth recruiter first called set', 0.25819888974716115),\n",
       " ('interview onsite interview process smooth', 0.25819888974716115),\n",
       " ('hm friendly questions fundamental statistics', 0.25819888974716115),\n",
       " ('questions dsa compsys os managed', 0.25819888974716115),\n",
       " ('onsite interview process smooth recruiter', 0.25819888974716115),\n",
       " ('hour hard ml questions leetcode', 0.25819888974716115),\n",
       " ('recruiter first called set interview', 0.25819888974716115),\n",
       " ('interview hiring manager interview onsite', 0.25819888974716115),\n",
       " ('well asked bunch fairly generic', 0.25819888974716115),\n",
       " ('interview hiring manager onsite interview', 0.25819888974716115),\n",
       " ('dsa compsys os managed answer', 0.25819888974716115),\n",
       " ('asked bunch fairly generic questions', 0.25819888974716115),\n",
       " ('process smooth recruiter first called', 0.25819888974716115),\n",
       " ('went well asked bunch fairly', 0.25819888974716115),\n",
       " ('manager interview onsite interview process', 0.25819888974716115),\n",
       " ('os managed answer quickly quick', 0.25819888974716115),\n",
       " ('questions fundamental statistics sql questions', 0.25819888974716115),\n",
       " ('called set interview hiring manager', 0.25819888974716115),\n",
       " ('managed answer quickly quick brown', 0.25819888974716115),\n",
       " ('hiring manager onsite interview scheduled', 0.25819888974716115),\n",
       " ('recruiter interview hiring manager interview', 0.25819888974716115),\n",
       " ('overall experience good took hour', 0.25819888974716115),\n",
       " ('interview process smooth recruiter first', 0.25819888974716115),\n",
       " ('took hour hard ml questions', 0.25819888974716115),\n",
       " ('sql questions little bit ml', 0.25819888974716115),\n",
       " ('data challenge discussed front group', 0.242535625036333),\n",
       " ('tipsguidelines interview something people would', 0.242535625036333),\n",
       " ('consultant position technical question discussion', 0.242535625036333),\n",
       " ('data challenge data challenge discussed', 0.242535625036333),\n",
       " ('topics relevant specific department followed', 0.242535625036333),\n",
       " ('looked experience consultant position technical', 0.242535625036333),\n",
       " ('random one interviewers interrupted answer', 0.242535625036333),\n",
       " ('senior looked experience consultant position', 0.242535625036333),\n",
       " ('experiences quizzed broad topics relevant', 0.242535625036333),\n",
       " ('stages take water snack onsite', 0.242535625036333),\n",
       " ('technical question discussion predicting time', 0.242535625036333),\n",
       " ('rather random one interviewers interrupted', 0.242535625036333),\n",
       " ('technical interview junior one general', 0.242535625036333),\n",
       " ('homework assignment followed allday onsite', 0.242535625036333),\n",
       " ('experience consultant position technical question', 0.242535625036333),\n",
       " ('structured recruiter refused provide tipsguidelines', 0.242535625036333),\n",
       " ('kind asked thoughtful questions stages', 0.242535625036333),\n",
       " ('take water snack onsite interview', 0.242535625036333),\n",
       " ('takehome data challenge data challenge', 0.242535625036333),\n",
       " ('general interview senior looked experience', 0.242535625036333),\n",
       " ('followed takehome data challenge data', 0.242535625036333),\n",
       " ('first discussed previous experiences quizzed', 0.242535625036333),\n",
       " ('followed homework assignment followed allday', 0.242535625036333),\n",
       " ('interview interviewers kind asked thoughtful', 0.242535625036333),\n",
       " ('interview junior one general interview', 0.242535625036333),\n",
       " ('specific department followed takehome data', 0.242535625036333),\n",
       " ('challenge data challenge discussed front', 0.242535625036333),\n",
       " ('discussion predicting time series multiple', 0.242535625036333),\n",
       " ('discussed previous experiences quizzed broad', 0.242535625036333),\n",
       " ('discussed front group people department', 0.242535625036333),\n",
       " ('something people would usually questions', 0.242535625036333),\n",
       " ('interview senior looked experience consultant', 0.242535625036333),\n",
       " ('interview something people would usually', 0.242535625036333),\n",
       " ('department followed takehome data challenge', 0.242535625036333),\n",
       " ('interviewers interrupted answer halfway rudely', 0.242535625036333),\n",
       " ('interviewers kind asked thoughtful questions', 0.242535625036333),\n",
       " ('thoughtful questions stages take water', 0.242535625036333),\n",
       " ('interviews rather random one interviewers', 0.242535625036333),\n",
       " ('time series multiple iot sensors', 0.242535625036333),\n",
       " ('junior one general interview senior', 0.242535625036333),\n",
       " ('challenge discussed front group people', 0.242535625036333),\n",
       " ('screen recruiter followed homework assignment', 0.242535625036333),\n",
       " ('followed allday onsite interview interviewers', 0.242535625036333),\n",
       " ('question discussion predicting time series', 0.242535625036333),\n",
       " ('onsite interview interviewers kind asked', 0.242535625036333),\n",
       " ('provide tipsguidelines interview something people', 0.242535625036333),\n",
       " ('recruiter refused provide tipsguidelines interview', 0.242535625036333),\n",
       " ('assignment followed allday onsite interview', 0.242535625036333),\n",
       " ('questions interviews rather random one', 0.242535625036333),\n",
       " ('predicting time series multiple iot', 0.242535625036333),\n",
       " ('position technical question discussion predicting', 0.242535625036333),\n",
       " ('previous experiences quizzed broad topics', 0.242535625036333),\n",
       " ('questions stages take water snack', 0.242535625036333),\n",
       " ('poorly structured recruiter refused provide', 0.242535625036333),\n",
       " ('one technical interview junior one', 0.242535625036333),\n",
       " ('relevant specific department followed takehome', 0.242535625036333),\n",
       " ('recruiter followed homework assignment followed', 0.242535625036333),\n",
       " ('allday onsite interview interviewers kind', 0.242535625036333),\n",
       " ('one interviewers interrupted answer halfway', 0.242535625036333),\n",
       " ('refused provide tipsguidelines interview something', 0.242535625036333),\n",
       " ('phone screen recruiter followed homework', 0.242535625036333),\n",
       " ('broad topics relevant specific department', 0.242535625036333),\n",
       " ('one general interview senior looked', 0.242535625036333),\n",
       " ('quizzed broad topics relevant specific', 0.242535625036333),\n",
       " ('would usually questions interviews rather', 0.242535625036333),\n",
       " ('people would usually questions interviews', 0.242535625036333),\n",
       " ('usually questions interviews rather random', 0.242535625036333),\n",
       " ('asked thoughtful questions stages take', 0.242535625036333),\n",
       " ('tell availability two weeks available', 0.23570226039551584),\n",
       " ('recruiter reached ghosted applied position', 0.23570226039551584),\n",
       " ('position another referral however recruiter', 0.23570226039551584),\n",
       " ('availability two weeks available phone', 0.23570226039551584),\n",
       " ('available phone number conversation phone', 0.23570226039551584),\n",
       " ('offer email asked tell availability', 0.23570226039551584),\n",
       " ('difference random forest xgboost second', 0.23570226039551584),\n",
       " ('interviewer asked questions related cv', 0.23570226039551584),\n",
       " ('phone started asking want position', 0.23570226039551584),\n",
       " ('referral however recruiter reached ghosted', 0.23570226039551584),\n",
       " ('phone number conversation phone started', 0.23570226039551584),\n",
       " ('phone interview offer email asked', 0.23570226039551584),\n",
       " ('previous emails agree big company', 0.23570226039551584),\n",
       " ('asked questions related cv also', 0.23570226039551584),\n",
       " ('interview offer email asked tell', 0.23570226039551584),\n",
       " ('weeks available phone number conversation', 0.23570226039551584),\n",
       " ('xgboost second part data query', 0.23570226039551584),\n",
       " ('first part interviewer asked questions', 0.23570226039551584),\n",
       " ('random forest xgboost second part', 0.23570226039551584),\n",
       " ('agree big company coordinated interview', 0.23570226039551584),\n",
       " ('algorithms difference random forest xgboost', 0.23570226039551584),\n",
       " ('forest xgboost second part data', 0.23570226039551584),\n",
       " ('reached ghosted applied position another', 0.23570226039551584),\n",
       " ('also understanding machine learning algorithms', 0.23570226039551584),\n",
       " ('ghosted applied position another referral', 0.23570226039551584),\n",
       " ('ghosted excuse lost previous emails', 0.23570226039551584),\n",
       " ('got phone interview offer email', 0.23570226039551584),\n",
       " ('questions related cv also understanding', 0.23570226039551584),\n",
       " ('another referral however recruiter reached', 0.23570226039551584),\n",
       " ('excuse lost previous emails agree', 0.23570226039551584),\n",
       " ('reached ghosted excuse lost previous', 0.23570226039551584),\n",
       " ('applied online got phone interview', 0.23570226039551584),\n",
       " ('however recruiter reached ghosted excuse', 0.23570226039551584),\n",
       " ('started asking want position projects', 0.23570226039551584),\n",
       " ('applied position another referral however', 0.23570226039551584),\n",
       " ('emails agree big company coordinated', 0.23570226039551584),\n",
       " ('learning algorithms difference random forest', 0.23570226039551584),\n",
       " ('email asked tell availability two', 0.23570226039551584),\n",
       " ('asked tell availability two weeks', 0.23570226039551584),\n",
       " ('big company coordinated interview process', 0.23570226039551584),\n",
       " ('number conversation phone started asking', 0.23570226039551584),\n",
       " ('recruiter reached ghosted excuse lost', 0.23570226039551584),\n",
       " ('machine learning algorithms difference random', 0.23570226039551584),\n",
       " ('conversation phone started asking want', 0.23570226039551584),\n",
       " ('part data query coding questions', 0.23570226039551584),\n",
       " ('cv also understanding machine learning', 0.23570226039551584),\n",
       " ('online got phone interview offer', 0.23570226039551584),\n",
       " ('lost previous emails agree big', 0.23570226039551584),\n",
       " ('understanding machine learning algorithms difference', 0.23570226039551584),\n",
       " ('second part data query coding', 0.23570226039551584),\n",
       " ('part interviewer asked questions related', 0.23570226039551584),\n",
       " ('company coordinated interview process like', 0.23570226039551584),\n",
       " ('related cv also understanding machine', 0.23570226039551584),\n",
       " ('two weeks available phone number', 0.23570226039551584),\n",
       " ('resume general introduction seems served', 0.22941573387056177),\n",
       " ('apples expect basic knowledge elaborate', 0.22941573387056177),\n",
       " ('hr screen quick minute call', 0.22941573387056177),\n",
       " ('elaborate thought process coding leetcode', 0.22941573387056177),\n",
       " ('screen quick minute call talking', 0.22941573387056177),\n",
       " ('screen sql basic pythonab testing', 0.22941573387056177),\n",
       " ('technical screen sql basic pythonab', 0.22941573387056177),\n",
       " ('knowledge elaborate thought process coding', 0.22941573387056177),\n",
       " ('production questions centered apples expect', 0.22941573387056177),\n",
       " ('stages went hr screen quick', 0.22941573387056177),\n",
       " ('sql basic pythonab testing mins', 0.22941573387056177),\n",
       " ('questions centered apples expect basic', 0.22941573387056177),\n",
       " ('went hr screen quick minute', 0.22941573387056177),\n",
       " ('manager mins technical screen sql', 0.22941573387056177),\n",
       " ('pythonab testing mins panel interview', 0.22941573387056177),\n",
       " ('home assignment followed presentation team', 0.22941573387056177),\n",
       " ('expect basic knowledge elaborate thought', 0.22941573387056177),\n",
       " ('statistic questions production questions centered', 0.22941573387056177),\n",
       " ('general introduction seems served first', 0.22941573387056177),\n",
       " ('centered apples expect basic knowledge', 0.22941573387056177),\n",
       " ('first filter next phase take', 0.22941573387056177),\n",
       " ('followed presentation team rounds interview', 0.22941573387056177),\n",
       " ('next phase take home assignment', 0.22941573387056177),\n",
       " ('forward basic statistic questions production', 0.22941573387056177),\n",
       " ('talking hiring manager mins technical', 0.22941573387056177),\n",
       " ('filter next phase take home', 0.22941573387056177),\n",
       " ('quick minute call talking hiring', 0.22941573387056177),\n",
       " ('coding leetcode easy think culture', 0.22941573387056177),\n",
       " ('mins panel interview mins different', 0.22941573387056177),\n",
       " ('take home assignment followed presentation', 0.22941573387056177),\n",
       " ('minutes go resume general introduction', 0.22941573387056177),\n",
       " ('go resume general introduction seems', 0.22941573387056177),\n",
       " ('minute call talking hiring manager', 0.22941573387056177),\n",
       " ('straight forward basic statistic questions', 0.22941573387056177),\n",
       " ('questions production questions centered apples', 0.22941573387056177),\n",
       " ('mins technical screen sql basic', 0.22941573387056177),\n",
       " ('hiring manager mins technical screen', 0.22941573387056177),\n",
       " ('easy think culture team fit', 0.22941573387056177),\n",
       " ('phase take home assignment followed', 0.22941573387056177),\n",
       " ('introduction seems served first filter', 0.22941573387056177),\n",
       " ('seems served first filter next', 0.22941573387056177),\n",
       " ('testing mins panel interview mins', 0.22941573387056177),\n",
       " ('interview took minutes go resume', 0.22941573387056177),\n",
       " ('think culture team fit important', 0.22941573387056177),\n",
       " ('panel interview mins different stakeholders', 0.22941573387056177),\n",
       " ('basic statistic questions production questions', 0.22941573387056177),\n",
       " ('assignment followed presentation team rounds', 0.22941573387056177),\n",
       " ('call talking hiring manager mins', 0.22941573387056177),\n",
       " ('basic pythonab testing mins panel', 0.22941573387056177),\n",
       " ('call interview took minutes go', 0.22941573387056177),\n",
       " ('process coding leetcode easy think', 0.22941573387056177),\n",
       " ('served first filter next phase', 0.22941573387056177),\n",
       " ('leetcode easy think culture team', 0.22941573387056177),\n",
       " ('took minutes go resume general', 0.22941573387056177),\n",
       " ('thought process coding leetcode easy', 0.22941573387056177),\n",
       " ('basic knowledge elaborate thought process', 0.22941573387056177),\n",
       " ('phone call interview took minutes', 0.22941573387056177),\n",
       " ('analytics ml statistics sure gave', 0.223606797749979),\n",
       " ('level went till tech screening', 0.223606797749979),\n",
       " ('applied online hr contacted role', 0.223606797749979),\n",
       " ('till tech screening applied online', 0.223606797749979),\n",
       " ('statistics sure gave ds title', 0.223606797749979),\n",
       " ('went till tech screening applied', 0.223606797749979),\n",
       " ('questions easy medium level went', 0.223606797749979),\n",
       " ('medium level went till tech', 0.223606797749979),\n",
       " ('process simple questions easy medium', 0.223606797749979),\n",
       " ('hr contacted role focused data', 0.223606797749979),\n",
       " ('simple questions easy medium level', 0.223606797749979),\n",
       " ('online hr contacted role focused', 0.223606797749979),\n",
       " ('easy medium level went till', 0.223606797749979),\n",
       " ('contacted role focused data analytics', 0.223606797749979),\n",
       " ('role focused data analytics ml', 0.223606797749979),\n",
       " ('screening applied online hr contacted', 0.223606797749979),\n",
       " ('ml statistics sure gave ds', 0.223606797749979),\n",
       " ('tech screening applied online hr', 0.223606797749979),\n",
       " ('data analytics ml statistics sure', 0.223606797749979),\n",
       " ('focused data analytics ml statistics', 0.223606797749979),\n",
       " ('future coworker asked various questions', 0.2182178902359924),\n",
       " ('interviews done drop room would', 0.2182178902359924),\n",
       " ('resume walk general questions like', 0.2182178902359924),\n",
       " ('room would meet one person', 0.2182178902359924),\n",
       " ('simple interview siri technical team', 0.2182178902359924),\n",
       " ('level sql medium hard level', 0.2182178902359924),\n",
       " ('one week technical interview ds', 0.2182178902359924),\n",
       " ('introduced team one week technical', 0.2182178902359924),\n",
       " ('nice asked questions typical engineer', 0.2182178902359924),\n",
       " ('minutes interview resume walk general', 0.2182178902359924),\n",
       " ('science interviews process quick organized', 0.2182178902359924),\n",
       " ('functional team manager future coworker', 0.2182178902359924),\n",
       " ('general questions like tell techniques', 0.2182178902359924),\n",
       " ('interviews process quick organized expected', 0.2182178902359924),\n",
       " ('quick organized expected big corporation', 0.2182178902359924),\n",
       " ('questions typical engineer data science', 0.2182178902359924),\n",
       " ('hiring manager cross functional team', 0.2182178902359924),\n",
       " ('questions simple interview siri technical', 0.2182178902359924),\n",
       " ('interview siri technical team minutes', 0.2182178902359924),\n",
       " ('manager future coworker asked various', 0.2182178902359924),\n",
       " ('interview manager asked experience introduced', 0.2182178902359924),\n",
       " ('organized expected big corporation went', 0.2182178902359924),\n",
       " ('process quick organized expected big', 0.2182178902359924),\n",
       " ('interview process due hiring timelines', 0.2182178902359924),\n",
       " ('interview ds team python medium', 0.2182178902359924),\n",
       " ('manager asked experience introduced team', 0.2182178902359924),\n",
       " ('professional interviewers nice asked questions', 0.2182178902359924),\n",
       " ('project explained team questions like', 0.2182178902359924),\n",
       " ('python medium hard level sql', 0.2182178902359924),\n",
       " ('interview punctual professional interviewers nice', 0.2182178902359924),\n",
       " ('interview resume walk general questions', 0.2182178902359924),\n",
       " ('medium hard level sql medium', 0.2182178902359924),\n",
       " ('siri technical team minutes interview', 0.2182178902359924),\n",
       " ('interviewed hiring manager cross functional', 0.2182178902359924),\n",
       " ('screen interview manager asked experience', 0.2182178902359924),\n",
       " ('partial interview process due hiring', 0.2182178902359924),\n",
       " ('past experiences using data interviews', 0.2182178902359924),\n",
       " ('like tell techniques using project', 0.2182178902359924),\n",
       " ('like general software engineer interview', 0.2182178902359924),\n",
       " ('questions like general software engineer', 0.2182178902359924),\n",
       " ('manager cross functional team manager', 0.2182178902359924),\n",
       " ('questions like tell techniques using', 0.2182178902359924),\n",
       " ('questions past experiences using data', 0.2182178902359924),\n",
       " ('hard level sql medium hard', 0.2182178902359924),\n",
       " ('interviewers nice asked questions typical', 0.2182178902359924),\n",
       " ('punctual professional interviewers nice asked', 0.2182178902359924),\n",
       " ('hr approached email days screen', 0.2182178902359924),\n",
       " ('expected big corporation went partial', 0.2182178902359924),\n",
       " ('approached email days screen interview', 0.2182178902359924),\n",
       " ('technical team minutes interview resume', 0.2182178902359924),\n",
       " ('big corporation went partial interview', 0.2182178902359924),\n",
       " ('various questions past experiences using', 0.2182178902359924),\n",
       " ('week technical interview ds team', 0.2182178902359924),\n",
       " ('email days screen interview manager', 0.2182178902359924),\n",
       " ('data science interviews process quick', 0.2182178902359924),\n",
       " ('data interviews done drop room', 0.2182178902359924),\n",
       " ('using project explained team questions', 0.2182178902359924),\n",
       " ('technical interview ds team python', 0.2182178902359924),\n",
       " ('using data interviews done drop', 0.2182178902359924),\n",
       " ('asked various questions past experiences', 0.2182178902359924),\n",
       " ('cross functional team manager future', 0.2182178902359924),\n",
       " ('coworker asked various questions past', 0.2182178902359924),\n",
       " ('explained team questions like general', 0.2182178902359924),\n",
       " ('engineer data science interviews process', 0.2182178902359924),\n",
       " ('corporation went partial interview process', 0.2182178902359924),\n",
       " ('experiences using data interviews done', 0.2182178902359924),\n",
       " ('would meet one person another', 0.2182178902359924),\n",
       " ('typical engineer data science interviews', 0.2182178902359924),\n",
       " ('experience introduced team one week', 0.2182178902359924),\n",
       " ('asked questions typical engineer data', 0.2182178902359924),\n",
       " ('walk general questions like tell', 0.2182178902359924),\n",
       " ('asked experience introduced team one', 0.2182178902359924),\n",
       " ('team questions like general software', 0.2182178902359924),\n",
       " ('went partial interview process due', 0.2182178902359924),\n",
       " ('ds team python medium hard', 0.2182178902359924),\n",
       " ('drop room would meet one', 0.2182178902359924),\n",
       " ('team minutes interview resume walk', 0.2182178902359924),\n",
       " ('team manager future coworker asked', 0.2182178902359924),\n",
       " ('days screen interview manager asked', 0.2182178902359924),\n",
       " ('team one week technical interview', 0.2182178902359924),\n",
       " ('techniques using project explained team', 0.2182178902359924),\n",
       " ('team python medium hard level', 0.2182178902359924),\n",
       " ('tell techniques using project explained', 0.2182178902359924),\n",
       " ('done drop room would meet', 0.2182178902359924),\n",
       " ('manager asking details projects technical', 0.21320071635561044),\n",
       " ('hr calls min asking background', 0.21320071635561044),\n",
       " ('prep hour onsite onsite feedback', 0.21320071635561044),\n",
       " ('team took two half weeks', 0.21320071635561044),\n",
       " ('took two half weeks get', 0.21320071635561044),\n",
       " ('half weeks get final decision', 0.21320071635561044),\n",
       " ('assessment week onsite interview rounds', 0.21320071635561044),\n",
       " ('week onsite interview rounds managers', 0.21320071635561044),\n",
       " ('hours prep hour onsite onsite', 0.21320071635561044),\n",
       " ('weeks get final decision onsite', 0.21320071635561044),\n",
       " ('hour onsite onsite feedback whatsoever', 0.21320071635561044),\n",
       " ('screen one hour case study', 0.21320071635561044),\n",
       " ('members team took two half', 0.21320071635561044),\n",
       " ('hour case study give hours', 0.21320071635561044),\n",
       " ('interview rounds managers different teams', 0.21320071635561044),\n",
       " ('home assessment week onsite interview', 0.21320071635561044),\n",
       " ('hiring manager asking details projects', 0.21320071635561044),\n",
       " ('two half weeks get final', 0.21320071635561044),\n",
       " ('home assessment data analysis take', 0.21320071635561044),\n",
       " ('min asking background hiring manager', 0.21320071635561044),\n",
       " ('analysis take home assessment week', 0.21320071635561044),\n",
       " ('projects technical take home assessment', 0.21320071635561044),\n",
       " ('one hour case study give', 0.21320071635561044),\n",
       " ('case study give hours prep', 0.21320071635561044),\n",
       " ('recruiters members team took two', 0.21320071635561044),\n",
       " ('asking details projects technical take', 0.21320071635561044),\n",
       " ('technical take home assessment data', 0.21320071635561044),\n",
       " ('feedback whatsoever given recruiters members', 0.21320071635561044),\n",
       " ('technical screen one hour case', 0.21320071635561044),\n",
       " ('whatsoever given recruiters members team', 0.21320071635561044),\n",
       " ('calls min asking background hiring', 0.21320071635561044),\n",
       " ('data analysis take home assessment', 0.21320071635561044),\n",
       " ('give hours prep hour onsite', 0.21320071635561044),\n",
       " ('onsite onsite feedback whatsoever given', 0.21320071635561044),\n",
       " ('given recruiters members team took', 0.21320071635561044),\n",
       " ('take home assessment week onsite', 0.21320071635561044),\n",
       " ('onsite interview rounds managers different', 0.21320071635561044),\n",
       " ('take home assessment data analysis', 0.21320071635561044),\n",
       " ('details projects technical take home', 0.21320071635561044),\n",
       " ('asking background hiring manager asking', 0.21320071635561044),\n",
       " ('assessment data analysis take home', 0.21320071635561044),\n",
       " ('background hiring manager asking details', 0.21320071635561044),\n",
       " ('onsite feedback whatsoever given recruiters', 0.21320071635561044),\n",
       " ('study give hours prep hour', 0.21320071635561044),\n",
       " ('la verdad que es recomendable', 0.20412414523193154),\n",
       " ('en las oficinas de apple', 0.20412414523193154),\n",
       " ('tiene varias fases la entrevista', 0.20412414523193154),\n",
       " ('la entrevista es presencial en', 0.20412414523193154),\n",
       " ('mi caso particular en las', 0.20412414523193154),\n",
       " ('recomendable hacerlo tiene varias fases', 0.20412414523193154),\n",
       " ('que es recomendable hacerlo tiene', 0.20412414523193154),\n",
       " ('entrevista es presencial en mi', 0.20412414523193154),\n",
       " ('es presencial en mi caso', 0.20412414523193154),\n",
       " ('es recomendable hacerlo tiene varias', 0.20412414523193154),\n",
       " ('en mi caso particular en', 0.20412414523193154),\n",
       " ('presencial en mi caso particular', 0.20412414523193154),\n",
       " ('hacerlo tiene varias fases la', 0.20412414523193154),\n",
       " ('muy bueno la verdad que', 0.20412414523193154),\n",
       " ('particular en las oficinas de', 0.20412414523193154),\n",
       " ('varias fases la entrevista es', 0.20412414523193154),\n",
       " ('fases la entrevista es presencial', 0.20412414523193154),\n",
       " ('un proceso muy guiado muy', 0.20412414523193154),\n",
       " ('guiado muy bueno la verdad', 0.20412414523193154),\n",
       " ('verdad que es recomendable hacerlo', 0.20412414523193154),\n",
       " ('caso particular en las oficinas', 0.20412414523193154),\n",
       " ('proceso muy guiado muy bueno', 0.20412414523193154),\n",
       " ('muy guiado muy bueno la', 0.20412414523193154),\n",
       " ('bueno la verdad que es', 0.20412414523193154),\n",
       " ('hectic intriguing one phone interview', 0.18898223650461363),\n",
       " ('expectation team clear wanted data', 0.18898223650461363),\n",
       " ('wanted data scientist know data', 0.18898223650461363),\n",
       " ('case based technical statistical questions', 0.18898223650461363),\n",
       " ('phone interview mins onsite round', 0.18898223650461363),\n",
       " ('comprising rounds phone interview comprised', 0.18898223650461363),\n",
       " ('onsite round comprising rounds phone', 0.18898223650461363),\n",
       " ('data engineering analytics developer work', 0.18898223650461363),\n",
       " ('statistical questions asked expectation team', 0.18898223650461363),\n",
       " ('phone interview comprised case based', 0.18898223650461363),\n",
       " ('intriguing one phone interview mins', 0.18898223650461363),\n",
       " ('questions asked expectation team clear', 0.18898223650461363),\n",
       " ('data scientist know data engineering', 0.18898223650461363),\n",
       " ('interview comprised case based technical', 0.18898223650461363),\n",
       " ('technical statistical questions asked expectation', 0.18898223650461363),\n",
       " ('mins onsite round comprising rounds', 0.18898223650461363),\n",
       " ('know data engineering analytics developer', 0.18898223650461363),\n",
       " ('asked expectation team clear wanted', 0.18898223650461363),\n",
       " ('one phone interview mins onsite', 0.18898223650461363),\n",
       " ('comprised case based technical statistical', 0.18898223650461363),\n",
       " ('round comprising rounds phone interview', 0.18898223650461363),\n",
       " ('engineering analytics developer work well', 0.18898223650461363),\n",
       " ('scientist know data engineering analytics', 0.18898223650461363),\n",
       " ('rounds phone interview comprised case', 0.18898223650461363),\n",
       " ('clear wanted data scientist know', 0.18898223650461363),\n",
       " ('based technical statistical questions asked', 0.18898223650461363),\n",
       " ('interview mins onsite round comprising', 0.18898223650461363),\n",
       " ('team clear wanted data scientist', 0.18898223650461363),\n",
       " ('someone team getting apple really', 0.1825741858350554),\n",
       " ('interview told code language turns', 0.1825741858350554),\n",
       " ('interviewer also asked machine learning', 0.1825741858350554),\n",
       " ('preferred language interviewer also asked', 0.1825741858350554),\n",
       " ('recruiter talked someone team getting', 0.1825741858350554),\n",
       " ('shot explain apple good fit', 0.1825741858350554),\n",
       " ('definately worth shot explain apple', 0.1825741858350554),\n",
       " ('difficultinitial phone screening manager screening', 0.1825741858350554),\n",
       " ('share useful aspects interview told', 0.1825741858350554),\n",
       " ('recruiter linkedin schedule phone interview', 0.1825741858350554),\n",
       " ('approached recruiter talked someone team', 0.1825741858350554),\n",
       " ('phone interview one week later', 0.1825741858350554),\n",
       " ('phone screening manager screening case', 0.1825741858350554),\n",
       " ('week later recruiter doesnt share', 0.1825741858350554),\n",
       " ('aspects interview told code language', 0.1825741858350554),\n",
       " ('really difficultinitial phone screening manager', 0.1825741858350554),\n",
       " ('process quite tedious loose interest', 0.1825741858350554),\n",
       " ('code language turns need code', 0.1825741858350554),\n",
       " ('turns need code python preferred', 0.1825741858350554),\n",
       " ('tedious loose interest general definately', 0.1825741858350554),\n",
       " ('schedule phone interview one week', 0.1825741858350554),\n",
       " ('asked machine learning questions answered', 0.1825741858350554),\n",
       " ('need code python preferred language', 0.1825741858350554),\n",
       " ('recruiter doesnt share useful aspects', 0.1825741858350554),\n",
       " ('manager screening case study final', 0.1825741858350554),\n",
       " ('contacted recruiter linkedin schedule phone', 0.1825741858350554),\n",
       " ('round overall process quite tedious', 0.1825741858350554),\n",
       " ('python preferred language interviewer also', 0.1825741858350554),\n",
       " ('code python preferred language interviewer', 0.1825741858350554),\n",
       " ('screening case study final round', 0.1825741858350554),\n",
       " ('language turns need code python', 0.1825741858350554),\n",
       " ('screening manager screening case study', 0.1825741858350554),\n",
       " ('machine learning questions answered well', 0.1825741858350554),\n",
       " ('told code language turns need', 0.1825741858350554),\n",
       " ('case study final round overall', 0.1825741858350554),\n",
       " ('loose interest general definately worth', 0.1825741858350554),\n",
       " ('one week later recruiter doesnt', 0.1825741858350554),\n",
       " ('linkedin schedule phone interview one', 0.1825741858350554),\n",
       " ('useful aspects interview told code', 0.1825741858350554),\n",
       " ('overall process quite tedious loose', 0.1825741858350554),\n",
       " ('learning questions answered well believe', 0.1825741858350554),\n",
       " ('later recruiter doesnt share useful', 0.1825741858350554),\n",
       " ('apple really difficultinitial phone screening', 0.1825741858350554),\n",
       " ('language interviewer also asked machine', 0.1825741858350554),\n",
       " ('get contacted recruiter linkedin schedule', 0.1825741858350554),\n",
       " ('interest general definately worth shot', 0.1825741858350554),\n",
       " ('talked someone team getting apple', 0.1825741858350554),\n",
       " ('interview one week later recruiter', 0.1825741858350554),\n",
       " ('team getting apple really difficultinitial', 0.1825741858350554),\n",
       " ('study final round overall process', 0.1825741858350554),\n",
       " ('final round overall process quite', 0.1825741858350554),\n",
       " ('doesnt share useful aspects interview', 0.1825741858350554),\n",
       " ('good fit dream company mine', 0.1825741858350554),\n",
       " ('explain apple good fit dream', 0.1825741858350554),\n",
       " ('worth shot explain apple good', 0.1825741858350554),\n",
       " ('general definately worth shot explain', 0.1825741858350554),\n",
       " ('getting apple really difficultinitial phone', 0.1825741858350554),\n",
       " ('quite tedious loose interest general', 0.1825741858350554),\n",
       " ('also asked machine learning questions', 0.1825741858350554),\n",
       " ('apple good fit dream company', 0.1825741858350554),\n",
       " ('started phone screens contacted initially', 0.17960530202677494),\n",
       " ('recruiter internal apple brought onsite', 0.17960530202677494),\n",
       " ('varied programmers data scientists managers', 0.17960530202677494),\n",
       " ('knowledge questions regarding programming statisticsmath',\n",
       "  0.17960530202677494),\n",
       " ('brought onsite cupertino ca campus', 0.17960530202677494),\n",
       " ('phone screens contacted initially recruiter', 0.17960530202677494),\n",
       " ('internal apple brought onsite cupertino', 0.17960530202677494),\n",
       " ('data scientists managers directors interview', 0.17960530202677494),\n",
       " ('regarding programming statisticsmath example model', 0.17960530202677494),\n",
       " ('screens contacted initially recruiter internal', 0.17960530202677494),\n",
       " ('campus meet interviewers varied programmers', 0.17960530202677494),\n",
       " ('onste consisted general knowledge questions', 0.17960530202677494),\n",
       " ('general knowledge questions regarding programming', 0.17960530202677494),\n",
       " ('initially recruiter internal apple brought', 0.17960530202677494),\n",
       " ('ca campus meet interviewers varied', 0.17960530202677494),\n",
       " ('cupertino ca campus meet interviewers', 0.17960530202677494),\n",
       " ('apple brought onsite cupertino ca', 0.17960530202677494),\n",
       " ('onsite cupertino ca campus meet', 0.17960530202677494),\n",
       " ('statisticsmath example model certain data', 0.17960530202677494),\n",
       " ('interviewers varied programmers data scientists', 0.17960530202677494),\n",
       " ('scientists managers directors interview onste', 0.17960530202677494),\n",
       " ('example model certain data sets', 0.17960530202677494),\n",
       " ('managers directors interview onste consisted', 0.17960530202677494),\n",
       " ('questions regarding programming statisticsmath example',\n",
       "  0.17960530202677494),\n",
       " ('consisted general knowledge questions regarding', 0.17960530202677494),\n",
       " ('programmers data scientists managers directors', 0.17960530202677494),\n",
       " ('contacted initially recruiter internal apple', 0.17960530202677494),\n",
       " ('programming statisticsmath example model certain', 0.17960530202677494),\n",
       " ('meet interviewers varied programmers data', 0.17960530202677494),\n",
       " ('interview onste consisted general knowledge', 0.17960530202677494),\n",
       " ('directors interview onste consisted general', 0.17960530202677494),\n",
       " ('havent heard definite yes even', 0.1690308509457033),\n",
       " ('months since onsite interview still', 0.1690308509457033),\n",
       " ('still considering months since onsite', 0.1690308509457033),\n",
       " ('still havent heard definite yes', 0.1690308509457033),\n",
       " ('step make sure still considering', 0.1690308509457033),\n",
       " ('step follow several times step', 0.1690308509457033),\n",
       " ('heard definite yes even following', 0.1690308509457033),\n",
       " ('hiring manager technical interview onsite', 0.1690308509457033),\n",
       " ('even following every person recruiting', 0.1690308509457033),\n",
       " ('every step follow several times', 0.1690308509457033),\n",
       " ('times step make sure still', 0.1690308509457033),\n",
       " ('onsite interview still havent heard', 0.1690308509457033),\n",
       " ('initial phone screen recruiter phone', 0.1690308509457033),\n",
       " ('considering months since onsite interview', 0.1690308509457033),\n",
       " ('sure still considering months since', 0.1690308509457033),\n",
       " ('extremely slow every step follow', 0.1690308509457033),\n",
       " ('onsite interview extremely slow every', 0.1690308509457033),\n",
       " ('make sure still considering months', 0.1690308509457033),\n",
       " ('manager technical interview onsite interview', 0.1690308509457033),\n",
       " ('screen recruiter phone interview hiring', 0.1690308509457033),\n",
       " ('technical interview onsite interview extremely', 0.1690308509457033),\n",
       " ('yes even following every person', 0.1690308509457033),\n",
       " ('phone interview hiring manager technical', 0.1690308509457033),\n",
       " ('interview hiring manager technical interview', 0.1690308509457033),\n",
       " ('slow every step follow several', 0.1690308509457033),\n",
       " ('following every person recruiting team', 0.1690308509457033),\n",
       " ('interview still havent heard definite', 0.1690308509457033),\n",
       " ('definite yes even following every', 0.1690308509457033),\n",
       " ('since onsite interview still havent', 0.1690308509457033),\n",
       " ('interview onsite interview extremely slow', 0.1690308509457033),\n",
       " ('phone screen recruiter phone interview', 0.1690308509457033),\n",
       " ('several times step make sure', 0.1690308509457033),\n",
       " ('follow several times step make', 0.1690308509457033),\n",
       " ('recruiter phone interview hiring manager', 0.1690308509457033),\n",
       " ('interview extremely slow every step', 0.1690308509457033),\n",
       " ('fit took time energy could', 0.1643989873053573),\n",
       " ('took time energy could devoted', 0.1643989873053573),\n",
       " ('got along everyone team lunch', 0.1643989873053573),\n",
       " ('aced takehome offline coding challenge', 0.1643989873053573),\n",
       " ('polishing presentation skills subsequent interviews', 0.1643989873053573),\n",
       " ('energy could devoted pursuing prospects', 0.1643989873053573),\n",
       " ('correctly answered technical challenges onsite', 0.1643989873053573),\n",
       " ('pursuing prospects served good way', 0.1643989873053573),\n",
       " ('good way polishing presentation skills', 0.1643989873053573),\n",
       " ('devoted pursuing prospects served good', 0.1643989873053573),\n",
       " ('could devoted pursuing prospects served', 0.1643989873053573),\n",
       " ('way polishing presentation skills subsequent', 0.1643989873053573),\n",
       " ('everyone team lunch interview felt', 0.1643989873053573),\n",
       " ('prospects served good way polishing', 0.1643989873053573),\n",
       " ('team lunch interview felt highly', 0.1643989873053573),\n",
       " ('role surmise came culture fit', 0.1643989873053573),\n",
       " ('offline coding challenge correctly answered', 0.1643989873053573),\n",
       " ('technical challenges onsite got along', 0.1643989873053573),\n",
       " ('challenge correctly answered technical challenges', 0.1643989873053573),\n",
       " ('challenges onsite got along everyone', 0.1643989873053573),\n",
       " ('coding challenge correctly answered technical', 0.1643989873053573),\n",
       " ('prepared interview aced takehome offline', 0.1643989873053573),\n",
       " ('highly qualified role surmise came', 0.1643989873053573),\n",
       " ('along everyone team lunch interview', 0.1643989873053573),\n",
       " ('onsite got along everyone team', 0.1643989873053573),\n",
       " ('came culture fit took time', 0.1643989873053573),\n",
       " ('interview felt highly qualified role', 0.1643989873053573),\n",
       " ('surmise came culture fit took', 0.1643989873053573),\n",
       " ('answered technical challenges onsite got', 0.1643989873053573),\n",
       " ('culture fit took time energy', 0.1643989873053573),\n",
       " ('time energy could devoted pursuing', 0.1643989873053573),\n",
       " ('qualified role surmise came culture', 0.1643989873053573),\n",
       " ('served good way polishing presentation', 0.1643989873053573),\n",
       " ('takehome offline coding challenge correctly', 0.1643989873053573),\n",
       " ('felt highly qualified role surmise', 0.1643989873053573),\n",
       " ('interview aced takehome offline coding', 0.1643989873053573),\n",
       " ('lunch interview felt highly qualified', 0.1643989873053573),\n",
       " ('interview overall process took like', 0.16012815380508713),\n",
       " ('even though didnt apply specific', 0.16012815380508713),\n",
       " ('interview quite intense hours day', 0.16012815380508713),\n",
       " ('panel interview quite intense hours', 0.16012815380508713),\n",
       " ('feedback every interviewer order accepted', 0.16012815380508713),\n",
       " ('process took like weeks recruiter', 0.16012815380508713),\n",
       " ('interview people vp interview overall', 0.16012815380508713),\n",
       " ('positive feedback every interviewer order', 0.16012815380508713),\n",
       " ('intense hours day get positive', 0.16012815380508713),\n",
       " ('phone coding interview hiring manager', 0.16012815380508713),\n",
       " ('weeks recruiter helpful interview preps', 0.16012815380508713),\n",
       " ('interview panel interview people vp', 0.16012815380508713),\n",
       " ('coding interview hiring manager interview', 0.16012815380508713),\n",
       " ('role phone coding interview hiring', 0.16012815380508713),\n",
       " ('vp interview overall process took', 0.16012815380508713),\n",
       " ('people vp interview overall process', 0.16012815380508713),\n",
       " ('panel interview people vp interview', 0.16012815380508713),\n",
       " ('overall process took like weeks', 0.16012815380508713),\n",
       " ('didnt apply specific role phone', 0.16012815380508713),\n",
       " ('apply specific role phone coding', 0.16012815380508713),\n",
       " ('like weeks recruiter helpful interview', 0.16012815380508713),\n",
       " ('contacted regarding opportunity even though', 0.16012815380508713),\n",
       " ('interview hiring manager interview panel', 0.16012815380508713),\n",
       " ('regarding opportunity even though didnt', 0.16012815380508713),\n",
       " ('preps panel interview quite intense', 0.16012815380508713),\n",
       " ('specific role phone coding interview', 0.16012815380508713),\n",
       " ('though didnt apply specific role', 0.16012815380508713),\n",
       " ('took like weeks recruiter helpful', 0.16012815380508713),\n",
       " ('recruiter helpful interview preps panel', 0.16012815380508713),\n",
       " ('helpful interview preps panel interview', 0.16012815380508713),\n",
       " ('interview preps panel interview quite', 0.16012815380508713),\n",
       " ('hiring manager interview panel interview', 0.16012815380508713),\n",
       " ('manager interview panel interview people', 0.16012815380508713),\n",
       " ('quite intense hours day get', 0.16012815380508713),\n",
       " ('hours day get positive feedback', 0.16012815380508713),\n",
       " ('recruiter contacted regarding opportunity even', 0.16012815380508713),\n",
       " ('opportunity even though didnt apply', 0.16012815380508713),\n",
       " ('get positive feedback every interviewer', 0.16012815380508713),\n",
       " ('day get positive feedback every', 0.16012815380508713),\n",
       " ('hear almost two weeks sent', 0.14586499149789459),\n",
       " ('follow days recruiter sent thank', 0.14586499149789459),\n",
       " ('process lengthy talked different people', 0.14586499149789459),\n",
       " ('people phone presented case study', 0.14586499149789459),\n",
       " ('never heard back disappointing see', 0.14586499149789459),\n",
       " ('gone almost hours interview never', 0.14586499149789459),\n",
       " ('two weeks sent email follow', 0.14586499149789459),\n",
       " ('feedback asked greater feedback gone', 0.14586499149789459),\n",
       " ('talked different people phone presented', 0.14586499149789459),\n",
       " ('phone presented case study onsite', 0.14586499149789459),\n",
       " ('study onsite hours lunchinterview site', 0.14586499149789459),\n",
       " ('oneway road apple need keep', 0.14586499149789459),\n",
       " ('almost hours interview never heard', 0.14586499149789459),\n",
       " ('feedback gone almost hours interview', 0.14586499149789459),\n",
       " ('need keep calling dont disappear', 0.14586499149789459),\n",
       " ('presented case study onsite hours', 0.14586499149789459),\n",
       " ('case study onsite hours lunchinterview', 0.14586499149789459),\n",
       " ('road apple need keep calling', 0.14586499149789459),\n",
       " ('onsite hours lunchinterview site end', 0.14586499149789459),\n",
       " ('greater feedback gone almost hours', 0.14586499149789459),\n",
       " ('almost two weeks sent email', 0.14586499149789459),\n",
       " ('recruiter sent thank email feedback', 0.14586499149789459),\n",
       " ('back disappointing see hiring process', 0.14586499149789459),\n",
       " ('process oneway road apple need', 0.14586499149789459),\n",
       " ('interview process lengthy talked different', 0.14586499149789459),\n",
       " ('heard back disappointing see hiring', 0.14586499149789459),\n",
       " ('end hear almost two weeks', 0.14586499149789459),\n",
       " ('hours lunchinterview site end hear', 0.14586499149789459),\n",
       " ('weeks sent email follow days', 0.14586499149789459),\n",
       " ('email feedback asked greater feedback', 0.14586499149789459),\n",
       " ('sent thank email feedback asked', 0.14586499149789459),\n",
       " ('email follow days recruiter sent', 0.14586499149789459),\n",
       " ('days recruiter sent thank email', 0.14586499149789459),\n",
       " ('interview never heard back disappointing', 0.14586499149789459),\n",
       " ('hiring process oneway road apple', 0.14586499149789459),\n",
       " ('sent email follow days recruiter', 0.14586499149789459),\n",
       " ('site end hear almost two', 0.14586499149789459),\n",
       " ('keep calling dont disappear unprofessional', 0.14586499149789459),\n",
       " ('hours interview never heard back', 0.14586499149789459),\n",
       " ('lunchinterview site end hear almost', 0.14586499149789459),\n",
       " ('thank email feedback asked greater', 0.14586499149789459),\n",
       " ('asked greater feedback gone almost', 0.14586499149789459),\n",
       " ('different people phone presented case', 0.14586499149789459),\n",
       " ('lengthy talked different people phone', 0.14586499149789459),\n",
       " ('see hiring process oneway road', 0.14586499149789459),\n",
       " ('apple need keep calling dont', 0.14586499149789459),\n",
       " ('disappointing see hiring process oneway', 0.14586499149789459),\n",
       " ('time would suggest respectful candidates', 0.14433756729740646),\n",
       " ('apple cork ireland interview process', 0.14433756729740646),\n",
       " ('initial screening round hiring manager', 0.14433756729740646),\n",
       " ('separate rounds spread couple weeks', 0.14433756729740646),\n",
       " ('spread couple weeks one initial', 0.14433756729740646),\n",
       " ('various team members interview process', 0.14433756729740646),\n",
       " ('ghosted never provided answer even', 0.14433756729740646),\n",
       " ('rounds spread couple weeks one', 0.14433756729740646),\n",
       " ('would suggest respectful candidates spend', 0.14433756729740646),\n",
       " ('ireland interview process consisted separate', 0.14433756729740646),\n",
       " ('spend hours going interview process', 0.14433756729740646),\n",
       " ('interview process consisted separate rounds', 0.14433756729740646),\n",
       " ('interview process waste time would', 0.14433756729740646),\n",
       " ('different thirty minute interviews various', 0.14433756729740646),\n",
       " ('test six different thirty minute', 0.14433756729740646),\n",
       " ('team members interview process recruiter', 0.14433756729740646),\n",
       " ('interviewed apple cork ireland interview', 0.14433756729740646),\n",
       " ('followed technical test six different', 0.14433756729740646),\n",
       " ('following consider interview process waste', 0.14433756729740646),\n",
       " ('six different thirty minute interviews', 0.14433756729740646),\n",
       " ('thirty minute interviews various team', 0.14433756729740646),\n",
       " ('waste time would suggest respectful', 0.14433756729740646),\n",
       " ('technical test six different thirty', 0.14433756729740646),\n",
       " ('process consisted separate rounds spread', 0.14433756729740646),\n",
       " ('respectful candidates spend hours going', 0.14433756729740646),\n",
       " ('interviews various team members interview', 0.14433756729740646),\n",
       " ('process recruiter ghosted never provided', 0.14433756729740646),\n",
       " ('minute interviews various team members', 0.14433756729740646),\n",
       " ('candidates spend hours going interview', 0.14433756729740646),\n",
       " ('suggest respectful candidates spend hours', 0.14433756729740646),\n",
       " ('one initial screening round hiring', 0.14433756729740646),\n",
       " ('provided answer even following consider', 0.14433756729740646),\n",
       " ('consisted separate rounds spread couple', 0.14433756729740646),\n",
       " ('process waste time would suggest', 0.14433756729740646),\n",
       " ('recruiter ghosted never provided answer', 0.14433756729740646),\n",
       " ('manager followed technical test six', 0.14433756729740646),\n",
       " ('even following consider interview process', 0.14433756729740646),\n",
       " ('interview process recruiter ghosted never', 0.14433756729740646),\n",
       " ('members interview process recruiter ghosted', 0.14433756729740646),\n",
       " ('cork ireland interview process consisted', 0.14433756729740646),\n",
       " ('hiring manager followed technical test', 0.14433756729740646),\n",
       " ('consider interview process waste time', 0.14433756729740646),\n",
       " ('never provided answer even following', 0.14433756729740646),\n",
       " ('round hiring manager followed technical', 0.14433756729740646),\n",
       " ('weeks one initial screening round', 0.14433756729740646),\n",
       " ('couple weeks one initial screening', 0.14433756729740646),\n",
       " ('screening round hiring manager followed', 0.14433756729740646),\n",
       " ('answer even following consider interview', 0.14433756729740646),\n",
       " ('experience basic data science questions', 0.1386750490563073),\n",
       " ('several minute meetings data scientists', 0.1386750490563073),\n",
       " ('day ordeal got left pm', 0.1386750490563073),\n",
       " ('asked past experience basic data', 0.1386750490563073),\n",
       " ('interview minute phone call hiring', 0.1386750490563073),\n",
       " ('basic machine learning questions onsite', 0.1386750490563073),\n",
       " ('basic data science questions next', 0.1386750490563073),\n",
       " ('interviews invited onsite interview first', 0.1386750490563073),\n",
       " ('team asked code python third', 0.1386750490563073),\n",
       " ('hiring manager asked past experience', 0.1386750490563073),\n",
       " ('scientists machine learning engineers managers', 0.1386750490563073),\n",
       " ('went phone interviews invited onsite', 0.1386750490563073),\n",
       " ('pm several minute meetings data', 0.1386750490563073),\n",
       " ('third call senior data scientist', 0.1386750490563073),\n",
       " ('minute meetings data scientists machine', 0.1386750490563073),\n",
       " ('minute phone call hiring manager', 0.1386750490563073),\n",
       " ('next call data scientist team', 0.1386750490563073),\n",
       " ('first interview minute phone call', 0.1386750490563073),\n",
       " ('scientist team asked code python', 0.1386750490563073),\n",
       " ('code python third call senior', 0.1386750490563073),\n",
       " ('scientist asked basic machine learning', 0.1386750490563073),\n",
       " ('interview whole day ordeal got', 0.1386750490563073),\n",
       " ('science questions next call data', 0.1386750490563073),\n",
       " ('onsite interview whole day ordeal', 0.1386750490563073),\n",
       " ('senior data scientist asked basic', 0.1386750490563073),\n",
       " ('phone interviews invited onsite interview', 0.1386750490563073),\n",
       " ('past experience basic data science', 0.1386750490563073),\n",
       " ('asked code python third call', 0.1386750490563073),\n",
       " ('questions onsite interview whole day', 0.1386750490563073),\n",
       " ('ordeal got left pm several', 0.1386750490563073),\n",
       " ('questions next call data scientist', 0.1386750490563073),\n",
       " ('onsite interview first interview minute', 0.1386750490563073),\n",
       " ('call senior data scientist asked', 0.1386750490563073),\n",
       " ('left pm several minute meetings', 0.1386750490563073),\n",
       " ('machine learning engineers managers etc', 0.1386750490563073),\n",
       " ('machine learning questions onsite interview', 0.1386750490563073),\n",
       " ('learning questions onsite interview whole', 0.1386750490563073),\n",
       " ('data science questions next call', 0.1386750490563073),\n",
       " ('whole day ordeal got left', 0.1386750490563073),\n",
       " ('call hiring manager asked past', 0.1386750490563073),\n",
       " ('call data scientist team asked', 0.1386750490563073),\n",
       " ('manager asked past experience basic', 0.1386750490563073),\n",
       " ('phone call hiring manager asked', 0.1386750490563073),\n",
       " ('asked basic machine learning questions', 0.1386750490563073),\n",
       " ('data scientist asked basic machine', 0.1386750490563073),\n",
       " ('interview first interview minute phone', 0.1386750490563073),\n",
       " ('meetings data scientists machine learning', 0.1386750490563073),\n",
       " ('got left pm several minute', 0.1386750490563073),\n",
       " ('data scientist team asked code', 0.1386750490563073),\n",
       " ('python third call senior data', 0.1386750490563073),\n",
       " ('data scientists machine learning engineers', 0.1386750490563073),\n",
       " ('invited onsite interview first interview', 0.1386750490563073),\n",
       " ('would say whole recruiting experience', 0.1203858530857692),\n",
       " ('recruiter positive feedback week despite', 0.1203858530857692),\n",
       " ('recruiter reached aug replied back', 0.1203858530857692),\n",
       " ('questions behavioral ones final interview', 0.1203858530857692),\n",
       " ('ran hour hm passionate asked', 0.1203858530857692),\n",
       " ('asked coding questions behavioral ones', 0.1203858530857692),\n",
       " ('reached aug replied back time', 0.1203858530857692),\n",
       " ('quite interesting experience recruiter reached', 0.1203858530857692),\n",
       " ('whole recruiting experience pleasant efficient', 0.1203858530857692),\n",
       " ('team heard back recruiter positive', 0.1203858530857692),\n",
       " ('aug replied back time initial', 0.1203858530857692),\n",
       " ('till pm interviews total met', 0.1203858530857692),\n",
       " ('interesting experience recruiter reached aug', 0.1203858530857692),\n",
       " ('interview daylong loop starting running', 0.1203858530857692),\n",
       " ('disappeared months later responded back', 0.1203858530857692),\n",
       " ('despite initial ghosting would say', 0.1203858530857692),\n",
       " ('slipped crack still market talked', 0.1203858530857692),\n",
       " ('daylong loop starting running way', 0.1203858530857692),\n",
       " ('interviews total met multiple people', 0.1203858530857692),\n",
       " ('market talked passed information one', 0.1203858530857692),\n",
       " ('time initial screening disappeared months', 0.1203858530857692),\n",
       " ('later responded back saying email', 0.1203858530857692),\n",
       " ('crack still market talked passed', 0.1203858530857692),\n",
       " ('week despite initial ghosting would', 0.1203858530857692),\n",
       " ('loop starting running way till', 0.1203858530857692),\n",
       " ('screening ran hour hm passionate', 0.1203858530857692),\n",
       " ('email slipped crack still market', 0.1203858530857692),\n",
       " ('initial screening disappeared months later', 0.1203858530857692),\n",
       " ('initial ghosting would say whole', 0.1203858530857692),\n",
       " ('information one hm picked resume', 0.1203858530857692),\n",
       " ('stakeholders team heard back recruiter', 0.1203858530857692),\n",
       " ('starting running way till pm', 0.1203858530857692),\n",
       " ('hour hm passionate asked coding', 0.1203858530857692),\n",
       " ('hm picked resume min tech', 0.1203858530857692),\n",
       " ('hm passionate asked coding questions', 0.1203858530857692),\n",
       " ('heard back recruiter positive feedback', 0.1203858530857692),\n",
       " ('experience recruiter reached aug replied', 0.1203858530857692),\n",
       " ('still market talked passed information', 0.1203858530857692),\n",
       " ('tech screening ran hour hm', 0.1203858530857692),\n",
       " ('ghosting would say whole recruiting', 0.1203858530857692),\n",
       " ('feedback week despite initial ghosting', 0.1203858530857692),\n",
       " ('final interview daylong loop starting', 0.1203858530857692),\n",
       " ('talked passed information one hm', 0.1203858530857692),\n",
       " ('total met multiple people stakeholders', 0.1203858530857692),\n",
       " ('screening disappeared months later responded', 0.1203858530857692),\n",
       " ('saying email slipped crack still', 0.1203858530857692),\n",
       " ('pm interviews total met multiple', 0.1203858530857692),\n",
       " ('responded back saying email slipped', 0.1203858530857692),\n",
       " ('passed information one hm picked', 0.1203858530857692),\n",
       " ('passionate asked coding questions behavioral', 0.1203858530857692),\n",
       " ('people stakeholders team heard back', 0.1203858530857692),\n",
       " ('behavioral ones final interview daylong', 0.1203858530857692),\n",
       " ('ones final interview daylong loop', 0.1203858530857692),\n",
       " ('resume min tech screening ran', 0.1203858530857692),\n",
       " ('picked resume min tech screening', 0.1203858530857692),\n",
       " ('one hm picked resume min', 0.1203858530857692),\n",
       " ('multiple people stakeholders team heard', 0.1203858530857692),\n",
       " ('running way till pm interviews', 0.1203858530857692),\n",
       " ('say whole recruiting experience pleasant', 0.1203858530857692),\n",
       " ('replied back time initial screening', 0.1203858530857692),\n",
       " ('back time initial screening disappeared', 0.1203858530857692),\n",
       " ('positive feedback week despite initial', 0.1203858530857692),\n",
       " ('met multiple people stakeholders team', 0.1203858530857692),\n",
       " ('back saying email slipped crack', 0.1203858530857692),\n",
       " ('min tech screening ran hour', 0.1203858530857692),\n",
       " ('months later responded back saying', 0.1203858530857692),\n",
       " ('coding questions behavioral ones final', 0.1203858530857692),\n",
       " ('way till pm interviews total', 0.1203858530857692),\n",
       " ('back recruiter positive feedback week', 0.1203858530857692),\n",
       " ('team culture fanboys constructive criticism', 0.11396057645963796),\n",
       " ('work team culture fanboys constructive', 0.11396057645963796),\n",
       " ('tech sessions remote onsite manager', 0.11396057645963796),\n",
       " ('remote onsite manager screen asked', 0.11396057645963796),\n",
       " ('teaser asked old school interview', 0.11396057645963796),\n",
       " ('waterfall seemingly secretive cant really', 0.11396057645963796),\n",
       " ('tech screen python sql question', 0.11396057645963796),\n",
       " ('tech screen tech sessions remote', 0.11396057645963796),\n",
       " ('screen asked resume asked brain', 0.11396057645963796),\n",
       " ('sql hard python seemed like', 0.11396057645963796),\n",
       " ('resume asked brain teaser asked', 0.11396057645963796),\n",
       " ('seemingly secretive cant really get', 0.11396057645963796),\n",
       " ('screen tech screen tech sessions', 0.11396057645963796),\n",
       " ('screen tech sessions remote onsite', 0.11396057645963796),\n",
       " ('trust firstline management make decisions', 0.11396057645963796),\n",
       " ('really get good idea work', 0.11396057645963796),\n",
       " ('school interview questions tech screen', 0.11396057645963796),\n",
       " ('seemed like better software engineer', 0.11396057645963796),\n",
       " ('seemed like upper management trust', 0.11396057645963796),\n",
       " ('scenarios disagreement coworker hypothetical make', 0.11396057645963796),\n",
       " ('upper management trust firstline management', 0.11396057645963796),\n",
       " ('sessions remote onsite manager screen', 0.11396057645963796),\n",
       " ('rude seemed like upper management', 0.11396057645963796),\n",
       " ('software engineer lots hypothetical questions', 0.11396057645963796),\n",
       " ('spam metric unlimited data presentation', 0.11396057645963796),\n",
       " ('screen python sql question hr', 0.11396057645963796),\n",
       " ('sql question hr onsite intermediate', 0.11396057645963796),\n",
       " ('unlimited data presentation people extremely', 0.11396057645963796),\n",
       " ('secretive cant really get good', 0.11396057645963796),\n",
       " ('manager screen tech screen tech', 0.11396057645963796),\n",
       " ('better software engineer lots hypothetical', 0.11396057645963796),\n",
       " ('good idea work team culture', 0.11396057645963796),\n",
       " ('make decisions waterfall seemingly secretive', 0.11396057645963796),\n",
       " ('data presentation people extremely condescending', 0.11396057645963796),\n",
       " ('interview questions tech screen python', 0.11396057645963796),\n",
       " ('asked brain teaser asked old', 0.11396057645963796),\n",
       " ('asked old school interview questions', 0.11396057645963796),\n",
       " ('asked resume asked brain teaser', 0.11396057645963796),\n",
       " ('coworker hypothetical make spam metric', 0.11396057645963796),\n",
       " ('lots hypothetical questions handle different', 0.11396057645963796),\n",
       " ('get good idea work team', 0.11396057645963796),\n",
       " ('engineer lots hypothetical questions handle', 0.11396057645963796),\n",
       " ('people extremely condescending rude seemed', 0.11396057645963796),\n",
       " ('like upper management trust firstline', 0.11396057645963796),\n",
       " ('firstline management make decisions waterfall', 0.11396057645963796),\n",
       " ('onsite manager screen asked resume', 0.11396057645963796),\n",
       " ('like better software engineer lots', 0.11396057645963796),\n",
       " ('onsite intermediate advanced sql hard', 0.11396057645963796),\n",
       " ('brain teaser asked old school', 0.11396057645963796),\n",
       " ('cant really get good idea', 0.11396057645963796),\n",
       " ('condescending rude seemed like upper', 0.11396057645963796),\n",
       " ('old school interview questions tech', 0.11396057645963796),\n",
       " ('fanboys constructive criticism frowned upon', 0.11396057645963796),\n",
       " ('make spam metric unlimited data', 0.11396057645963796),\n",
       " ('culture fanboys constructive criticism frowned', 0.11396057645963796),\n",
       " ('management make decisions waterfall seemingly', 0.11396057645963796),\n",
       " ('hypothetical make spam metric unlimited', 0.11396057645963796),\n",
       " ('questions handle different scenarios disagreement', 0.11396057645963796),\n",
       " ('questions tech screen python sql', 0.11396057645963796),\n",
       " ('question hr onsite intermediate advanced', 0.11396057645963796),\n",
       " ('python sql question hr onsite', 0.11396057645963796),\n",
       " ('different scenarios disagreement coworker hypothetical',\n",
       "  0.11396057645963796),\n",
       " ('python seemed like better software', 0.11396057645963796),\n",
       " ('advanced sql hard python seemed', 0.11396057645963796),\n",
       " ('manager screen asked resume asked', 0.11396057645963796),\n",
       " ('disagreement coworker hypothetical make spam', 0.11396057645963796),\n",
       " ('hr onsite intermediate advanced sql', 0.11396057645963796),\n",
       " ('metric unlimited data presentation people', 0.11396057645963796),\n",
       " ('extremely condescending rude seemed like', 0.11396057645963796),\n",
       " ('hypothetical questions handle different scenarios', 0.11396057645963796),\n",
       " ('intermediate advanced sql hard python', 0.11396057645963796),\n",
       " ('idea work team culture fanboys', 0.11396057645963796),\n",
       " ('management trust firstline management make', 0.11396057645963796),\n",
       " ('presentation people extremely condescending rude', 0.11396057645963796),\n",
       " ('hard python seemed like better', 0.11396057645963796),\n",
       " ('handle different scenarios disagreement coworker', 0.11396057645963796),\n",
       " ('decisions waterfall seemingly secretive cant', 0.11396057645963796),\n",
       " ('sense statistics case study given', 0.10101525445522108),\n",
       " ('extremely combative interviewer came know', 0.10101525445522108),\n",
       " ('manager screening technical assessment sql', 0.10101525445522108),\n",
       " ('experience final rounds negative one', 0.10101525445522108),\n",
       " ('tedious interview process spanned multiple', 0.10101525445522108),\n",
       " ('distracted left minutes early finally', 0.10101525445522108),\n",
       " ('led awkward conversation couldnt understand', 0.10101525445522108),\n",
       " ('sense interview philosophical debate bayesian', 0.10101525445522108),\n",
       " ('technical assessment sql case study', 0.10101525445522108),\n",
       " ('screening technical assessment sql case', 0.10101525445522108),\n",
       " ('last interview hear recruiter weeks', 0.10101525445522108),\n",
       " ('left minutes early finally debate', 0.10101525445522108),\n",
       " ('screening hiring manager screening technical', 0.10101525445522108),\n",
       " ('early finally debate extremely combative', 0.10101525445522108),\n",
       " ('long tedious interview process spanned', 0.10101525445522108),\n",
       " ('ab testing final round challenging', 0.10101525445522108),\n",
       " ('separate interviews behavioral product sense', 0.10101525445522108),\n",
       " ('sql case study presentation panel', 0.10101525445522108),\n",
       " ('interview process spanned multiple stages', 0.10101525445522108),\n",
       " ('interview philosophical debate bayesian vs', 0.10101525445522108),\n",
       " ('spanned multiple stages hr screening', 0.10101525445522108),\n",
       " ...]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appleprocess_vectorizer = TfidfVectorizer(ngram_range=(5,5), min_df=0.001, max_df = 0.75)\n",
    "apple_vectorized_process = pd.DataFrame(appleprocess_vectorizer.fit_transform(apple_process_df['Process']).toarray(), columns = appleprocess_vectorizer.get_feature_names_out())\n",
    "apple_vectorized_process.loc['Total'] = apple_vectorized_process.sum(numeric_only=True, axis=0)\n",
    "apple_vectorized_process = apple_vectorized_process.sort_values(apple_vectorized_process.last_valid_index(), axis=1, ascending=False)\n",
    "appleprocess_sorted_word_list = [(col, apple_vectorized_process[col].iloc[-1]) for col in apple_vectorized_process.columns]\n",
    "appleprocess_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google TFIDF Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('short interview nice talk product', 0.4588314677411235),\n",
       " ('interview nice talk product manager', 0.4588314677411235),\n",
       " ('interview although good made end', 0.37796447300922725),\n",
       " ('talking great excited code interview', 0.37796447300922725),\n",
       " ('recruiter questionnaire days applying online', 0.37796447300922725),\n",
       " ('great smooth talking great excited', 0.37796447300922725),\n",
       " ('online questionnaire schedule phone interview', 0.37796447300922725),\n",
       " ('great excited code interview although', 0.37796447300922725),\n",
       " ('code interview although good made', 0.37796447300922725),\n",
       " ('excited code interview although good', 0.37796447300922725),\n",
       " ('smooth talking great excited code', 0.37796447300922725),\n",
       " ('reply recruiter questionnaire days applying', 0.37796447300922725),\n",
       " ('got reply recruiter questionnaire days', 0.37796447300922725),\n",
       " ('days applying online questionnaire schedule', 0.37796447300922725),\n",
       " ('applying online questionnaire schedule phone', 0.37796447300922725),\n",
       " ('questionnaire days applying online questionnaire', 0.37796447300922725),\n",
       " ('sexist also seem technical interested', 0.35355339059327373),\n",
       " ('technical interested hiring fit woman', 0.35355339059327373),\n",
       " ('duration connecting month send email', 0.35355339059327373),\n",
       " ('also seem technical interested hiring', 0.35355339059327373),\n",
       " ('experience asked code live explain', 0.35355339059327373),\n",
       " ('asked code live explain codem', 0.35355339059327373),\n",
       " ('case fortunately acceptetthe duration connecting', 0.35355339059327373),\n",
       " ('videocall asked experience asked code', 0.35355339059327373),\n",
       " ('fortunately acceptetthe duration connecting month', 0.35355339059327373),\n",
       " ('seem technical interested hiring fit', 0.35355339059327373),\n",
       " ('code live explain codem wich', 0.35355339059327373),\n",
       " ('connecting month send email visit', 0.35355339059327373),\n",
       " ('live explain codem wich python', 0.35355339059327373),\n",
       " ('asked experience asked code live', 0.35355339059327373),\n",
       " ('proffesional interview case fortunately acceptetthe', 0.35355339059327373),\n",
       " ('managers execs incredibly sexist also', 0.35355339059327373),\n",
       " ('acceptetthe duration connecting month send', 0.35355339059327373),\n",
       " ('explain codem wich python asked', 0.35355339059327373),\n",
       " ('interview case fortunately acceptetthe duration', 0.35355339059327373),\n",
       " ('hiring managers execs incredibly sexist', 0.35355339059327373),\n",
       " ('codem wich python asked coding', 0.35355339059327373),\n",
       " ('like proffesional interview case fortunately', 0.35355339059327373),\n",
       " ('incredibly sexist also seem technical', 0.35355339059327373),\n",
       " ('execs incredibly sexist also seem', 0.35355339059327373),\n",
       " ('screen onsite need pass tech', 0.3333333333333333),\n",
       " ('first get onsite onsite like', 0.3333333333333333),\n",
       " ('tech screen onsite need pass', 0.3333333333333333),\n",
       " ('onsite need pass tech screen', 0.3333333333333333),\n",
       " ('get onsite onsite like interviews', 0.3333333333333333),\n",
       " ('need pass tech screen first', 0.3333333333333333),\n",
       " ('screen first get onsite onsite', 0.3333333333333333),\n",
       " ('tech screen first get onsite', 0.3333333333333333),\n",
       " ('pass tech screen first get', 0.3333333333333333),\n",
       " ('interview questions simple similar got', 0.31622776601683794),\n",
       " ('career google questions asked interview', 0.31622776601683794),\n",
       " ('focused heshe wants career google', 0.31622776601683794),\n",
       " ('questions simple similar got interviews', 0.31622776601683794),\n",
       " ('questions via phone interview questions', 0.31622776601683794),\n",
       " ('interview process easy candidate need', 0.31622776601683794),\n",
       " ('different job one applied already', 0.31622776601683794),\n",
       " ('hr suggested different job one', 0.31622776601683794),\n",
       " ('technical skills statistics probability questions', 0.31622776601683794),\n",
       " ('applied already filled back forth', 0.31622776601683794),\n",
       " ('easy candidate need focused heshe', 0.31622776601683794),\n",
       " ('candidate need focused heshe wants', 0.31622776601683794),\n",
       " ('wants career google questions asked', 0.31622776601683794),\n",
       " ('suggested different job one applied', 0.31622776601683794),\n",
       " ('smooth hr suggested different job', 0.31622776601683794),\n",
       " ('process easy candidate need focused', 0.31622776601683794),\n",
       " ('skills statistics probability questions via', 0.31622776601683794),\n",
       " ('filled back forth emails scheduling', 0.31622776601683794),\n",
       " ('one applied already filled back', 0.31622776601683794),\n",
       " ('statistics probability questions via phone', 0.31622776601683794),\n",
       " ('already filled back forth emails', 0.31622776601683794),\n",
       " ('phone interview questions simple similar', 0.31622776601683794),\n",
       " ('asked technical skills statistics probability', 0.31622776601683794),\n",
       " ('job one applied already filled', 0.31622776601683794),\n",
       " ('heshe wants career google questions', 0.31622776601683794),\n",
       " ('google questions asked interview easy', 0.31622776601683794),\n",
       " ('via phone interview questions simple', 0.31622776601683794),\n",
       " ('need focused heshe wants career', 0.31622776601683794),\n",
       " ('probability questions via phone interview', 0.31622776601683794),\n",
       " ('asked lot information related products', 0.3015113445777636),\n",
       " ('recruiter call phone schedule phone', 0.3015113445777636),\n",
       " ('according team applied asked lot', 0.3015113445777636),\n",
       " ('mins according team applied asked', 0.3015113445777636),\n",
       " ('interview mins according team applied', 0.3015113445777636),\n",
       " ('call phone schedule phone interview', 0.3015113445777636),\n",
       " ('schedule phone interview mins according', 0.3015113445777636),\n",
       " ('applied asked lot information related', 0.3015113445777636),\n",
       " ('phone interview mins according team', 0.3015113445777636),\n",
       " ('team applied asked lot information', 0.3015113445777636),\n",
       " ('phone schedule phone interview mins', 0.3015113445777636),\n",
       " ('hr reply called hr phone', 0.28867513459481287),\n",
       " ('hr phone interview onsite could', 0.28867513459481287),\n",
       " ('sql interviewer never mentioned keep', 0.28867513459481287),\n",
       " ('asking experience statistic question experience', 0.28867513459481287),\n",
       " ('rounds onsite interviews tech interviews', 0.28867513459481287),\n",
       " ('show interview first interview quite', 0.28867513459481287),\n",
       " ('hr passed technical interview important', 0.28867513459481287),\n",
       " ('rigorous phone call coding challenge', 0.28867513459481287),\n",
       " ('hr know next show interview', 0.28867513459481287),\n",
       " ('session culture fit really testing', 0.28867513459481287),\n",
       " ('seems interviewer know telling neither', 0.28867513459481287),\n",
       " ('require join table python asked', 0.28867513459481287),\n",
       " ('easy evaluate culture fit candidate', 0.28867513459481287),\n",
       " ('important prepared enough website called', 0.28867513459481287),\n",
       " ('reply called hr phone interview', 0.28867513459481287),\n",
       " ('onsite interviews tech interviews behavior', 0.28867513459481287),\n",
       " ('join table python asked join', 0.28867513459481287),\n",
       " ('keep asking experience statistic question', 0.28867513459481287),\n",
       " ('phone interview rounds onsite interviews', 0.28867513459481287),\n",
       " ('phone interview onsite could earlier', 0.28867513459481287),\n",
       " ('phone call coding challenge whiteboard', 0.28867513459481287),\n",
       " ('know next show interview first', 0.28867513459481287),\n",
       " ('know telling neither interviewers extremely', 0.28867513459481287),\n",
       " ('passed technical interview important prepared', 0.28867513459481287),\n",
       " ('painfully long rigorous phone call', 0.28867513459481287),\n",
       " ('leetcode unfortunately didnt go well', 0.28867513459481287),\n",
       " ('interview first hr know next', 0.28867513459481287),\n",
       " ('onsite could earlier holiday season', 0.28867513459481287),\n",
       " ('online waited around month hr', 0.28867513459481287),\n",
       " ('online prescreening step filling form', 0.28867513459481287),\n",
       " ('long rigorous phone call coding', 0.28867513459481287),\n",
       " ('next show interview first interview', 0.28867513459481287),\n",
       " ('culture fit really testing smart', 0.28867513459481287),\n",
       " ('never mentioned keep asking experience', 0.28867513459481287),\n",
       " ('neither interviewers extremely unprofessional require',\n",
       "  0.28867513459481287),\n",
       " ('month hr reply called hr', 0.28867513459481287),\n",
       " ('prepared enough website called leetcode', 0.28867513459481287),\n",
       " ('coding challenge whiteboard session culture', 0.28867513459481287),\n",
       " ('prescreening step filling form tech', 0.28867513459481287),\n",
       " ('interviews tech interviews behavior interview', 0.28867513459481287),\n",
       " ('interview first interview quite easy', 0.28867513459481287),\n",
       " ('interview hr passed technical interview', 0.28867513459481287),\n",
       " ('interview important prepared enough website', 0.28867513459481287),\n",
       " ('call coding challenge whiteboard session', 0.28867513459481287),\n",
       " ('call interview first hr know', 0.28867513459481287),\n",
       " ('interview onsite could earlier holiday', 0.28867513459481287),\n",
       " ('called hr phone interview onsite', 0.28867513459481287),\n",
       " ('called leetcode unfortunately didnt go', 0.28867513459481287),\n",
       " ('really testing smart capable engineer', 0.28867513459481287),\n",
       " ('quite easy evaluate culture fit', 0.28867513459481287),\n",
       " ('interview quite easy evaluate culture', 0.28867513459481287),\n",
       " ('interview rounds onsite interviews tech', 0.28867513459481287),\n",
       " ('challenge whiteboard session culture fit', 0.28867513459481287),\n",
       " ('interviewer familiar process told test', 0.28867513459481287),\n",
       " ('python asked join sql told', 0.28867513459481287),\n",
       " ('interviewer know telling neither interviewers', 0.28867513459481287),\n",
       " ('interviewer never mentioned keep asking', 0.28867513459481287),\n",
       " ('interviewers extremely unprofessional require join', 0.28867513459481287),\n",
       " ('process told test sql interviewer', 0.28867513459481287),\n",
       " ('step filling form tech phone', 0.28867513459481287),\n",
       " ('mentioned keep asking experience statistic', 0.28867513459481287),\n",
       " ('apply online prescreening step filling', 0.28867513459481287),\n",
       " ('unprofessional require join table python', 0.28867513459481287),\n",
       " ('familiar process told test sql', 0.28867513459481287),\n",
       " ('extremely unprofessional require join table', 0.28867513459481287),\n",
       " ('experience statistic question experience good', 0.28867513459481287),\n",
       " ('filling form tech phone interview', 0.28867513459481287),\n",
       " ('test sql interviewer never mentioned', 0.28867513459481287),\n",
       " ('first interview quite easy evaluate', 0.28867513459481287),\n",
       " ('form tech phone interview rounds', 0.28867513459481287),\n",
       " ('first interview hr passed technical', 0.28867513459481287),\n",
       " ('table python asked join sql', 0.28867513459481287),\n",
       " ('enough website called leetcode unfortunately', 0.28867513459481287),\n",
       " ('fit really testing smart capable', 0.28867513459481287),\n",
       " ('waited around month hr reply', 0.28867513459481287),\n",
       " ('first hr know next show', 0.28867513459481287),\n",
       " ('around month hr reply called', 0.28867513459481287),\n",
       " ('telling neither interviewers extremely unprofessional',\n",
       "  0.28867513459481287),\n",
       " ('technical interview important prepared enough', 0.28867513459481287),\n",
       " ('whiteboard session culture fit really', 0.28867513459481287),\n",
       " ('applied online waited around month', 0.28867513459481287),\n",
       " ('told test sql interviewer never', 0.28867513459481287),\n",
       " ('website called leetcode unfortunately didnt', 0.28867513459481287),\n",
       " ('tech phone interview rounds onsite', 0.28867513459481287),\n",
       " ('phone screen hangout interview onsite', 0.2773500981126146),\n",
       " ('job application didnt get interview', 0.2773500981126146),\n",
       " ('get interview recommended another ux', 0.2773500981126146),\n",
       " ('scientist us approached hr recruiter', 0.2773500981126146),\n",
       " ('tech phone interview contacted recruiter', 0.2773500981126146),\n",
       " ('hiring manager managerial colleagues teams', 0.2773500981126146),\n",
       " ('screen hangout interview onsite sensed', 0.2773500981126146),\n",
       " ('approached hr recruiter first placetook', 0.2773500981126146),\n",
       " ('challenging encountered lot statistics questions', 0.2773500981126146),\n",
       " ('placetook weeks arrange call finally', 0.2773500981126146),\n",
       " ('interviews challenging encountered lot statistics', 0.2773500981126146),\n",
       " ('interview contacted recruiter months job', 0.2773500981126146),\n",
       " ('checking chemistry hiring manager managerial', 0.2773500981126146),\n",
       " ('technical interviews challenging encountered lot', 0.2773500981126146),\n",
       " ('didnt get interview recommended another', 0.2773500981126146),\n",
       " ('application phone screen hangout interview', 0.2773500981126146),\n",
       " ('reminiscent casella berger statistics text', 0.2773500981126146),\n",
       " ('weeks arrange call finally speak', 0.2773500981126146),\n",
       " ('data scientist us approached hr', 0.2773500981126146),\n",
       " ('sensed onsite interviews checking chemistry', 0.2773500981126146),\n",
       " ('questions reminiscent casella berger statistics', 0.2773500981126146),\n",
       " ('onsite sensed onsite interviews checking', 0.2773500981126146),\n",
       " ('application didnt get interview recommended', 0.2773500981126146),\n",
       " ('hr recruiter first placetook weeks', 0.2773500981126146),\n",
       " ('interviews checking chemistry hiring manager', 0.2773500981126146),\n",
       " ('onsite interviews checking chemistry hiring', 0.2773500981126146),\n",
       " ('casella berger statistics text book', 0.2773500981126146),\n",
       " ('phone interview contacted recruiter months', 0.2773500981126146),\n",
       " ('forward technical interviews challenging encountered', 0.2773500981126146),\n",
       " ('recommended another ux position google', 0.2773500981126146),\n",
       " ('hangout call data scientist us', 0.2773500981126146),\n",
       " ('hangout interview onsite sensed onsite', 0.2773500981126146),\n",
       " ('contacted recruiter months job application', 0.2773500981126146),\n",
       " ('first two straight forward technical', 0.2773500981126146),\n",
       " ('statistics questions reminiscent casella berger', 0.2773500981126146),\n",
       " ('encountered lot statistics questions reminiscent', 0.2773500981126146),\n",
       " ('got tech phone interview contacted', 0.2773500981126146),\n",
       " ('recruiter first placetook weeks arrange', 0.2773500981126146),\n",
       " ('recruiter months job application didnt', 0.2773500981126146),\n",
       " ('two straight forward technical interviews', 0.2773500981126146),\n",
       " ('lot statistics questions reminiscent casella', 0.2773500981126146),\n",
       " ('chemistry hiring manager managerial colleagues', 0.2773500981126146),\n",
       " ('us approached hr recruiter first', 0.2773500981126146),\n",
       " ('arrange call finally speak interviewer', 0.2773500981126146),\n",
       " ('google hangout call data scientist', 0.2773500981126146),\n",
       " ('months job application didnt get', 0.2773500981126146),\n",
       " ('submission application phone screen hangout', 0.2773500981126146),\n",
       " ('first placetook weeks arrange call', 0.2773500981126146),\n",
       " ('straight forward technical interviews challenging', 0.2773500981126146),\n",
       " ('interview recommended another ux position', 0.2773500981126146),\n",
       " ('call data scientist us approached', 0.2773500981126146),\n",
       " ('interview onsite sensed onsite interviews', 0.2773500981126146),\n",
       " ('first phone screen hr technical', 0.2672612419124244),\n",
       " ('portal recruiter called back month', 0.2672612419124244),\n",
       " ('wanted tried ask easy connect', 0.2672612419124244),\n",
       " ('application processed careers website briefly', 0.2672612419124244),\n",
       " ('technical phone interviews rejected interviewer', 0.2672612419124244),\n",
       " ('five data scientists also got', 0.2672612419124244),\n",
       " ('really match asked interview interviewer', 0.2672612419124244),\n",
       " ('distracted looked like know wanted', 0.2672612419124244),\n",
       " ('pretty disconnected distracted looked like', 0.2672612419124244),\n",
       " ('interview really match asked interview', 0.2672612419124244),\n",
       " ('careers website briefly spoke hr', 0.2672612419124244),\n",
       " ('called back month explained whole', 0.2672612419124244),\n",
       " ('interview interviewer also several minutes', 0.2672612419124244),\n",
       " ('gave prepare interview really match', 0.2672612419124244),\n",
       " ('also got chance talk team', 0.2672612419124244),\n",
       " ('briefly spoke hr asked fill', 0.2672612419124244),\n",
       " ('prepare interview really match asked', 0.2672612419124244),\n",
       " ('phone screen hr technical phone', 0.2672612419124244),\n",
       " ('every interview focusing different aspects', 0.2672612419124244),\n",
       " ('refer whole process took month', 0.2672612419124244),\n",
       " ('different toolsets projects showcase tools', 0.2672612419124244),\n",
       " ('referral information gave prepare interview', 0.2672612419124244),\n",
       " ('recruiter called back month explained', 0.2672612419124244),\n",
       " ('focusing different aspects data science', 0.2672612419124244),\n",
       " ('interview focusing different aspects data', 0.2672612419124244),\n",
       " ('took month first phone screen', 0.2672612419124244),\n",
       " ('disconnected distracted looked like know', 0.2672612419124244),\n",
       " ('interview five data scientists also', 0.2672612419124244),\n",
       " ('phone interviews rejected interviewer remote', 0.2672612419124244),\n",
       " ('interviewer pretty disconnected distracted looked', 0.2672612419124244),\n",
       " ('applied referral information gave prepare', 0.2672612419124244),\n",
       " ('interviews rejected interviewer remote cold', 0.2672612419124244),\n",
       " ('match asked interview interviewer also', 0.2672612419124244),\n",
       " ('interviewer also several minutes late', 0.2672612419124244),\n",
       " ('team leaders think future data', 0.2672612419124244),\n",
       " ('looked like know wanted tried', 0.2672612419124244),\n",
       " ('connect hr get phonevideo interview', 0.2672612419124244),\n",
       " ('several minutes late interview google', 0.2672612419124244),\n",
       " ('assessment onsite interview five data', 0.2672612419124244),\n",
       " ('chance talk team leaders think', 0.2672612419124244),\n",
       " ('talk team leaders think future', 0.2672612419124244),\n",
       " ('whole process took month first', 0.2672612419124244),\n",
       " ('consists interviews every interview focusing', 0.2672612419124244),\n",
       " ('process took month first phone', 0.2672612419124244),\n",
       " ('explained whole process consists interviews', 0.2672612419124244),\n",
       " ('ask easy connect hr get', 0.2672612419124244),\n",
       " ('information gave prepare interview really', 0.2672612419124244),\n",
       " ('two online assessment onsite interview', 0.2672612419124244),\n",
       " ('processed careers website briefly spoke', 0.2672612419124244),\n",
       " ('spoke hr asked fill google', 0.2672612419124244),\n",
       " ('google document information experiences different', 0.2672612419124244),\n",
       " ('employee refer whole process took', 0.2672612419124244),\n",
       " ('month first phone screen hr', 0.2672612419124244),\n",
       " ('asked interview interviewer also several', 0.2672612419124244),\n",
       " ('got employee refer whole process', 0.2672612419124244),\n",
       " ('asked fill google document information', 0.2672612419124244),\n",
       " ('month explained whole process consists', 0.2672612419124244),\n",
       " ('minutes late interview google hangouts', 0.2672612419124244),\n",
       " ('got chance talk team leaders', 0.2672612419124244),\n",
       " ('whole process consists interviews every', 0.2672612419124244),\n",
       " ('like know wanted tried ask', 0.2672612419124244),\n",
       " ('interviews every interview focusing different', 0.2672612419124244),\n",
       " ('leaders think future data science', 0.2672612419124244),\n",
       " ('process consists interviews every interview', 0.2672612419124244),\n",
       " ('information experiences different toolsets projects', 0.2672612419124244),\n",
       " ('website briefly spoke hr asked', 0.2672612419124244),\n",
       " ('document information experiences different toolsets', 0.2672612419124244),\n",
       " ('know wanted tried ask easy', 0.2672612419124244),\n",
       " ('data scientists also got chance', 0.2672612419124244),\n",
       " ('applied portal recruiter called back', 0.2672612419124244),\n",
       " ('hr technical phone interviews rejected', 0.2672612419124244),\n",
       " ('get phonevideo interview right away', 0.2672612419124244),\n",
       " ('online assessment onsite interview five', 0.2672612419124244),\n",
       " ('also several minutes late interview', 0.2672612419124244),\n",
       " ('easy connect hr get phonevideo', 0.2672612419124244),\n",
       " ('hr asked fill google document', 0.2672612419124244),\n",
       " ('hr get phonevideo interview right', 0.2672612419124244),\n",
       " ('tried ask easy connect hr', 0.2672612419124244),\n",
       " ('experiences different toolsets projects showcase', 0.2672612419124244),\n",
       " ('scientists also got chance talk', 0.2672612419124244),\n",
       " ('fill google document information experiences', 0.2672612419124244),\n",
       " ('onsite interview five data scientists', 0.2672612419124244),\n",
       " ('screen hr technical phone interviews', 0.2672612419124244),\n",
       " ('back month explained whole process', 0.2672612419124244),\n",
       " ('clearance phone interview onsite interview', 0.25819888974716115),\n",
       " ('problems statistics probability basic coding', 0.25819888974716115),\n",
       " ('interviews differnent topics like coiding', 0.25819888974716115),\n",
       " ('interviewers friendly would give time', 0.25819888974716115),\n",
       " ('fit role based background technical', 0.25819888974716115),\n",
       " ('problem solving skills think know', 0.25819888974716115),\n",
       " ('interviews waited months hiring committee', 0.25819888974716115),\n",
       " ('interviews answers required typed google', 0.25819888974716115),\n",
       " ('process super smooth questions tough', 0.25819888974716115),\n",
       " ('googles website recruiter advanced final', 0.25819888974716115),\n",
       " ('introduction coding challange statistics question', 0.25819888974716115),\n",
       " ('whole process quick hr nice', 0.25819888974716115),\n",
       " ('final round right away interviews', 0.25819888974716115),\n",
       " ('online waited days get email', 0.25819888974716115),\n",
       " ('advanced final round right away', 0.25819888974716115),\n",
       " ('data scientist intern three rounds', 0.25819888974716115),\n",
       " ('like coiding stats interviewers friendly', 0.25819888974716115),\n",
       " ('nice questions easy statistic problems', 0.25819888974716115),\n",
       " ('nice give many hints along', 0.25819888974716115),\n",
       " ('would give time reply questions', 0.25819888974716115),\n",
       " ('days get email hr set', 0.25819888974716115),\n",
       " ('many hints along way interview', 0.25819888974716115),\n",
       " ('material preparing interview video interview', 0.25819888974716115),\n",
       " ('mathematics behind concepts good go', 0.25819888974716115),\n",
       " ('months submission googles website recruiter', 0.25819888974716115),\n",
       " ('contacts email assesses fit role', 0.25819888974716115),\n",
       " ('may happen faang want understand', 0.25819888974716115),\n",
       " ('youtube interviewer nice questions easy', 0.25819888974716115),\n",
       " ('experience may happen faang want', 0.25819888974716115),\n",
       " ('data scientist position youtube interviewer', 0.25819888974716115),\n",
       " ('website recruiter advanced final round', 0.25819888974716115),\n",
       " ('pending clearance phone interview onsite', 0.25819888974716115),\n",
       " ('preparing interview video interview data', 0.25819888974716115),\n",
       " ('coding challange statistics question related', 0.25819888974716115),\n",
       " ('video interview data scientist position', 0.25819888974716115),\n",
       " ('position youtube interviewer nice questions', 0.25819888974716115),\n",
       " ('waited days get email hr', 0.25819888974716115),\n",
       " ('waited months hiring committee decision', 0.25819888974716115),\n",
       " ('phone interviews answers required typed', 0.25819888974716115),\n",
       " ('phone interview scheduled pending clearance', 0.25819888974716115),\n",
       " ('want understand way thinking problem', 0.25819888974716115),\n",
       " ('phone interview onsite interview scheduled', 0.25819888974716115),\n",
       " ('along way interview give hypothetic', 0.25819888974716115),\n",
       " ('way interview give hypothetic business', 0.25819888974716115),\n",
       " ('know else say good luck', 0.25819888974716115),\n",
       " ('coiding stats interviewers friendly would', 0.25819888974716115),\n",
       " ('know mathematics behind concepts good', 0.25819888974716115),\n",
       " ('way thinking problem solving skills', 0.25819888974716115),\n",
       " ('time reply questions dont know', 0.25819888974716115),\n",
       " ('unique experience may happen faang', 0.25819888974716115),\n",
       " ('related hypothesis testing interview process', 0.25819888974716115),\n",
       " ('scheduled pending clearance phone interview', 0.25819888974716115),\n",
       " ('give material preparing interview video', 0.25819888974716115),\n",
       " ('give many hints along way', 0.25819888974716115),\n",
       " ('give hypothetic business question ask', 0.25819888974716115),\n",
       " ('based background technical phone interview', 0.25819888974716115),\n",
       " ('hr set screen interview techphone', 0.25819888974716115),\n",
       " ('rounds phone interviews answers required', 0.25819888974716115),\n",
       " ('dont know else say good', 0.25819888974716115),\n",
       " ('hypothesis testing interview process super', 0.25819888974716115),\n",
       " ('hypothetic business question ask correct', 0.25819888974716115),\n",
       " ('applied online waited days get', 0.25819888974716115),\n",
       " ('round right away interviews waited', 0.25819888974716115),\n",
       " ('interviewer nice questions easy statistic', 0.25819888974716115),\n",
       " ('doc problems statistics probability basic', 0.25819888974716115),\n",
       " ('role based background technical phone', 0.25819888974716115),\n",
       " ('intern three rounds phone interviews', 0.25819888974716115),\n",
       " ('right away interviews waited months', 0.25819888974716115),\n",
       " ('interview applied online waited days', 0.25819888974716115),\n",
       " ('technical phone interview scheduled pending', 0.25819888974716115),\n",
       " ('required typed google doc problems', 0.25819888974716115),\n",
       " ('reply questions dont know else', 0.25819888974716115),\n",
       " ('give time reply questions dont', 0.25819888974716115),\n",
       " ('background technical phone interview scheduled', 0.25819888974716115),\n",
       " ('scientist intern three rounds phone', 0.25819888974716115),\n",
       " ('google data scientist intern three', 0.25819888974716115),\n",
       " ('submission googles website recruiter advanced', 0.25819888974716115),\n",
       " ('stats interviewers friendly would give', 0.25819888974716115),\n",
       " ('statistics question related hypothesis testing', 0.25819888974716115),\n",
       " ('statistics question interviewer interview nice', 0.25819888974716115),\n",
       " ('super smooth questions tough person', 0.25819888974716115),\n",
       " ('solving skills think know mathematics', 0.25819888974716115),\n",
       " ('google doc problems statistics probability', 0.25819888974716115),\n",
       " ('smooth questions tough person come', 0.25819888974716115),\n",
       " ('happen faang want understand way', 0.25819888974716115),\n",
       " ('email hr set screen interview', 0.25819888974716115),\n",
       " ('scientist position youtube interviewer nice', 0.25819888974716115),\n",
       " ('skills think know mathematics behind', 0.25819888974716115),\n",
       " ('arranged interview give material preparing', 0.25819888974716115),\n",
       " ('email assesses fit role based', 0.25819888974716115),\n",
       " ('assesses fit role based background', 0.25819888974716115),\n",
       " ('set screen interview techphone interview', 0.25819888974716115),\n",
       " ('hints along way interview give', 0.25819888974716115),\n",
       " ('away interviews waited months hiring', 0.25819888974716115),\n",
       " ('hr arranged interview give material', 0.25819888974716115),\n",
       " ('screen interview techphone interview whole', 0.25819888974716115),\n",
       " ('interview data scientist position youtube', 0.25819888974716115),\n",
       " ('faang want understand way thinking', 0.25819888974716115),\n",
       " ('thinking problem solving skills think', 0.25819888974716115),\n",
       " ('call recruiter months submission googles', 0.25819888974716115),\n",
       " ('friendly would give time reply', 0.25819888974716115),\n",
       " ('recruiter advanced final round right', 0.25819888974716115),\n",
       " ('think know mathematics behind concepts', 0.25819888974716115),\n",
       " ('question interviewer interview nice give', 0.25819888974716115),\n",
       " ('interview process super smooth questions', 0.25819888974716115),\n",
       " ('three rounds phone interviews answers', 0.25819888974716115),\n",
       " ('got call recruiter months submission', 0.25819888974716115),\n",
       " ('questions tough person come statistics', 0.25819888974716115),\n",
       " ('question related hypothesis testing interview', 0.25819888974716115),\n",
       " ('topics like coiding stats interviewers', 0.25819888974716115),\n",
       " ('interviewed google data scientist intern', 0.25819888974716115),\n",
       " ('tough person come statistics background', 0.25819888974716115),\n",
       " ('interview whole process quick hr', 0.25819888974716115),\n",
       " ('interview video interview data scientist', 0.25819888974716115),\n",
       " ('challange statistics question related hypothesis', 0.25819888974716115),\n",
       " ('interview scheduled pending clearance phone', 0.25819888974716115),\n",
       " ('interview techphone interview whole process', 0.25819888974716115),\n",
       " ('testing interview process super smooth', 0.25819888974716115),\n",
       " ('questions dont know else say', 0.25819888974716115),\n",
       " ('interviewer interview nice give many', 0.25819888974716115),\n",
       " ('techphone interview applied online waited', 0.25819888974716115),\n",
       " ('interview give hypothetic business question', 0.25819888974716115),\n",
       " ('interview give material preparing interview', 0.25819888974716115),\n",
       " ('techphone interview whole process quick', 0.25819888974716115),\n",
       " ('brief introduction coding challange statistics', 0.25819888974716115),\n",
       " ('recruiter contacts email assesses fit', 0.25819888974716115),\n",
       " ('understand way thinking problem solving', 0.25819888974716115),\n",
       " ('typed google doc problems statistics', 0.25819888974716115),\n",
       " ('answers required typed google doc', 0.25819888974716115),\n",
       " ('recruiter months submission googles website', 0.25819888974716115),\n",
       " ('business question ask correct metrics', 0.25819888974716115),\n",
       " ('get email hr set screen', 0.25819888974716115),\n",
       " ('differnent topics like coiding stats', 0.25819888974716115),\n",
       " ('interview nice give many hints', 0.25819888974716115),\n",
       " ('brainstorm statistics question interviewer interview', 0.25819888974716115),\n",
       " ('meet used google docs communicate', 0.25000000000000006),\n",
       " ('fellows glad take another one', 0.25000000000000006),\n",
       " ('email hr department interview date', 0.25000000000000006),\n",
       " ('helpful expert like salary good', 0.25000000000000006),\n",
       " ('looking forward next one google', 0.25000000000000006),\n",
       " ('makes sense data scientist role', 0.25000000000000006),\n",
       " ('interviewer connected google meet used', 0.25000000000000006),\n",
       " ('interview two weeks questions clear', 0.25000000000000006),\n",
       " ('department interview date interviewer connected', 0.25000000000000006),\n",
       " ('google meet used google docs', 0.25000000000000006),\n",
       " ('emphasized obviously makes sense data', 0.25000000000000006),\n",
       " ('handled rounds technical questions theoretical', 0.25000000000000006),\n",
       " ('google fellows glad take another', 0.25000000000000006),\n",
       " ('helpful scheduled phone interview two', 0.25000000000000006),\n",
       " ('kind helpful expert like salary', 0.25000000000000006),\n",
       " ('focused ab test confidence interval', 0.25000000000000006),\n",
       " ('fields would love calm hole', 0.25000000000000006),\n",
       " ('data anlysis rounds give problems', 0.25000000000000006),\n",
       " ('difficulty levels specifically technical aspect', 0.25000000000000006),\n",
       " ('interval power analysis machine learning', 0.25000000000000006),\n",
       " ('date received information email hr', 0.25000000000000006),\n",
       " ('inspiring beautiful good team expert', 0.25000000000000006),\n",
       " ('date interviewer connected google meet', 0.25000000000000006),\n",
       " ('first call vo asked question', 0.25000000000000006),\n",
       " ('forward next one google fellows', 0.25000000000000006),\n",
       " ('forward certainly terms difficulty levels', 0.25000000000000006),\n",
       " ('interviw really liked looking forward', 0.25000000000000006),\n",
       " ('hr department interview date interviewer', 0.25000000000000006),\n",
       " ('glad take another one another', 0.25000000000000006),\n",
       " ('hr ask past projects handled', 0.25000000000000006),\n",
       " ('levels specifically technical aspect emphasized', 0.25000000000000006),\n",
       " ('interview date interviewer connected google', 0.25000000000000006),\n",
       " ('expert like salary good environment', 0.25000000000000006),\n",
       " ('good environment inspiring beautiful good', 0.25000000000000006),\n",
       " ('expert team professional fields would', 0.25000000000000006),\n",
       " ('like salary good environment inspiring', 0.25000000000000006),\n",
       " ('liked looking forward next one', 0.25000000000000006),\n",
       " ('good phone screen first call', 0.25000000000000006),\n",
       " ('good team expert team professional', 0.25000000000000006),\n",
       " ('environment inspiring beautiful good team', 0.25000000000000006),\n",
       " ('interview sql skills also case', 0.25000000000000006),\n",
       " ('information email hr department interview', 0.25000000000000006),\n",
       " ('ab test confidence interval power', 0.25000000000000006),\n",
       " ('technical aspect emphasized obviously makes', 0.25000000000000006),\n",
       " ('beautiful good team expert team', 0.25000000000000006),\n",
       " ('straight forward certainly terms difficulty', 0.25000000000000006),\n",
       " ('questions clear focused ab test', 0.25000000000000006),\n",
       " ('certainly terms difficulty levels specifically', 0.25000000000000006),\n",
       " ('ask past projects handled rounds', 0.25000000000000006),\n",
       " ('question sql time series right', 0.25000000000000006),\n",
       " ('take another one another one', 0.25000000000000006),\n",
       " ('team expert team professional fields', 0.25000000000000006),\n",
       " ('projects handled rounds technical questions', 0.25000000000000006),\n",
       " ('team professional fields would love', 0.25000000000000006),\n",
       " ('professional fields would love calm', 0.25000000000000006),\n",
       " ('asked question sql time series', 0.25000000000000006),\n",
       " ('process straight forward certainly terms', 0.25000000000000006),\n",
       " ('technical questions theoretical stats data', 0.25000000000000006),\n",
       " ('clear focused ab test confidence', 0.25000000000000006),\n",
       " ('terms difficulty levels specifically technical', 0.25000000000000006),\n",
       " ('code interview sql skills also', 0.25000000000000006),\n",
       " ('test confidence interval power analysis', 0.25000000000000006),\n",
       " ('power analysis machine learning algorithms', 0.25000000000000006),\n",
       " ('theoretical stats data anlysis rounds', 0.25000000000000006),\n",
       " ('time series right code interview', 0.25000000000000006),\n",
       " ('stats data anlysis rounds give', 0.25000000000000006),\n",
       " ('questions theoretical stats data anlysis', 0.25000000000000006),\n",
       " ('phone interview two weeks questions', 0.25000000000000006),\n",
       " ('avery smooth interviw really liked', 0.25000000000000006),\n",
       " ('rounds give problems ask solve', 0.25000000000000006),\n",
       " ('right code interview sql skills', 0.25000000000000006),\n",
       " ('rounds process straight forward certainly', 0.25000000000000006),\n",
       " ('rounds round hr ask past', 0.25000000000000006),\n",
       " ('rounds technical questions theoretical stats', 0.25000000000000006),\n",
       " ('salary good environment inspiring beautiful', 0.25000000000000006),\n",
       " ('scheduled date received information email', 0.25000000000000006),\n",
       " ('scheduled phone interview two weeks', 0.25000000000000006),\n",
       " ('screen first call vo asked', 0.25000000000000006),\n",
       " ('series right code interview sql', 0.25000000000000006),\n",
       " ('sql time series right code', 0.25000000000000006),\n",
       " ('aspect emphasized obviously makes sense', 0.25000000000000006),\n",
       " ('recruiter helpful scheduled phone interview', 0.25000000000000006),\n",
       " ('recruiter contacted scheduled date received', 0.25000000000000006),\n",
       " ('smooth interviw really liked looking', 0.25000000000000006),\n",
       " ('call vo asked question sql', 0.25000000000000006),\n",
       " ('received information email hr department', 0.25000000000000006),\n",
       " ('really liked looking forward next', 0.25000000000000006),\n",
       " ('specifically technical aspect emphasized obviously', 0.25000000000000006),\n",
       " ('sql skills also case study', 0.25000000000000006),\n",
       " ('phone screen first call vo', 0.25000000000000006),\n",
       " ('round hr ask past projects', 0.25000000000000006),\n",
       " ('wa avery smooth interviw really', 0.25000000000000006),\n",
       " ('would love calm hole interview', 0.25000000000000006),\n",
       " ('obviously makes sense data scientist', 0.25000000000000006),\n",
       " ('two weeks questions clear focused', 0.25000000000000006),\n",
       " ('next one google fellows glad', 0.25000000000000006),\n",
       " ('one another one another one', 0.25000000000000006),\n",
       " ('used google docs communicate interviewer', 0.25000000000000006),\n",
       " ('connected google meet used google', 0.25000000000000006),\n",
       " ('contacted recruiter helpful scheduled phone', 0.25000000000000006),\n",
       " ('past projects handled rounds technical', 0.25000000000000006),\n",
       " ('vo asked question sql time', 0.25000000000000006),\n",
       " ('weeks questions clear focused ab', 0.25000000000000006),\n",
       " ('although took rounds process straight', 0.25000000000000006),\n",
       " ('contacted scheduled date received information', 0.25000000000000006),\n",
       " ('anlysis rounds give problems ask', 0.25000000000000006),\n",
       " ('confidence interval power analysis machine', 0.25000000000000006),\n",
       " ('took rounds process straight forward', 0.25000000000000006),\n",
       " ('another one another one another', 0.25000000000000006),\n",
       " ('one google fellows glad take', 0.25000000000000006),\n",
       " ('nice good phone screen first', 0.25000000000000006),\n",
       " ('onsite rounds round hr ask', 0.25000000000000006),\n",
       " ('availability phone interview gave five', 0.242535625036333),\n",
       " ('second round consists interviews technical', 0.242535625036333),\n",
       " ('hard engage whether even going', 0.242535625036333),\n",
       " ('hard work asked availability phone', 0.242535625036333),\n",
       " ('simple conceptual question second round', 0.242535625036333),\n",
       " ('algorithm using pseudo code coding', 0.242535625036333),\n",
       " ('home project finished within week', 0.242535625036333),\n",
       " ('finished within week like project', 0.242535625036333),\n",
       " ('since questions openended hard engage', 0.242535625036333),\n",
       " ('slow extremely hard work asked', 0.242535625036333),\n",
       " ('experience projects background looks take', 0.242535625036333),\n",
       " ('went resume give take home', 0.242535625036333),\n",
       " ('background looks take communication first', 0.242535625036333),\n",
       " ('second round asked non normal', 0.242535625036333),\n",
       " ('screen virtual onsite day rounds', 0.242535625036333),\n",
       " ('round second round asked non', 0.242535625036333),\n",
       " ('implement machine learning algorithm using', 0.242535625036333),\n",
       " ('round simple conceptual question second', 0.242535625036333),\n",
       " ('extremely hard work asked availability', 0.242535625036333),\n",
       " ('rounds one resume machine learning', 0.242535625036333),\n",
       " ('fast relatively non software technical', 0.242535625036333),\n",
       " ('hr slow extremely hard work', 0.242535625036333),\n",
       " ('rounds total techs behavior questions', 0.242535625036333),\n",
       " ('work asked availability phone interview', 0.242535625036333),\n",
       " ('within week like project enter', 0.242535625036333),\n",
       " ('white board interview questions difficult', 0.242535625036333),\n",
       " ('scheduling followed phone screen senior', 0.242535625036333),\n",
       " ('science problems lot back forth', 0.242535625036333),\n",
       " ('hr days mins chat regular', 0.242535625036333),\n",
       " ('whether even going direction wanted', 0.242535625036333),\n",
       " ('back hr days mins chat', 0.242535625036333),\n",
       " ('back forth recruiter regarding scheduling', 0.242535625036333),\n",
       " ('weeks get informed ont pass', 0.242535625036333),\n",
       " ('forth recruiter regarding scheduling followed', 0.242535625036333),\n",
       " ('emailphoneonsite hr slow extremely hard', 0.242535625036333),\n",
       " ('get contacted recruiter month phone', 0.242535625036333),\n",
       " ('approaches solving data science problems', 0.242535625036333),\n",
       " ('give take home project finished', 0.242535625036333),\n",
       " ('technical behavioral since questions openended', 0.242535625036333),\n",
       " ('applied referral get contacted recruiter', 0.242535625036333),\n",
       " ('two rounds one resume machine', 0.242535625036333),\n",
       " ('total techs behavior questions weeks', 0.242535625036333),\n",
       " ('techs behavior questions weeks get', 0.242535625036333),\n",
       " ('five full days choose result', 0.242535625036333),\n",
       " ('using google doc white board', 0.242535625036333),\n",
       " ('get back hr days mins', 0.242535625036333),\n",
       " ('gave slot thats availability list', 0.242535625036333),\n",
       " ('test communicate present idea clear', 0.242535625036333),\n",
       " ('gave five full days choose', 0.242535625036333),\n",
       " ('full days choose result gave', 0.242535625036333),\n",
       " ('friend get back hr days', 0.242535625036333),\n",
       " ('think really test communicate present', 0.242535625036333),\n",
       " ('teasers first round second round', 0.242535625036333),\n",
       " ('first round simple conceptual question', 0.242535625036333),\n",
       " ('solving data science problems lot', 0.242535625036333),\n",
       " ('via google call using google', 0.242535625036333),\n",
       " ('first asked introduce ask behavior', 0.242535625036333),\n",
       " ('week like project enter final', 0.242535625036333),\n",
       " ('followed phone screen senior data', 0.242535625036333),\n",
       " ('asked non normal distributions probabilities', 0.242535625036333),\n",
       " ('asked introduce ask behavior question', 0.242535625036333),\n",
       " ('asked implement machine learning algorithm', 0.242535625036333),\n",
       " ('virtual onsite day rounds total', 0.242535625036333),\n",
       " ('asked brain teasers first round', 0.242535625036333),\n",
       " ('take home project finished within', 0.242535625036333),\n",
       " ('asked availability phone interview gave', 0.242535625036333),\n",
       " ('engage whether even going direction', 0.242535625036333),\n",
       " ('google doc white board interview', 0.242535625036333),\n",
       " ('using pseudo code coding algorithm', 0.242535625036333),\n",
       " ('ask behavior question went resume', 0.242535625036333),\n",
       " ('first round second round asked', 0.242535625036333),\n",
       " ('google call using google doc', 0.242535625036333),\n",
       " ('mins chat regular questions experience', 0.242535625036333),\n",
       " ('present idea clear simple way', 0.242535625036333),\n",
       " ('doc white board interview questions', 0.242535625036333),\n",
       " ('phone screen virtual onsite day', 0.242535625036333),\n",
       " ('days choose result gave slot', 0.242535625036333),\n",
       " ('days mins chat regular questions', 0.242535625036333),\n",
       " ('fairly fast relatively non software', 0.242535625036333),\n",
       " ('introduce ask behavior question went', 0.242535625036333),\n",
       " ('probabilities process fairly fast relatively', 0.242535625036333),\n",
       " ('interviews technical behavioral since questions', 0.242535625036333),\n",
       " ('problems lot back forth recruiter', 0.242535625036333),\n",
       " ('process fairly fast relatively non', 0.242535625036333),\n",
       " ('choose result gave slot thats', 0.242535625036333),\n",
       " ('project enter final round interview', 0.242535625036333),\n",
       " ('project finished within week like', 0.242535625036333),\n",
       " ('projects background looks take communication', 0.242535625036333),\n",
       " ('pseudo code coding algorithm questions', 0.242535625036333),\n",
       " ('chat regular questions experience projects', 0.242535625036333),\n",
       " ('question second round consists interviews', 0.242535625036333),\n",
       " ('interviewer asked implement machine learning', 0.242535625036333),\n",
       " ('question went resume give take', 0.242535625036333),\n",
       " ('questionnaire regarding past projects approaches', 0.242535625036333),\n",
       " ('interview via google call using', 0.242535625036333),\n",
       " ('interview two rounds one resume', 0.242535625036333),\n",
       " ('questions difficult think really test', 0.242535625036333),\n",
       " ('day rounds total techs behavior', 0.242535625036333),\n",
       " ('phone screen senior data scientist', 0.242535625036333),\n",
       " ('questions interviewer asked implement machine', 0.242535625036333),\n",
       " ('phone interview gave five full', 0.242535625036333),\n",
       " ('month phone screen virtual onsite', 0.242535625036333),\n",
       " ('contacted recruiter month phone screen', 0.242535625036333),\n",
       " ('contact recruiter referred friend get', 0.242535625036333),\n",
       " ('consists interviews technical behavioral since', 0.242535625036333),\n",
       " ('machine learning questions interviewer asked', 0.242535625036333),\n",
       " ('machine learning algorithm using pseudo', 0.242535625036333),\n",
       " ('lot back forth recruiter regarding', 0.242535625036333),\n",
       " ('looks take communication first priority', 0.242535625036333),\n",
       " ('non normal distributions probabilities process', 0.242535625036333),\n",
       " ('non software technical exam coding', 0.242535625036333),\n",
       " ('normal distributions probabilities process fairly', 0.242535625036333),\n",
       " ('like project enter final round', 0.242535625036333),\n",
       " ('data science problems lot back', 0.242535625036333),\n",
       " ('conceptual question second round consists', 0.242535625036333),\n",
       " ('one resume machine learning questions', 0.242535625036333),\n",
       " ('onsite day rounds total techs', 0.242535625036333),\n",
       " ('learning questions interviewer asked implement', 0.242535625036333),\n",
       " ('learning algorithm using pseudo code', 0.242535625036333),\n",
       " ('openended hard engage whether even', 0.242535625036333),\n",
       " ('past projects approaches solving data', 0.242535625036333),\n",
       " ('communicate present idea clear simple', 0.242535625036333),\n",
       " ('questions experience projects background looks', 0.242535625036333),\n",
       " ('projects approaches solving data science', 0.242535625036333),\n",
       " ('regarding scheduling followed phone screen', 0.242535625036333),\n",
       " ('initial contact recruiter referred friend', 0.242535625036333),\n",
       " ('recruiter regarding scheduling followed phone', 0.242535625036333),\n",
       " ('difficult think really test communicate', 0.242535625036333),\n",
       " ('resume give take home project', 0.242535625036333),\n",
       " ('recruiter referred friend get back', 0.242535625036333),\n",
       " ('brain teasers first round second', 0.242535625036333),\n",
       " ('distributions probabilities process fairly fast', 0.242535625036333),\n",
       " ('regarding past projects approaches solving', 0.242535625036333),\n",
       " ('behavioral since questions openended hard', 0.242535625036333),\n",
       " ('resume machine learning questions interviewer', 0.242535625036333),\n",
       " ('result gave slot thats availability', 0.242535625036333),\n",
       " ('recruiter month phone screen virtual', 0.242535625036333),\n",
       " ('behavior questions weeks get informed', 0.242535625036333),\n",
       " ('interview gave five full days', 0.242535625036333),\n",
       " ('call using google doc white', 0.242535625036333),\n",
       " ('referral get contacted recruiter month', 0.242535625036333),\n",
       " ('behavior question went resume give', 0.242535625036333),\n",
       " ('round asked non normal distributions', 0.242535625036333),\n",
       " ('questions openended hard engage whether', 0.242535625036333),\n",
       " ('questions weeks get informed ont', 0.242535625036333),\n",
       " ('campus interview two rounds one', 0.242535625036333),\n",
       " ('regular questions experience projects background', 0.242535625036333),\n",
       " ('round consists interviews technical behavioral', 0.242535625036333),\n",
       " ('board interview questions difficult think', 0.242535625036333),\n",
       " ('referred friend get back hr', 0.242535625036333),\n",
       " ('interview questions difficult think really', 0.242535625036333),\n",
       " ('really test communicate present idea', 0.242535625036333),\n",
       " ('relatively non software technical exam', 0.242535625036333),\n",
       " ('video interview video interview asked', 0.23570226039551587),\n",
       " ('resume chat recruiter prescreen questionnaire', 0.23570226039551587),\n",
       " ('onsite people took mins sure', 0.23570226039551587),\n",
       " ('later next interview scheduled whole', 0.23570226039551587),\n",
       " ('video interview asked tech questions', 0.23570226039551587),\n",
       " ('relatively straightforward similar companies submit', 0.23570226039551587),\n",
       " ('scheduled whole process moved pretty', 0.23570226039551587),\n",
       " ('standard recruiter call phone tech', 0.23570226039551587),\n",
       " ('said would move next round', 0.23570226039551587),\n",
       " ('interview arranged video interview video', 0.23570226039551587),\n",
       " ('linked informal phone interview arranged', 0.23570226039551587),\n",
       " ('next round hiring manager weeks', 0.23570226039551587),\n",
       " ('weeks later next interview scheduled', 0.23570226039551587),\n",
       " ('next interview scheduled whole process', 0.23570226039551587),\n",
       " ('went smoothly didnt pass hiring', 0.23570226039551587),\n",
       " ('went wrong though thought went', 0.23570226039551587),\n",
       " ('whole process moved pretty slow', 0.23570226039551587),\n",
       " ('manager weeks later next interview', 0.23570226039551587),\n",
       " ('move next round hiring manager', 0.23570226039551587),\n",
       " ('would move next round hiring', 0.23570226039551587),\n",
       " ('mins sure went wrong though', 0.23570226039551587),\n",
       " ('wrong though thought went smoothly', 0.23570226039551587),\n",
       " ('looking phd student recruiter found', 0.23570226039551587),\n",
       " ('referral recruiter reached said would', 0.23570226039551587),\n",
       " ('past technical interview however process', 0.23570226039551587),\n",
       " ('process relatively straightforward similar companies', 0.23570226039551587),\n",
       " ('recruiter prescreen questionnaire technical interview',\n",
       "  0.23570226039551587),\n",
       " ('tech interview onsite people took', 0.23570226039551587),\n",
       " ('informal phone interview arranged video', 0.23570226039551587),\n",
       " ('recruiter found linked informal phone', 0.23570226039551587),\n",
       " ('recruiter call phone tech interview', 0.23570226039551587),\n",
       " ('quantitative analyst looking phd student', 0.23570226039551587),\n",
       " ('interview onsite people took mins', 0.23570226039551587),\n",
       " ('smoothly didnt pass hiring committee', 0.23570226039551587),\n",
       " ('sure went wrong though thought', 0.23570226039551587),\n",
       " ('questionnaire technical interview ds onsite', 0.23570226039551587),\n",
       " ('interview video interview asked tech', 0.23570226039551587),\n",
       " ('submit resume chat recruiter prescreen', 0.23570226039551587),\n",
       " ('reached said would move next', 0.23570226039551587),\n",
       " ('student recruiter found linked informal', 0.23570226039551587),\n",
       " ('straightforward similar companies submit resume', 0.23570226039551587),\n",
       " ('similar companies submit resume chat', 0.23570226039551587),\n",
       " ('technical interview ds onsite interview', 0.23570226039551587),\n",
       " ('people took mins sure went', 0.23570226039551587),\n",
       " ('technical interview however process relatively', 0.23570226039551587),\n",
       " ('phd student recruiter found linked', 0.23570226039551587),\n",
       " ('phone interview arranged video interview', 0.23570226039551587),\n",
       " ('took mins sure went wrong', 0.23570226039551587),\n",
       " ('interview scheduled whole process moved', 0.23570226039551587),\n",
       " ('thought went smoothly didnt pass', 0.23570226039551587),\n",
       " ('though thought went smoothly didnt', 0.23570226039551587),\n",
       " ('found linked informal phone interview', 0.23570226039551587),\n",
       " ('phone tech interview onsite people', 0.23570226039551587),\n",
       " ('however process relatively straightforward similar', 0.23570226039551587),\n",
       " ('prescreen questionnaire technical interview ds', 0.23570226039551587),\n",
       " ('job also called quantitative analyst', 0.23570226039551587),\n",
       " ('hiring manager weeks later next', 0.23570226039551587),\n",
       " ('interview however process relatively straightforward', 0.23570226039551587),\n",
       " ('recruiter reached said would move', 0.23570226039551587),\n",
       " ('process moved pretty slow dropped', 0.23570226039551587),\n",
       " ('round hiring manager weeks later', 0.23570226039551587),\n",
       " ('make past technical interview however', 0.23570226039551587),\n",
       " ('arranged video interview video interview', 0.23570226039551587),\n",
       " ('didnt make past technical interview', 0.23570226039551587),\n",
       " ('companies submit resume chat recruiter', 0.23570226039551587),\n",
       " ('called quantitative analyst looking phd', 0.23570226039551587),\n",
       " ('applied referral recruiter reached said', 0.23570226039551587),\n",
       " ('call phone tech interview onsite', 0.23570226039551587),\n",
       " ('analyst looking phd student recruiter', 0.23570226039551587),\n",
       " ('also called quantitative analyst looking', 0.23570226039551587),\n",
       " ('didnt pass hiring committee review', 0.23570226039551587),\n",
       " ('chat recruiter prescreen questionnaire technical', 0.23570226039551587),\n",
       " ('impress convince guys thorough fundamentals', 0.22941573387056183),\n",
       " ('round phone interviews followed onsite', 0.22941573387056183),\n",
       " ('push use loops dislike never', 0.22941573387056183),\n",
       " ('question asked think good hospitality', 0.22941573387056183),\n",
       " ('project manager informal used gauge', 0.22941573387056183),\n",
       " ('asked technical questions easy interview', 0.22941573387056183),\n",
       " ('challenging questions product seem like', 0.22941573387056183),\n",
       " ('challenges next came discussion project', 0.22941573387056183),\n",
       " ('questionnaire placement coding interview language', 0.22941573387056183),\n",
       " ('full day interview data scientists', 0.22941573387056183),\n",
       " ('full day make interview another', 0.22941573387056183),\n",
       " ('interviewer asked code google doc', 0.22941573387056183),\n",
       " ('designing system based available data', 0.22941573387056183),\n",
       " ('questions couple weeks later received', 0.22941573387056183),\n",
       " ('checked background asked technical questions', 0.22941573387056183),\n",
       " ('programming challenges next came discussion', 0.22941573387056183),\n",
       " ('test code test google document', 0.22941573387056183),\n",
       " ('technical questions live code test', 0.22941573387056183),\n",
       " ('code test code test google', 0.22941573387056183),\n",
       " ('good hospitality know right hired', 0.22941573387056183),\n",
       " ('interviews followed onsite interview interviewers', 0.22941573387056183),\n",
       " ('followed onsite interview interviewers challenging', 0.22941573387056183),\n",
       " ('three rounds technical interview designing', 0.22941573387056183),\n",
       " ('rounds technical interview designing system', 0.22941573387056183),\n",
       " ('straightforward programming challenges next came', 0.22941573387056183),\n",
       " ('basic concepts around probability regression', 0.22941573387056183),\n",
       " ('thorough fundamentals looking one research', 0.22941573387056183),\n",
       " ('code google doc focused basic', 0.22941573387056183),\n",
       " ('probability regression plus coding simulations', 0.22941573387056183),\n",
       " ('interviews asked basic questions like', 0.22941573387056183),\n",
       " ('think good hospitality know right', 0.22941573387056183),\n",
       " ('basic questions like live commute', 0.22941573387056183),\n",
       " ('choosing questions straightforward programming challenges',\n",
       "  0.22941573387056183),\n",
       " ('interviewers challenging questions product seem', 0.22941573387056183),\n",
       " ('asked code google doc focused', 0.22941573387056183),\n",
       " ('product seem like open questions', 0.22941573387056183),\n",
       " ('professionalism behavioral performance also gauged', 0.22941573387056183),\n",
       " ('fundamentals looking one research background', 0.22941573387056183),\n",
       " ('interview virtual interview included technical', 0.22941573387056183),\n",
       " ('gauge well interests skills match', 0.22941573387056183),\n",
       " ('interview language choosing questions straightforward',\n",
       "  0.22941573387056183),\n",
       " ('interview included technical questions live', 0.22941573387056183),\n",
       " ('interview hard impress convince guys', 0.22941573387056183),\n",
       " ('recruiter hour interview data scientist', 0.22941573387056183),\n",
       " ('around probability regression plus coding', 0.22941573387056183),\n",
       " ('system based available data professionalism', 0.22941573387056183),\n",
       " ('informal used gauge well interests', 0.22941573387056183),\n",
       " ('interview designing system based available', 0.22941573387056183),\n",
       " ('discussion project manager informal used', 0.22941573387056183),\n",
       " ('interview data scientists hr employee', 0.22941573387056183),\n",
       " ('regression plus coding simulations push', 0.22941573387056183),\n",
       " ('interview data scientist full day', 0.22941573387056183),\n",
       " ('essentials data science machine learning', 0.22941573387056183),\n",
       " ('dislike never set simulations way', 0.22941573387056183),\n",
       " ('go short interviews asked basic', 0.22941573387056183),\n",
       " ('behavioral performance also gauged essentials', 0.22941573387056183),\n",
       " ('research background masters guess require', 0.22941573387056183),\n",
       " ('doc focused basic concepts around', 0.22941573387056183),\n",
       " ('interview interviewers challenging questions product', 0.22941573387056183),\n",
       " ('received virtual interview virtual interview', 0.22941573387056183),\n",
       " ('gauged essentials data science machine', 0.22941573387056183),\n",
       " ('came discussion project manager informal', 0.22941573387056183),\n",
       " ('hr sent email technical questions', 0.22941573387056183),\n",
       " ('technical questions easy interview hard', 0.22941573387056183),\n",
       " ('technical questions couple weeks later', 0.22941573387056183),\n",
       " ('questions easy interview hard impress', 0.22941573387056183),\n",
       " ('questions fact correct answers must', 0.22941573387056183),\n",
       " ('technical phone screen checked background', 0.22941573387056183),\n",
       " ('interview super easy usually go', 0.22941573387056183),\n",
       " ('google doc focused basic concepts', 0.22941573387056183),\n",
       " ('questions like live commute availability', 0.22941573387056183),\n",
       " ('questions live code test code', 0.22941573387056183),\n",
       " ('interview recruiter hour interview data', 0.22941573387056183),\n",
       " ('asked basic questions like live', 0.22941573387056183),\n",
       " ('questions product seem like open', 0.22941573387056183),\n",
       " ('questions straightforward programming challenges next',\n",
       "  0.22941573387056183),\n",
       " ('included technical questions live code', 0.22941573387056183),\n",
       " ('technical interview designing system based', 0.22941573387056183),\n",
       " ('super easy usually go short', 0.22941573387056183),\n",
       " ('based available data professionalism behavioral', 0.22941573387056183),\n",
       " ('asked think good hospitality know', 0.22941573387056183),\n",
       " ('seem like open questions fact', 0.22941573387056183),\n",
       " ('virtual interview included technical questions', 0.22941573387056183),\n",
       " ('loops dislike never set simulations', 0.22941573387056183),\n",
       " ('alright interviewer asked code google', 0.22941573387056183),\n",
       " ('availability one question asked think', 0.22941573387056183),\n",
       " ('concepts around probability regression plus', 0.22941573387056183),\n",
       " ('looking one research background masters', 0.22941573387056183),\n",
       " ('also gauged essentials data science', 0.22941573387056183),\n",
       " ('virtual interview virtual interview included', 0.22941573387056183),\n",
       " ('live commute availability one question', 0.22941573387056183),\n",
       " ('one question asked think good', 0.22941573387056183),\n",
       " ('live code test code test', 0.22941573387056183),\n",
       " ('onsite interview interviewers challenging questions', 0.22941573387056183),\n",
       " ('available data professionalism behavioral performance',\n",
       "  0.22941573387056183),\n",
       " ('linkedin two round phone interviews', 0.22941573387056183),\n",
       " ('screening interview recruiter hour interview', 0.22941573387056183),\n",
       " ('open questions fact correct answers', 0.22941573387056183),\n",
       " ('data professionalism behavioral performance also', 0.22941573387056183),\n",
       " ('one research background masters guess', 0.22941573387056183),\n",
       " ('sent email technical questions couple', 0.22941573387056183),\n",
       " ('data science machine learning concepts', 0.22941573387056183),\n",
       " ('next came discussion project manager', 0.22941573387056183),\n",
       " ('mix one interviews full day', 0.22941573387056183),\n",
       " ('convince guys thorough fundamentals looking', 0.22941573387056183),\n",
       " ('fact correct answers must find', 0.22941573387056183),\n",
       " ('simulations push use loops dislike', 0.22941573387056183),\n",
       " ('guys thorough fundamentals looking one', 0.22941573387056183),\n",
       " ('employee mix one interviews full', 0.22941573387056183),\n",
       " ('short interviews asked basic questions', 0.22941573387056183),\n",
       " ('email technical questions couple weeks', 0.22941573387056183),\n",
       " ('one interviews full day make', 0.22941573387056183),\n",
       " ('couple weeks later received virtual', 0.22941573387056183),\n",
       " ('hard impress convince guys thorough', 0.22941573387056183),\n",
       " ('connected linkedin two round phone', 0.22941573387056183),\n",
       " ('manager informal used gauge well', 0.22941573387056183),\n",
       " ('started questionnaire placement coding interview', 0.22941573387056183),\n",
       " ('machine learning concepts reviewed questions', 0.22941573387056183),\n",
       " ('weeks later received virtual interview', 0.22941573387056183),\n",
       " ('usually go short interviews asked', 0.22941573387056183),\n",
       " ('interviews full day make interview', 0.22941573387056183),\n",
       " ('like open questions fact correct', 0.22941573387056183),\n",
       " ('hr employee mix one interviews', 0.22941573387056183),\n",
       " ('like live commute availability one', 0.22941573387056183),\n",
       " ('two round phone interviews followed', 0.22941573387056183),\n",
       " ('phone interviews followed onsite interview', 0.22941573387056183),\n",
       " ('data scientists hr employee mix', 0.22941573387056183),\n",
       " ('phone screen checked background asked', 0.22941573387056183),\n",
       " ('easy interview hard impress convince', 0.22941573387056183),\n",
       " ('hr connected linkedin two round', 0.22941573387056183),\n",
       " ('day interview data scientists hr', 0.22941573387056183),\n",
       " ('background asked technical questions easy', 0.22941573387056183),\n",
       " ('day make interview another day', 0.22941573387056183),\n",
       " ('coding interview language choosing questions', 0.22941573387056183),\n",
       " ('focused basic concepts around probability', 0.22941573387056183),\n",
       " ('placement coding interview language choosing', 0.22941573387056183),\n",
       " ('scientist full day interview data', 0.22941573387056183),\n",
       " ('plus coding simulations push use', 0.22941573387056183),\n",
       " ('science machine learning concepts reviewed', 0.22941573387056183),\n",
       " ('language choosing questions straightforward programming',\n",
       "  0.22941573387056183),\n",
       " ('coding simulations push use loops', 0.22941573387056183),\n",
       " ('learning concepts reviewed questions asked', 0.22941573387056183),\n",
       " ('data scientist full day interview', 0.22941573387056183),\n",
       " ('use loops dislike never set', 0.22941573387056183),\n",
       " ('commute availability one question asked', 0.22941573387056183),\n",
       " ('easy usually go short interviews', 0.22941573387056183),\n",
       " ('scientists hr employee mix one', 0.22941573387056183),\n",
       " ('screen checked background asked technical', 0.22941573387056183),\n",
       " ('hour interview data scientist full', 0.22941573387056183),\n",
       " ('later received virtual interview virtual', 0.22941573387056183),\n",
       " ('performance also gauged essentials data', 0.22941573387056183),\n",
       " ('used gauge well interests skills', 0.22941573387056183),\n",
       " ('recruiter first week short interview', 0.22941573387056174),\n",
       " ('talk product manager got phone', 0.22941573387056174),\n",
       " ('interview talking recruiter first week', 0.22941573387056174),\n",
       " ('talking recruiter first week short', 0.22941573387056174),\n",
       " ('nice talk product manager got', 0.22941573387056174),\n",
       " ('manager got phone interview talking', 0.22941573387056174),\n",
       " ('got phone interview talking recruiter', 0.22941573387056174),\n",
       " ('week short interview nice talk', 0.22941573387056174),\n",
       " ('product manager got phone interview', 0.22941573387056174),\n",
       " ('phone interview talking recruiter first', 0.22941573387056174),\n",
       " ('first week short interview nice', 0.22941573387056174),\n",
       " ('back onsite week overall quick', 0.223606797749979),\n",
       " ('employee referral intern position two', 0.223606797749979),\n",
       " ('screen interviewer listened previous experience', 0.223606797749979),\n",
       " ('interests min another tech interview', 0.223606797749979),\n",
       " ('screen onsite interview oneonone interviews', 0.223606797749979),\n",
       " ('hire latter personal wanted know', 0.223606797749979),\n",
       " ('hear unmuted didnt repeat might', 0.223606797749979),\n",
       " ('hr found linkedin scheduled informal', 0.223606797749979),\n",
       " ('background work interests min another', 0.223606797749979),\n",
       " ('informal phone talk talk background', 0.223606797749979),\n",
       " ('rounds interviews covering statistical coding', 0.223606797749979),\n",
       " ('series modeling behavior questions interviews', 0.223606797749979),\n",
       " ('behavior questions interviews minutes lunch', 0.223606797749979),\n",
       " ('inference product interpretation time series', 0.223606797749979),\n",
       " ('scheduled informal phone talk talk', 0.223606797749979),\n",
       " ('repeat might missed important bit', 0.223606797749979),\n",
       " ('intern position two video interviews', 0.223606797749979),\n",
       " ('phone screen interviewer listened previous', 0.223606797749979),\n",
       " ('last one team wanted hire', 0.223606797749979),\n",
       " ('latter personal wanted know research', 0.223606797749979),\n",
       " ('phone call recruiter technical phone', 0.223606797749979),\n",
       " ('personal wanted know research past', 0.223606797749979),\n",
       " ('pass tech interview position mountain', 0.223606797749979),\n",
       " ('overall quick decisions make interview', 0.223606797749979),\n",
       " ('overall pleasant five rounds interviews', 0.223606797749979),\n",
       " ('onsite week overall quick decisions', 0.223606797749979),\n",
       " ('onsite pass tech interview position', 0.223606797749979),\n",
       " ('linkedin scheduled informal phone talk', 0.223606797749979),\n",
       " ('onsite interview oneonone interviews lunch', 0.223606797749979),\n",
       " ('listened previous experience asked regression', 0.223606797749979),\n",
       " ('oneonone interviews lunch middle got', 0.223606797749979),\n",
       " ('one team wanted hire latter', 0.223606797749979),\n",
       " ('one purely technical last one', 0.223606797749979),\n",
       " ('lunch middle got back onsite', 0.223606797749979),\n",
       " ('make interview process clearly laid', 0.223606797749979),\n",
       " ('covering statistical coding probability statistical', 0.223606797749979),\n",
       " ('couldnt hear unmuted didnt repeat', 0.223606797749979),\n",
       " ('mute bit messaged couldnt hear', 0.223606797749979),\n",
       " ('messaged couldnt hear unmuted didnt', 0.223606797749979),\n",
       " ('middle got back onsite week', 0.223606797749979),\n",
       " ('might missed important bit info', 0.223606797749979),\n",
       " ('min another tech interview onsite', 0.223606797749979),\n",
       " ('modeling behavior questions interviews minutes', 0.223606797749979),\n",
       " ('coding probability statistical inference product', 0.223606797749979),\n",
       " ('phone screen onsite interview oneonone', 0.223606797749979),\n",
       " ('interpretation time series modeling behavior', 0.223606797749979),\n",
       " ('phone talk talk background work', 0.223606797749979),\n",
       " ('bit messaged couldnt hear unmuted', 0.223606797749979),\n",
       " ('regression question talking mute bit', 0.223606797749979),\n",
       " ('referral intern position two video', 0.223606797749979),\n",
       " ('recruiter technical phone screen onsite', 0.223606797749979),\n",
       " ('call recruiter technical phone screen', 0.223606797749979),\n",
       " ('interview oneonone interviews lunch middle', 0.223606797749979),\n",
       " ('interview onsite pass tech interview', 0.223606797749979),\n",
       " ('interview position mountain view hires', 0.223606797749979),\n",
       " ('quick decisions make interview process', 0.223606797749979),\n",
       " ...]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googleprocess_vectorizer = TfidfVectorizer(ngram_range=(5,5), min_df=0.001, max_df = 0.75)\n",
    "google_vectorized_process = pd.DataFrame(googleprocess_vectorizer.fit_transform(google_process_df['Process']).toarray(), columns = googleprocess_vectorizer.get_feature_names_out())\n",
    "google_vectorized_process.loc['Total'] = google_vectorized_process.sum(numeric_only=True, axis=0)\n",
    "google_vectorized_process = google_vectorized_process.sort_values(google_vectorized_process.last_valid_index(), axis=1, ascending=False)\n",
    "googleprocess_sorted_word_list = [(col, google_vectorized_process[col].iloc[-1]) for col in google_vectorized_process.columns]\n",
    "googleprocess_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft TFIDF Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('six seven interviews one hr', 0.6324555320336759),\n",
       " ('hr rest algodesign questions process', 0.6324555320336759),\n",
       " ('algodesign questions process organized well', 0.6324555320336759),\n",
       " ('seven interviews one hr rest', 0.6324555320336759),\n",
       " ('questions process organized well phase', 0.6324555320336759),\n",
       " ('organized well phase time prepare', 0.6324555320336759),\n",
       " ('process organized well phase time', 0.6324555320336759),\n",
       " ('one hr rest algodesign questions', 0.6324555320336759),\n",
       " ('rest algodesign questions process organized', 0.6324555320336759),\n",
       " ('interviews one hr rest algodesign', 0.6324555320336759),\n",
       " ('applied job ad linkedin recruiter', 0.6030226891555273),\n",
       " ('link test test almost hours', 0.6030226891555273),\n",
       " ('test almost hours pass test', 0.6030226891555273),\n",
       " ('almost hours pass test explain', 0.6030226891555273),\n",
       " ('recruiter contacted sent link test', 0.6030226891555273),\n",
       " ('contacted sent link test test', 0.6030226891555273),\n",
       " ('sent link test test almost', 0.6030226891555273),\n",
       " ('test test almost hours pass', 0.6030226891555273),\n",
       " ('ad linkedin recruiter contacted sent', 0.6030226891555273),\n",
       " ('linkedin recruiter contacted sent link', 0.6030226891555273),\n",
       " ('job ad linkedin recruiter contacted', 0.6030226891555273),\n",
       " ('communicated beforehand surprises interviewers friendly',\n",
       "  0.5773502691896257),\n",
       " ('science much say apart first', 0.5773502691896257),\n",
       " ('type questions would find cracking', 0.5773502691896257),\n",
       " ('part college recruitment process interviews', 0.5773502691896257),\n",
       " ('describe experiences interest data science', 0.5773502691896257),\n",
       " ('took month final rounds short', 0.5773502691896257),\n",
       " ('interest data science much say', 0.5773502691896257),\n",
       " ('experiences interest data science much', 0.5773502691896257),\n",
       " ('really enjoyed rounds looks team', 0.5773502691896257),\n",
       " ('interviews consisted rounds mostly type', 0.5773502691896257),\n",
       " ('team leader hour data science', 0.5773502691896257),\n",
       " ('recruitment process interviews consisted rounds', 0.5773502691896257),\n",
       " ('professional friendly welcoming schedule clearly', 0.5773502691896257),\n",
       " ('passionate work questions moderately difficult', 0.5773502691896257),\n",
       " ('interview team leader hour data', 0.5773502691896257),\n",
       " ('apart first round due diligence', 0.5773502691896257),\n",
       " ('final took month final rounds', 0.5773502691896257),\n",
       " ('interviewed part college recruitment process', 0.5773502691896257),\n",
       " ('process interviews consisted rounds mostly', 0.5773502691896257),\n",
       " ('clearly communicated beforehand surprises interviewers',\n",
       "  0.5773502691896257),\n",
       " ('short interviewers super nice really', 0.5773502691896257),\n",
       " ('beforehand surprises interviewers friendly truly', 0.5773502691896257),\n",
       " ('round due diligence ml algorithms', 0.5773502691896257),\n",
       " ('due diligence ml algorithms interest', 0.5773502691896257),\n",
       " ('friendly truly passionate work questions', 0.5773502691896257),\n",
       " ('friendly welcoming schedule clearly communicated', 0.5773502691896257),\n",
       " ('truly passionate work questions moderately', 0.5773502691896257),\n",
       " ('enjoyed rounds looks team specific', 0.5773502691896257),\n",
       " ('nice really enjoyed rounds looks', 0.5773502691896257),\n",
       " ('final rounds short interviewers super', 0.5773502691896257),\n",
       " ('screening hr interview phone interview', 0.5773502691896257),\n",
       " ('super nice really enjoyed rounds', 0.5773502691896257),\n",
       " ('diligence ml algorithms interest lie', 0.5773502691896257),\n",
       " ('surprises interviewers friendly truly passionate', 0.5773502691896257),\n",
       " ('consisted rounds mostly type questions', 0.5773502691896257),\n",
       " ('leader hour data science interview', 0.5773502691896257),\n",
       " ('welcoming schedule clearly communicated beforehand', 0.5773502691896257),\n",
       " ('interview interview higher manager hr', 0.5773502691896257),\n",
       " ('questions would find cracking coding', 0.5773502691896257),\n",
       " ('month final rounds short interviewers', 0.5773502691896257),\n",
       " ('rounds mostly type questions would', 0.5773502691896257),\n",
       " ('would find cracking coding interview', 0.5773502691896257),\n",
       " ('phone final took month final', 0.5773502691896257),\n",
       " ('hour data science interview interview', 0.5773502691896257),\n",
       " ('say apart first round due', 0.5773502691896257),\n",
       " ('college recruitment process interviews consisted', 0.5773502691896257),\n",
       " ('schedule clearly communicated beforehand surprises', 0.5773502691896257),\n",
       " ('data science interview interview higher', 0.5773502691896257),\n",
       " ('science interview interview higher manager', 0.5773502691896257),\n",
       " ('interviewers friendly truly passionate work', 0.5773502691896257),\n",
       " ('hr interview phone interview team', 0.5773502691896257),\n",
       " ('phone interview team leader hour', 0.5773502691896257),\n",
       " ('much say apart first round', 0.5773502691896257),\n",
       " ('first round due diligence ml', 0.5773502691896257),\n",
       " ('interviewers super nice really enjoyed', 0.5773502691896257),\n",
       " ('first screening hr interview phone', 0.5773502691896257),\n",
       " ('interview phone interview team leader', 0.5773502691896257),\n",
       " ('rounds short interviewers super nice', 0.5773502691896257),\n",
       " ('data science much say apart', 0.5773502691896257),\n",
       " ('mostly type questions would find', 0.5773502691896257),\n",
       " ('scores different types methods issues', 0.554700196225229),\n",
       " ('mcqs interview round related scores', 0.554700196225229),\n",
       " ('coding round pca along mcqs', 0.554700196225229),\n",
       " ('methods issues faced building model', 0.554700196225229),\n",
       " ('different types methods issues faced', 0.554700196225229),\n",
       " ('types methods issues faced building', 0.554700196225229),\n",
       " ('round pca along mcqs interview', 0.554700196225229),\n",
       " ('pca along mcqs interview round', 0.554700196225229),\n",
       " ('related scores different types methods', 0.554700196225229),\n",
       " ('round related scores different types', 0.554700196225229),\n",
       " ('one coding round pca along', 0.554700196225229),\n",
       " ('interview round related scores different', 0.554700196225229),\n",
       " ('along mcqs interview round related', 0.554700196225229),\n",
       " ('minimize residuals different statistical model', 0.5345224838248487),\n",
       " ('resume min technical questions min', 0.5345224838248487),\n",
       " ('ways minimize residuals different statistical', 0.5345224838248487),\n",
       " ('questions hours zoom meeting interviewer', 0.5345224838248487),\n",
       " ('members team unfortunately didnt receive', 0.5345224838248487),\n",
       " ('machine learning problem imbalaced classes', 0.5345224838248487),\n",
       " ('interviewer asks three technical questions', 0.5345224838248487),\n",
       " ('problem imbalaced classes resolved couple', 0.5345224838248487),\n",
       " ('hours zoom meeting interviewer asks', 0.5345224838248487),\n",
       " ('min coding technical questions including', 0.5345224838248487),\n",
       " ('microsoft teams four members team', 0.5345224838248487),\n",
       " ('four members team unfortunately didnt', 0.5345224838248487),\n",
       " ('classes resolved couple hour resolve', 0.5345224838248487),\n",
       " ('interviewd hiring event coding online', 0.5345224838248487),\n",
       " ('interviewd onsite microsoft teams four', 0.5345224838248487),\n",
       " ('hour resolve send back email', 0.5345224838248487),\n",
       " ('min go resume min technical', 0.5345224838248487),\n",
       " ('meeting interviewer asks three technical', 0.5345224838248487),\n",
       " ('min technical questions min coding', 0.5345224838248487),\n",
       " ('onsite microsoft teams four members', 0.5345224838248487),\n",
       " ('study building machine learning model', 0.5345224838248487),\n",
       " ('zoom meeting interviewer asks three', 0.5345224838248487),\n",
       " ('ask questions hours zoom meeting', 0.5345224838248487),\n",
       " ('email description data defines machine', 0.5345224838248487),\n",
       " ('go resume min technical questions', 0.5345224838248487),\n",
       " ('online assesment questions interviewd onsite', 0.5345224838248487),\n",
       " ('science ways minimize residuals different', 0.5345224838248487),\n",
       " ('couple hour resolve send back', 0.5345224838248487),\n",
       " ('technical questions data science ways', 0.5345224838248487),\n",
       " ('case study building machine learning', 0.5345224838248487),\n",
       " ('description data defines machine learning', 0.5345224838248487),\n",
       " ('building machine learning model scratch', 0.5345224838248487),\n",
       " ('event coding online assesment questions', 0.5345224838248487),\n",
       " ('technical questions min coding technical', 0.5345224838248487),\n",
       " ('hiring event coding online assesment', 0.5345224838248487),\n",
       " ('questions min coding technical questions', 0.5345224838248487),\n",
       " ('team unfortunately didnt receive offer', 0.5345224838248487),\n",
       " ('data defines machine learning problem', 0.5345224838248487),\n",
       " ('defines machine learning problem imbalaced', 0.5345224838248487),\n",
       " ('including case study building machine', 0.5345224838248487),\n",
       " ('teams four members team unfortunately', 0.5345224838248487),\n",
       " ('coding technical questions including case', 0.5345224838248487),\n",
       " ('assesment questions interviewd onsite microsoft', 0.5345224838248487),\n",
       " ('resolve send back email anwser', 0.5345224838248487),\n",
       " ('questions data science ways minimize', 0.5345224838248487),\n",
       " ('learning problem imbalaced classes resolved', 0.5345224838248487),\n",
       " ('coding online assesment questions interviewd', 0.5345224838248487),\n",
       " ('three technical questions data science', 0.5345224838248487),\n",
       " ('asks three technical questions data', 0.5345224838248487),\n",
       " ('technical questions including case study', 0.5345224838248487),\n",
       " ('recieve email description data defines', 0.5345224838248487),\n",
       " ('data science ways minimize residuals', 0.5345224838248487),\n",
       " ('questions including case study building', 0.5345224838248487),\n",
       " ('resolved couple hour resolve send', 0.5345224838248487),\n",
       " ('imbalaced classes resolved couple hour', 0.5345224838248487),\n",
       " ('questions interviewd onsite microsoft teams', 0.5345224838248487),\n",
       " ('final interviews team members nice', 0.5163977794943222),\n",
       " ('stats machine learning coding resume', 0.5163977794943222),\n",
       " ('members nice enjoy whole communication', 0.5163977794943222),\n",
       " ('rejected two days whole process', 0.5163977794943222),\n",
       " ('review hr rejected two days', 0.5163977794943222),\n",
       " ('video interviews including probability stats', 0.5163977794943222),\n",
       " ('interview process haphazard took months', 0.5163977794943222),\n",
       " ('questions asked answer conceptual questions', 0.5163977794943222),\n",
       " ('communication process hiring manager great', 0.5163977794943222),\n",
       " ('coding ml conceptual questions asked', 0.5163977794943222),\n",
       " ('interviews including probability stats machine', 0.5163977794943222),\n",
       " ('conceptual questions asked answer conceptual', 0.5163977794943222),\n",
       " ('interviews team members nice enjoy', 0.5163977794943222),\n",
       " ('took months hr disappearing months', 0.5163977794943222),\n",
       " ('coding resume review hr rejected', 0.5163977794943222),\n",
       " ('resume review hr rejected two', 0.5163977794943222),\n",
       " ('conducted rounds final interviews team', 0.5163977794943222),\n",
       " ('conceptual questions topics random forest', 0.5163977794943222),\n",
       " ('process haphazard took months hr', 0.5163977794943222),\n",
       " ('mainly asked machine learning questions', 0.5163977794943222),\n",
       " ('two days whole process quick', 0.5163977794943222),\n",
       " ('haphazard took months hr disappearing', 0.5163977794943222),\n",
       " ('including probability stats machine learning', 0.5163977794943222),\n",
       " ('including coding ml conceptual questions', 0.5163977794943222),\n",
       " ('ml conceptual questions asked answer', 0.5163977794943222),\n",
       " ('moved technical interview including coding', 0.5163977794943222),\n",
       " ('whole communication process hiring manager', 0.5163977794943222),\n",
       " ('months rounds round hr mainly', 0.5163977794943222),\n",
       " ('days whole process quick efficient', 0.5163977794943222),\n",
       " ('machine learning questions data science', 0.5163977794943222),\n",
       " ('rounds round hr mainly asked', 0.5163977794943222),\n",
       " ('machine learning coding resume review', 0.5163977794943222),\n",
       " ('rounds video interviews including probability', 0.5163977794943222),\n",
       " ('months hr disappearing months rounds', 0.5163977794943222),\n",
       " ('technical interview including coding ml', 0.5163977794943222),\n",
       " ('questions topics random forest xgboost', 0.5163977794943222),\n",
       " ('hr rejected two days whole', 0.5163977794943222),\n",
       " ('hr mainly asked machine learning', 0.5163977794943222),\n",
       " ('phone screening interviews conducted rounds', 0.5163977794943222),\n",
       " ('hr disappearing months rounds round', 0.5163977794943222),\n",
       " ('standard screening moved technical interview', 0.5163977794943222),\n",
       " ('interviews conducted rounds final interviews', 0.5163977794943222),\n",
       " ('answer conceptual questions topics random', 0.5163977794943222),\n",
       " ('asked answer conceptual questions topics', 0.5163977794943222),\n",
       " ('round hr mainly asked machine', 0.5163977794943222),\n",
       " ('probability stats machine learning coding', 0.5163977794943222),\n",
       " ('screening interviews conducted rounds final', 0.5163977794943222),\n",
       " ('initial phone screening interviews conducted', 0.5163977794943222),\n",
       " ('enjoy whole communication process hiring', 0.5163977794943222),\n",
       " ('learning coding resume review hr', 0.5163977794943222),\n",
       " ('learning questions data science questions', 0.5163977794943222),\n",
       " ('screening moved technical interview including', 0.5163977794943222),\n",
       " ('nice enjoy whole communication process', 0.5163977794943222),\n",
       " ('asked machine learning questions data', 0.5163977794943222),\n",
       " ('started standard screening moved technical', 0.5163977794943222),\n",
       " ('team members nice enjoy whole', 0.5163977794943222),\n",
       " ('smooth initial phone screening interviews', 0.5163977794943222),\n",
       " ('rounds final interviews team members', 0.5163977794943222),\n",
       " ('interview including coding ml conceptual', 0.5163977794943222),\n",
       " ('disappearing months rounds round hr', 0.5163977794943222),\n",
       " ('two teammates three management easy', 0.4999999999999999),\n",
       " ('question examples deal conflicts manager', 0.4999999999999999),\n",
       " ('interview team member technical interview', 0.4999999999999999),\n",
       " ('behavioural questions past experience two', 0.4999999999999999),\n",
       " ('sorting algorithms basic statistics questions', 0.4999999999999999),\n",
       " ('interview team member asked questions', 0.4999999999999999),\n",
       " ('experience two teammates three management', 0.4999999999999999),\n",
       " ('first interview hiring manager another', 0.4999999999999999),\n",
       " ('technical interview team member technical', 0.4999999999999999),\n",
       " ('two rounds lots behavioural questions', 0.4999999999999999),\n",
       " ('team member technical interview team', 0.4999999999999999),\n",
       " ('teammates three management easy pass', 0.4999999999999999),\n",
       " ('interview hiring manager another technical', 0.4999999999999999),\n",
       " ('asked questions sorting algorithms basic', 0.4999999999999999),\n",
       " ('management easy pass cultural fit', 0.4999999999999999),\n",
       " ('member asked questions sorting algorithms', 0.4999999999999999),\n",
       " ('questions past experience two teammates', 0.4999999999999999),\n",
       " ('three management easy pass cultural', 0.4999999999999999),\n",
       " ('member technical interview team member', 0.4999999999999999),\n",
       " ('manager another technical interview team', 0.4999999999999999),\n",
       " ('cultural fit question examples deal', 0.4999999999999999),\n",
       " ('past experience two teammates three', 0.4999999999999999),\n",
       " ('team member asked questions sorting', 0.4999999999999999),\n",
       " ('easy pass cultural fit question', 0.4999999999999999),\n",
       " ('rounds lots behavioural questions past', 0.4999999999999999),\n",
       " ('pass cultural fit question examples', 0.4999999999999999),\n",
       " ('fit question examples deal conflicts', 0.4999999999999999),\n",
       " ('hiring manager another technical interview', 0.4999999999999999),\n",
       " ('questions sorting algorithms basic statistics', 0.4999999999999999),\n",
       " ('technical interview team member asked', 0.4999999999999999),\n",
       " ('lots behavioural questions past experience', 0.4999999999999999),\n",
       " ('another technical interview team member', 0.4999999999999999),\n",
       " ('socializing candidates getting know company', 0.4850712500726659),\n",
       " ('case studies interviewer thorough appreciated', 0.4850712500726659),\n",
       " ('nice onsite interviewers well fun', 0.4850712500726659),\n",
       " ('remotely involved super day back', 0.4850712500726659),\n",
       " ('interviewer thorough appreciated concise answers', 0.4850712500726659),\n",
       " ('well fun socializing candidates getting', 0.4850712500726659),\n",
       " ('getting know company better overall', 0.4850712500726659),\n",
       " ('data science case studies interviewer', 0.4850712500726659),\n",
       " ('candidates getting know company better', 0.4850712500726659),\n",
       " ('held remotely involved super day', 0.4850712500726659),\n",
       " ('science case studies interviewer thorough', 0.4850712500726659),\n",
       " ('phone interview followed onsite interview', 0.4850712500726659),\n",
       " ('interviewers well fun socializing candidates', 0.4850712500726659),\n",
       " ('day back back data science', 0.4850712500726659),\n",
       " ('microsoft interview held remotely involved', 0.4850712500726659),\n",
       " ('interview recruiter super nice onsite', 0.4850712500726659),\n",
       " ('interview held remotely involved super', 0.4850712500726659),\n",
       " ('thorough appreciated concise answers nice', 0.4850712500726659),\n",
       " ('back data science case studies', 0.4850712500726659),\n",
       " ('back back data science case', 0.4850712500726659),\n",
       " ('involved super day back back', 0.4850712500726659),\n",
       " ('followed onsite interview recruiter super', 0.4850712500726659),\n",
       " ('company better overall great experience', 0.4850712500726659),\n",
       " ('studies interviewer thorough appreciated concise', 0.4850712500726659),\n",
       " ('know company better overall great', 0.4850712500726659),\n",
       " ('concise answers nice company culture', 0.4850712500726659),\n",
       " ('onsite interview recruiter super nice', 0.4850712500726659),\n",
       " ('super nice onsite interviewers well', 0.4850712500726659),\n",
       " ('onsite interviewers well fun socializing', 0.4850712500726659),\n",
       " ('recruiter super nice onsite interviewers', 0.4850712500726659),\n",
       " ('appreciated concise answers nice company', 0.4850712500726659),\n",
       " ('super day back back data', 0.4850712500726659),\n",
       " ('fun socializing candidates getting know', 0.4850712500726659),\n",
       " ('interview followed onsite interview recruiter', 0.4850712500726659),\n",
       " ('covered following topics relevant background', 0.4714045207910316),\n",
       " ('last practice lead interviewers calm', 0.4714045207910316),\n",
       " ('questions basic ml data science', 0.4714045207910316),\n",
       " ('invitation fullday interview rounds indepth', 0.4714045207910316),\n",
       " ('lead interviewers calm interacts great', 0.4714045207910316),\n",
       " ('questions areas algorithms machine learning', 0.4714045207910316),\n",
       " ('calm interacts great learning experience', 0.4714045207910316),\n",
       " ('connection two rounds got intern', 0.4714045207910316),\n",
       " ('job description work dynamics reasons', 0.4714045207910316),\n",
       " ('energy vms connection two rounds', 0.4714045207910316),\n",
       " ('talked vm information research also', 0.4714045207910316),\n",
       " ('data science got invitation fullday', 0.4714045207910316),\n",
       " ('ml data science got invitation', 0.4714045207910316),\n",
       " ('core concepts four rounds first', 0.4714045207910316),\n",
       " ('dynamics reasons want work microsoft', 0.4714045207910316),\n",
       " ('concepts four rounds first two', 0.4714045207910316),\n",
       " ('manager last practice lead interviewers', 0.4714045207910316),\n",
       " ('third hiring manager last practice', 0.4714045207910316),\n",
       " ('started round behavioral preliminary questions', 0.4714045207910316),\n",
       " ('interviews based around core concepts', 0.4714045207910316),\n",
       " ('topics relevant background job description', 0.4714045207910316),\n",
       " ('relevant background job description work', 0.4714045207910316),\n",
       " ('conducted hebrew covered following topics', 0.4714045207910316),\n",
       " ('technical third hiring manager last', 0.4714045207910316),\n",
       " ('minutes interview conducted hebrew covered', 0.4714045207910316),\n",
       " ('two rounds got intern offer', 0.4714045207910316),\n",
       " ('description work dynamics reasons want', 0.4714045207910316),\n",
       " ('things energy vms connection two', 0.4714045207910316),\n",
       " ('research also asked things energy', 0.4714045207910316),\n",
       " ('two rounds talked vm information', 0.4714045207910316),\n",
       " ('around core concepts four rounds', 0.4714045207910316),\n",
       " ('rounds indepth questions areas algorithms', 0.4714045207910316),\n",
       " ('rounds got intern offer researchori', 0.4714045207910316),\n",
       " ('information research also asked things', 0.4714045207910316),\n",
       " ('rounds first two technical third', 0.4714045207910316),\n",
       " ('behavioral preliminary questions basic ml', 0.4714045207910316),\n",
       " ('got invitation fullday interview rounds', 0.4714045207910316),\n",
       " ('intern offer researchori intern maybe', 0.4714045207910316),\n",
       " ('interview approximately minutes interview conducted', 0.4714045207910316),\n",
       " ('basic ml data science got', 0.4714045207910316),\n",
       " ('approximately minutes interview conducted hebrew', 0.4714045207910316),\n",
       " ('offer researchori intern maybe general', 0.4714045207910316),\n",
       " ('areas algorithms machine learning system', 0.4714045207910316),\n",
       " ('interview rounds indepth questions areas', 0.4714045207910316),\n",
       " ('indepth questions areas algorithms machine', 0.4714045207910316),\n",
       " ('interview conducted hebrew covered following', 0.4714045207910316),\n",
       " ('based around core concepts four', 0.4714045207910316),\n",
       " ('fullday interview rounds indepth questions', 0.4714045207910316),\n",
       " ('screening interview approximately minutes interview', 0.4714045207910316),\n",
       " ('first phone screening interview approximately', 0.4714045207910316),\n",
       " ('background job description work dynamics', 0.4714045207910316),\n",
       " ('four rounds first two technical', 0.4714045207910316),\n",
       " ('asked things energy vms connection', 0.4714045207910316),\n",
       " ('vms connection two rounds got', 0.4714045207910316),\n",
       " ('following topics relevant background job', 0.4714045207910316),\n",
       " ('round behavioral preliminary questions basic', 0.4714045207910316),\n",
       " ('first two technical third hiring', 0.4714045207910316),\n",
       " ('researchori intern maybe general process', 0.4714045207910316),\n",
       " ('got intern offer researchori intern', 0.4714045207910316),\n",
       " ('vm information research also asked', 0.4714045207910316),\n",
       " ('hebrew covered following topics relevant', 0.4714045207910316),\n",
       " ('algorithms machine learning system design', 0.4714045207910316),\n",
       " ('rounds talked vm information research', 0.4714045207910316),\n",
       " ('science got invitation fullday interview', 0.4714045207910316),\n",
       " ('interviewers calm interacts great learning', 0.4714045207910316),\n",
       " ('hiring manager last practice lead', 0.4714045207910316),\n",
       " ('also asked things energy vms', 0.4714045207910316),\n",
       " ('practice lead interviewers calm interacts', 0.4714045207910316),\n",
       " ('work dynamics reasons want work', 0.4714045207910316),\n",
       " ('phone screening interview approximately minutes', 0.4714045207910316),\n",
       " ('two technical third hiring manager', 0.4714045207910316),\n",
       " ('preliminary questions basic ml data', 0.4714045207910316),\n",
       " ('hour interviewer presents dataset csv', 0.44721359549995787),\n",
       " ('studies previous projects based sql', 0.44721359549995787),\n",
       " ('select build feature time interval', 0.44721359549995787),\n",
       " ('consisted day data insights test', 0.44721359549995787),\n",
       " ('interview data scientist microsoft background', 0.44721359549995787),\n",
       " ('huge db choose preferred language', 0.44721359549995787),\n",
       " ('ask feature engineering model selection', 0.44721359549995787),\n",
       " ('technical data science related questions', 0.44721359549995787),\n",
       " ('problem solve demystify specific insights', 0.44721359549995787),\n",
       " ('dataset csv format ask feature', 0.44721359549995787),\n",
       " ('wrangle data didnt specify problem', 0.44721359549995787),\n",
       " ('day pure technical data science', 0.44721359549995787),\n",
       " ('data scientist microsoft background check', 0.44721359549995787),\n",
       " ('process consisted day data insights', 0.44721359549995787),\n",
       " ('language wrangle data didnt specify', 0.44721359549995787),\n",
       " ('lasts hour interviewer presents dataset', 0.44721359549995787),\n",
       " ('process feature select build feature', 0.44721359549995787),\n",
       " ('technical question final round consists', 0.44721359549995787),\n",
       " ('round consists interviews minutes covers', 0.44721359549995787),\n",
       " ('interview internship position interview lasts', 0.44721359549995787),\n",
       " ('interview lasts hour interviewer presents', 0.44721359549995787),\n",
       " ('format ask feature engineering model', 0.44721359549995787),\n",
       " ('day data insights test given', 0.44721359549995787),\n",
       " ('data insights test given huge', 0.44721359549995787),\n",
       " ('consists interviews minutes covers topic', 0.44721359549995787),\n",
       " ('selection process feature select build', 0.44721359549995787),\n",
       " ('data didnt specify problem solve', 0.44721359549995787),\n",
       " ('technical questions role related discussion', 0.44721359549995787),\n",
       " ('demystify specific insights could underline', 0.44721359549995787),\n",
       " ('science related questions like based', 0.44721359549995787),\n",
       " ('presents dataset csv format ask', 0.44721359549995787),\n",
       " ('like coding questions case studies', 0.44721359549995787),\n",
       " ('csv format ask feature engineering', 0.44721359549995787),\n",
       " ('preferred language wrangle data didnt', 0.44721359549995787),\n",
       " ('covers topic like coding questions', 0.44721359549995787),\n",
       " ('like based case studies previous', 0.44721359549995787),\n",
       " ('rounds day pure technical data', 0.44721359549995787),\n",
       " ('round technical questions role related', 0.44721359549995787),\n",
       " ('data science related questions like', 0.44721359549995787),\n",
       " ('insights test given huge db', 0.44721359549995787),\n",
       " ('questions like based case studies', 0.44721359549995787),\n",
       " ('previous projects based sql hiring', 0.44721359549995787),\n",
       " ('test given huge db choose', 0.44721359549995787),\n",
       " ('manager round technical questions role', 0.44721359549995787),\n",
       " ('didnt specify problem solve demystify', 0.44721359549995787),\n",
       " ('internship position interview lasts hour', 0.44721359549995787),\n",
       " ('hiring manager round technical questions', 0.44721359549995787),\n",
       " ('db choose preferred language wrangle', 0.44721359549995787),\n",
       " ('round minutes interview data scientist', 0.44721359549995787),\n",
       " ('position interview lasts hour interviewer', 0.44721359549995787),\n",
       " ('given huge db choose preferred', 0.44721359549995787),\n",
       " ('scientist microsoft background check technical', 0.44721359549995787),\n",
       " ('minutes interview data scientist microsoft', 0.44721359549995787),\n",
       " ('coding questions case studies stats', 0.44721359549995787),\n",
       " ('minutes covers topic like coding', 0.44721359549995787),\n",
       " ('interviewer presents dataset csv format', 0.44721359549995787),\n",
       " ('case studies previous projects based', 0.44721359549995787),\n",
       " ('interviews minutes covers topic like', 0.44721359549995787),\n",
       " ('based sql hiring manager round', 0.44721359549995787),\n",
       " ('choose preferred language wrangle data', 0.44721359549995787),\n",
       " ('build feature time interval use', 0.44721359549995787),\n",
       " ('background check technical question final', 0.44721359549995787),\n",
       " ('solve demystify specific insights could', 0.44721359549995787),\n",
       " ('st round minutes interview data', 0.44721359549995787),\n",
       " ('related questions like based case', 0.44721359549995787),\n",
       " ('final round consists interviews minutes', 0.44721359549995787),\n",
       " ('projects based sql hiring manager', 0.44721359549995787),\n",
       " ('feature engineering model selection process', 0.44721359549995787),\n",
       " ('pure technical data science related', 0.44721359549995787),\n",
       " ('microsoft background check technical question', 0.44721359549995787),\n",
       " ('feature select build feature time', 0.44721359549995787),\n",
       " ('based case studies previous projects', 0.44721359549995787),\n",
       " ('engineering model selection process feature', 0.44721359549995787),\n",
       " ('model selection process feature select', 0.44721359549995787),\n",
       " ('sql hiring manager round technical', 0.44721359549995787),\n",
       " ('specify problem solve demystify specific', 0.44721359549995787),\n",
       " ('interview process consisted day data', 0.44721359549995787),\n",
       " ('check technical question final round', 0.44721359549995787),\n",
       " ('topic like coding questions case', 0.44721359549995787),\n",
       " ('question final round consists interviews', 0.44721359549995787),\n",
       " ('behavioral interview coding interviews questions', 0.43643578047198467),\n",
       " ('feedback remote contractor position relatively', 0.43643578047198467),\n",
       " ('response feedback remote contractor position', 0.43643578047198467),\n",
       " ('coding interviews questions leet code', 0.43643578047198467),\n",
       " ('code easymedium overall good interview', 0.43643578047198467),\n",
       " ('interview coding interviews questions leet', 0.43643578047198467),\n",
       " ('interviews questions leet code easymedium', 0.43643578047198467),\n",
       " ('contractor position relatively easier onsite', 0.43643578047198467),\n",
       " ('roughly behavioral interview coding interviews', 0.43643578047198467),\n",
       " ('interview process quick response feedback', 0.43643578047198467),\n",
       " ('months roughly behavioral interview coding', 0.43643578047198467),\n",
       " ('easymedium overall good interview process', 0.43643578047198467),\n",
       " ('two months roughly behavioral interview', 0.43643578047198467),\n",
       " ('questions leet code easymedium overall', 0.43643578047198467),\n",
       " ('process quick response feedback remote', 0.43643578047198467),\n",
       " ('consisted two months roughly behavioral', 0.43643578047198467),\n",
       " ('remote contractor position relatively easier', 0.43643578047198467),\n",
       " ('good interview process quick response', 0.43643578047198467),\n",
       " ('leet code easymedium overall good', 0.43643578047198467),\n",
       " ('quick response feedback remote contractor', 0.43643578047198467),\n",
       " ('overall good interview process quick', 0.43643578047198467),\n",
       " ('round second round personal interview', 0.42640143271122083),\n",
       " ('manager week starts managers introduction', 0.42640143271122083),\n",
       " ('team hiring manager week starts', 0.42640143271122083),\n",
       " ('test coding questions python related', 0.42640143271122083),\n",
       " ('interview using ms team hiring', 0.42640143271122083),\n",
       " ('week starts managers introduction intro', 0.42640143271122083),\n",
       " ('choice questions machine learning time', 0.42640143271122083),\n",
       " ('request scheduled hr video interview', 0.42640143271122083),\n",
       " ('hr video interview using ms', 0.42640143271122083),\n",
       " ('hrs people selected interview round', 0.42640143271122083),\n",
       " ('ms team hiring manager week', 0.42640143271122083),\n",
       " ('questions python related natural language', 0.42640143271122083),\n",
       " ('multiple choice questions machine learning', 0.42640143271122083),\n",
       " ('python related natural language processing', 0.42640143271122083),\n",
       " ('hiring manager week starts managers', 0.42640143271122083),\n",
       " ('scheduled hr video interview using', 0.42640143271122083),\n",
       " ('machine learning time hrs people', 0.42640143271122083),\n",
       " ('natural language processing multiple choice', 0.42640143271122083),\n",
       " ('info explanation process coding using', 0.42640143271122083),\n",
       " ('learning time hrs people selected', 0.42640143271122083),\n",
       " ('explanation process coding using codilitycom', 0.42640143271122083),\n",
       " ('questions machine learning time hrs', 0.42640143271122083),\n",
       " ('people selected interview round second', 0.42640143271122083),\n",
       " ('initial email request scheduled hr', 0.42640143271122083),\n",
       " ('starts managers introduction intro info', 0.42640143271122083),\n",
       " ('language processing multiple choice questions', 0.42640143271122083),\n",
       " ('selected interview round second round', 0.42640143271122083),\n",
       " ('intro info explanation process coding', 0.42640143271122083),\n",
       " ('using ms team hiring manager', 0.42640143271122083),\n",
       " ('using codilitycom rdrrio online platforms', 0.42640143271122083),\n",
       " ('process coding using codilitycom rdrrio', 0.42640143271122083),\n",
       " ('email request scheduled hr video', 0.42640143271122083),\n",
       " ('related natural language processing multiple', 0.42640143271122083),\n",
       " ('round online test coding questions', 0.42640143271122083),\n",
       " ('coding using codilitycom rdrrio online', 0.42640143271122083),\n",
       " ('processing multiple choice questions machine', 0.42640143271122083),\n",
       " ('managers introduction intro info explanation', 0.42640143271122083),\n",
       " ('time hrs people selected interview', 0.42640143271122083),\n",
       " ('online test coding questions python', 0.42640143271122083),\n",
       " ('first round online test coding', 0.42640143271122083),\n",
       " ('introduction intro info explanation process', 0.42640143271122083),\n",
       " ('video interview using ms team', 0.42640143271122083),\n",
       " ('interview round second round personal', 0.42640143271122083),\n",
       " ('coding questions python related natural', 0.42640143271122083),\n",
       " ('bem justo com job description', 0.4082482904638629),\n",
       " ('bem voltadas pela experiencia que', 0.4082482904638629),\n",
       " ('considerei bem justo com job', 0.4082482904638629),\n",
       " ('seu curriculo sao normalmente entrevistas', 0.4082482904638629),\n",
       " ('curriculo sao normalmente entrevistas tecnicas', 0.4082482904638629),\n",
       " ('descreve em seu curriculo sao', 0.4082482904638629),\n",
       " ('entrevistas tecnicas uma seguida da', 0.4082482904638629),\n",
       " ('experiencia que voce descreve em', 0.4082482904638629),\n",
       " ('perguntas sao bem voltadas pela', 0.4082482904638629),\n",
       " ('voce descreve em seu curriculo', 0.4082482904638629),\n",
       " ('tecnicas uma seguida da outra', 0.4082482904638629),\n",
       " ('voltadas pela experiencia que voce', 0.4082482904638629),\n",
       " ('description perguntas sao bem voltadas', 0.4082482904638629),\n",
       " ('com job description perguntas sao', 0.4082482904638629),\n",
       " ('pela experiencia que voce descreve', 0.4082482904638629),\n",
       " ('job description perguntas sao bem', 0.4082482904638629),\n",
       " ('sao bem voltadas pela experiencia', 0.4082482904638629),\n",
       " ('sao normalmente entrevistas tecnicas uma', 0.4082482904638629),\n",
       " ('em seu curriculo sao normalmente', 0.4082482904638629),\n",
       " ('normalmente entrevistas tecnicas uma seguida', 0.4082482904638629),\n",
       " ('em geral considerei bem justo', 0.4082482904638629),\n",
       " ('justo com job description perguntas', 0.4082482904638629),\n",
       " ('que voce descreve em seu', 0.4082482904638629),\n",
       " ('geral considerei bem justo com', 0.4082482904638629),\n",
       " ('followed managerialbehavioral followed technical interviewers',\n",
       "  0.3999999999999999),\n",
       " ('interviewers friendly th round canceled', 0.3999999999999999),\n",
       " ('technical interviewers friendly th round', 0.3999999999999999),\n",
       " ('hiring team rejected asked feedback', 0.3999999999999999),\n",
       " ('canceled reason got call hiring', 0.3999999999999999),\n",
       " ('call hiring team rejected asked', 0.3999999999999999),\n",
       " ('followed technical interviewers friendly th', 0.3999999999999999),\n",
       " ('scheduled first technical round followed', 0.3999999999999999),\n",
       " ('thought interviews went well didnt', 0.3999999999999999),\n",
       " ('first technical round followed managerialbehavioral', 0.3999999999999999),\n",
       " ('reason got call hiring team', 0.3999999999999999),\n",
       " ('round followed managerialbehavioral followed technical',\n",
       "  0.3999999999999999),\n",
       " ('rejected asked feedback thought interviews', 0.3999999999999999),\n",
       " ('technical round followed managerialbehavioral followed',\n",
       "  0.3999999999999999),\n",
       " ('team rejected asked feedback thought', 0.3999999999999999),\n",
       " ('round canceled reason got call', 0.3999999999999999),\n",
       " ('interviews scheduled first technical round', 0.3999999999999999),\n",
       " ('feedback thought interviews went well', 0.3999999999999999),\n",
       " ('interviews went well didnt receive', 0.3999999999999999),\n",
       " ('friendly th round canceled reason', 0.3999999999999999),\n",
       " ('asked feedback thought interviews went', 0.3999999999999999),\n",
       " ('th round canceled reason got', 0.3999999999999999),\n",
       " ('got call hiring team rejected', 0.3999999999999999),\n",
       " ('managerialbehavioral followed technical interviewers friendly',\n",
       "  0.3999999999999999),\n",
       " ('rounds interviews scheduled first technical', 0.3999999999999999),\n",
       " ('platform muted coding described thoughts', 0.3922322702763679),\n",
       " ('first bfs barpartite problem confirmed', 0.3922322702763679),\n",
       " ('round technical coding mixed behavioural', 0.3922322702763679),\n",
       " ('interview asked experience let code', 0.3922322702763679),\n",
       " ('realized interviewers somehow professional mostly', 0.3922322702763679),\n",
       " ('let code another platform muted', 0.3922322702763679),\n",
       " ('intern one boss gave interview', 0.3922322702763679),\n",
       " ('finished reviewed code gave positive', 0.3922322702763679),\n",
       " ('start coding finished reviewed code', 0.3922322702763679),\n",
       " ('followed round technical coding mixed', 0.3922322702763679),\n",
       " ('designed api start coding finished', 0.3922322702763679),\n",
       " ('screening followed round technical coding', 0.3922322702763679),\n",
       " ('gave interview asked experience let', 0.3922322702763679),\n",
       " ('somehow professional mostly jut trying', 0.3922322702763679),\n",
       " ('jut trying pass time like', 0.3922322702763679),\n",
       " ('described thoughts first bfs barpartite', 0.3922322702763679),\n",
       " ('team started phone screening followed', 0.3922322702763679),\n",
       " ('technical coding mixed behavioural questions', 0.3922322702763679),\n",
       " ('recruiting team started phone screening', 0.3922322702763679),\n",
       " ('interviewers somehow professional mostly jut', 0.3922322702763679),\n",
       " ('started phone screening followed round', 0.3922322702763679),\n",
       " ('experience let code another platform', 0.3922322702763679),\n",
       " ('reviewed code gave positive feedback', 0.3922322702763679),\n",
       " ('however realized interviewers somehow professional', 0.3922322702763679),\n",
       " ('thoughts first bfs barpartite problem', 0.3922322702763679),\n",
       " ('behavioural questions overally bad however', 0.3922322702763679),\n",
       " ('contacted microsoft recruiting team started', 0.3922322702763679),\n",
       " ('api start coding finished reviewed', 0.3922322702763679),\n",
       " ('muted coding described thoughts first', 0.3922322702763679),\n",
       " ('boss gave interview asked experience', 0.3922322702763679),\n",
       " ('pass time like already made', 0.3922322702763679),\n",
       " ('bfs barpartite problem confirmed designed', 0.3922322702763679),\n",
       " ('overally bad however realized interviewers', 0.3922322702763679),\n",
       " ('mostly jut trying pass time', 0.3922322702763679),\n",
       " ('barpartite problem confirmed designed api', 0.3922322702763679),\n",
       " ('problem confirmed designed api start', 0.3922322702763679),\n",
       " ('bad however realized interviewers somehow', 0.3922322702763679),\n",
       " ('asked experience let code another', 0.3922322702763679),\n",
       " ('one boss gave interview asked', 0.3922322702763679),\n",
       " ('questions overally bad however realized', 0.3922322702763679),\n",
       " ('professional mostly jut trying pass', 0.3922322702763679),\n",
       " ('another platform muted coding described', 0.3922322702763679),\n",
       " ('microsoft recruiting team started phone', 0.3922322702763679),\n",
       " ('mixed behavioural questions overally bad', 0.3922322702763679),\n",
       " ('trying pass time like already', 0.3922322702763679),\n",
       " ('code another platform muted coding', 0.3922322702763679),\n",
       " ('time like already made decision', 0.3922322702763679),\n",
       " ('coding described thoughts first bfs', 0.3922322702763679),\n",
       " ('phone screening followed round technical', 0.3922322702763679),\n",
       " ('coding mixed behavioural questions overally', 0.3922322702763679),\n",
       " ('coding finished reviewed code gave', 0.3922322702763679),\n",
       " ('confirmed designed api start coding', 0.3922322702763679),\n",
       " ('core feild think alot expertise', 0.3849001794597504),\n",
       " ('communication skills technical skills prepared', 0.3849001794597504),\n",
       " ('manage questios answerits difficult question', 0.3849001794597504),\n",
       " ('interview process thinks matter like', 0.3849001794597504),\n",
       " ('crack alli think must prepared', 0.3849001794597504),\n",
       " ('difficult manage questios answerits difficult', 0.3849001794597504),\n",
       " ('thinks matter like communication skills', 0.3849001794597504),\n",
       " ('think must prepared aspects give', 0.3849001794597504),\n",
       " ('question core feild think alot', 0.3849001794597504),\n",
       " ('expertise required crack alli think', 0.3849001794597504),\n",
       " ('skills technical skills prepared aspects', 0.3849001794597504),\n",
       " ('think alot expertise required crack', 0.3849001794597504),\n",
       " ('matter like communication skills technical', 0.3849001794597504),\n",
       " ('must prepared aspects give ln', 0.3849001794597504),\n",
       " ('difficult question core feild think', 0.3849001794597504),\n",
       " ('required crack alli think must', 0.3849001794597504),\n",
       " ('like communication skills technical skills', 0.3849001794597504),\n",
       " ('feild think alot expertise required', 0.3849001794597504),\n",
       " ('alli think must prepared aspects', 0.3849001794597504),\n",
       " ('give ln interview process thinks', 0.3849001794597504),\n",
       " ('aspects give ln interview process', 0.3849001794597504),\n",
       " ('alot expertise required crack alli', 0.3849001794597504),\n",
       " ('process thinks matter like communication', 0.3849001794597504),\n",
       " ('prepared aspects give ln interview', 0.3849001794597504),\n",
       " ('ln interview process thinks matter', 0.3849001794597504),\n",
       " ('questios answerits difficult question core', 0.3849001794597504),\n",
       " ('answerits difficult question core feild', 0.3849001794597504),\n",
       " ('programming call con coach aziendale', 0.3779644730092271),\n",
       " ('algoritmi data structures specialmente teoriche', 0.3779644730092271),\n",
       " ('alla fine cè un po', 0.3779644730092271),\n",
       " ('principali su algoritmi data structures', 0.3779644730092271),\n",
       " ('coach aziendale domande principali su', 0.3779644730092271),\n",
       " ('call con coach aziendale domande', 0.3779644730092271),\n",
       " ('lunga intervistatore tutto sommato cordiale', 0.3779644730092271),\n",
       " ('con coach aziendale domande principali', 0.3779644730092271),\n",
       " ('sommato cordiale molto puntiglioso alla', 0.3779644730092271),\n",
       " ('molto puntiglioso alla fine cè', 0.3779644730092271),\n",
       " ('specialmente teoriche abbastanza accademiche durata', 0.3779644730092271),\n",
       " ('live programming call con coach', 0.3779644730092271),\n",
       " ('tutto sommato cordiale molto puntiglioso', 0.3779644730092271),\n",
       " ('puntiglioso alla fine cè un', 0.3779644730092271),\n",
       " ('data structures specialmente teoriche abbastanza', 0.3779644730092271),\n",
       " ('cordiale molto puntiglioso alla fine', 0.3779644730092271),\n",
       " ('abbastanza lunga intervistatore tutto sommato', 0.3779644730092271),\n",
       " ('accademiche durata abbastanza lunga intervistatore', 0.3779644730092271),\n",
       " ('teoriche abbastanza accademiche durata abbastanza', 0.3779644730092271),\n",
       " ('domande principali su algoritmi data', 0.3779644730092271),\n",
       " ('su algoritmi data structures specialmente', 0.3779644730092271),\n",
       " ('abbastanza accademiche durata abbastanza lunga', 0.3779644730092271),\n",
       " ('structures specialmente teoriche abbastanza accademiche',\n",
       "  0.3779644730092271),\n",
       " ('fine cè un po di', 0.3779644730092271),\n",
       " ('intervistatore tutto sommato cordiale molto', 0.3779644730092271),\n",
       " ('aziendale domande principali su algoritmi', 0.3779644730092271),\n",
       " ('cè un po di feedback', 0.3779644730092271),\n",
       " ('durata abbastanza lunga intervistatore tutto', 0.3779644730092271),\n",
       " ('stat question coding requires lots', 0.3535533905932737),\n",
       " ('dont undetstand calculate stat question', 0.3535533905932737),\n",
       " ('questions stat question coding requires', 0.3535533905932737),\n",
       " ('question even though explain whole', 0.3535533905932737),\n",
       " ('stat question even though explain', 0.3535533905932737),\n",
       " ('though passes test dont undetstand', 0.3535533905932737),\n",
       " ('comments finished questions still said', 0.3535533905932737),\n",
       " ('though explain whole reasons behind', 0.3535533905932737),\n",
       " ('still said theres bug code', 0.3535533905932737),\n",
       " ('code even though passes test', 0.3535533905932737),\n",
       " ('coding requires lots comments finished', 0.3535533905932737),\n",
       " ('questions still said theres bug', 0.3535533905932737),\n",
       " ('lots comments finished questions still', 0.3535533905932737),\n",
       " ('said theres bug code even', 0.3535533905932737),\n",
       " ('even though explain whole reasons', 0.3535533905932737),\n",
       " ('wrangling questions stat question coding', 0.3535533905932737),\n",
       " ('whole reasons behind calculation vague', 0.3535533905932737),\n",
       " ('data wrangling questions stat question', 0.3535533905932737),\n",
       " ('even though passes test dont', 0.3535533905932737),\n",
       " ('bug code even though passes', 0.3535533905932737),\n",
       " ('firstround includes data wrangling questions', 0.3535533905932737),\n",
       " ('finished questions still said theres', 0.3535533905932737),\n",
       " ('includes data wrangling questions stat', 0.3535533905932737),\n",
       " ('undetstand calculate stat question even', 0.3535533905932737),\n",
       " ('explain whole reasons behind calculation', 0.3535533905932737),\n",
       " ('reasons behind calculation vague feedback', 0.3535533905932737),\n",
       " ('test dont undetstand calculate stat', 0.3535533905932737),\n",
       " ('theres bug code even though', 0.3535533905932737),\n",
       " ('passes test dont undetstand calculate', 0.3535533905932737),\n",
       " ('calculate stat question even though', 0.3535533905932737),\n",
       " ('question coding requires lots comments', 0.3535533905932737),\n",
       " ('requires lots comments finished questions', 0.3535533905932737),\n",
       " ('waiting response many open ended', 0.3481553119113956),\n",
       " ('time waiting response many open', 0.3481553119113956),\n",
       " ('interview share page coding hear', 0.3481553119113956),\n",
       " ('get results image searching bing', 0.3481553119113956),\n",
       " ('open ended questions get results', 0.3481553119113956),\n",
       " ('smooth process long time waiting', 0.3481553119113956),\n",
       " ('process long time waiting response', 0.3481553119113956),\n",
       " ('interview technical coding interview one', 0.3481553119113956),\n",
       " ('one day interview technical coding', 0.3481553119113956),\n",
       " ('back acceptance rejecting overlly smooth', 0.3481553119113956),\n",
       " ('interview one manager interview share', 0.3481553119113956),\n",
       " ('online recruiter emailed one day', 0.3481553119113956),\n",
       " ('emailed one day interview technical', 0.3481553119113956),\n",
       " ('acceptance rejecting overlly smooth process', 0.3481553119113956),\n",
       " ('coding interview one manager interview', 0.3481553119113956),\n",
       " ('coding hear back acceptance rejecting', 0.3481553119113956),\n",
       " ('share page coding hear back', 0.3481553119113956),\n",
       " ('one manager interview share page', 0.3481553119113956),\n",
       " ('rejecting overlly smooth process long', 0.3481553119113956),\n",
       " ('ended questions get results image', 0.3481553119113956),\n",
       " ('results image searching bing better', 0.3481553119113956),\n",
       " ('response many open ended questions', 0.3481553119113956),\n",
       " ('overlly smooth process long time', 0.3481553119113956),\n",
       " ('page coding hear back acceptance', 0.3481553119113956),\n",
       " ('applied online recruiter emailed one', 0.3481553119113956),\n",
       " ('hear back acceptance rejecting overlly', 0.3481553119113956),\n",
       " ('long time waiting response many', 0.3481553119113956),\n",
       " ('many open ended questions get', 0.3481553119113956),\n",
       " ('recruiter emailed one day interview', 0.3481553119113956),\n",
       " ('technical coding interview one manager', 0.3481553119113956),\n",
       " ('day interview technical coding interview', 0.3481553119113956),\n",
       " ('questions get results image searching', 0.3481553119113956),\n",
       " ('manager interview share page coding', 0.3481553119113956),\n",
       " ('site site rounds discussed projects', 0.316227766016838),\n",
       " ('data scientists currently working microsoft', 0.316227766016838),\n",
       " ('round data scientists currently working', 0.316227766016838),\n",
       " ('projects projects sites round data', 0.316227766016838),\n",
       " ('projects sites round data scientists', 0.316227766016838),\n",
       " ('rounds discussed projects projects sites', 0.316227766016838),\n",
       " ('site rounds discussed projects projects', 0.316227766016838),\n",
       " ('discussed projects projects sites round', 0.316227766016838),\n",
       " ('sites round data scientists currently', 0.316227766016838),\n",
       " ('phone site site rounds discussed', 0.316227766016838),\n",
       " ('numpy pandas behavior questions leadership', 0.3015113445777637),\n",
       " ('meeting microsoft one data scientist', 0.3015113445777637),\n",
       " ('interview person supposed ask different', 0.3015113445777637),\n",
       " ('different questions people nice try', 0.3015113445777637),\n",
       " ('crawler knowledges numpy pandas behavior', 0.3015113445777637),\n",
       " ('telephone conversation minutes meeting microsoft', 0.3015113445777637),\n",
       " ('two interviewers rude arrogant one', 0.3015113445777637),\n",
       " ('first round interview employee microsoft', 0.3015113445777637),\n",
       " ('supposed ask different questions people', 0.3015113445777637),\n",
       " ('one data scientist interview sure', 0.3015113445777637),\n",
       " ('interview sure good questions dont', 0.3015113445777637),\n",
       " ('sure good questions dont accepted', 0.3015113445777637),\n",
       " ('sql interview went smoothly interviewer', 0.3015113445777637),\n",
       " ('interviewer proud microsoft nd everything', 0.3015113445777637),\n",
       " ('behavioral technical questions sql interview', 0.3015113445777637),\n",
       " ('nd everything thought good thing', 0.3015113445777637),\n",
       " ('unresponsive two interviewers rude arrogant', 0.3015113445777637),\n",
       " ('minutes meeting microsoft one data', 0.3015113445777637),\n",
       " ('min first round interview employee', 0.3015113445777637),\n",
       " ('proud microsoft nd everything thought', 0.3015113445777637),\n",
       " ('several questions data structure web', 0.3015113445777637),\n",
       " ('technical questions sql interview went', 0.3015113445777637),\n",
       " ('interview went smoothly interviewer nice', 0.3015113445777637),\n",
       " ('push whatever reach far possible', 0.3015113445777637),\n",
       " ('try push whatever reach far', 0.3015113445777637),\n",
       " ('behavior questions leadership cooperation interviewers',\n",
       "  0.3015113445777637),\n",
       " ('conversation minutes meeting microsoft one', 0.3015113445777637),\n",
       " ('nice try push whatever reach', 0.3015113445777637),\n",
       " ('short telephone conversation minutes meeting', 0.3015113445777637),\n",
       " ('one interviewer proud microsoft nd', 0.3015113445777637),\n",
       " ('questions sql interview went smoothly', 0.3015113445777637),\n",
       " ('arrogant one interviewer proud microsoft', 0.3015113445777637),\n",
       " ('rude arrogant one interviewer proud', 0.3015113445777637),\n",
       " ('recruiters unresponsive two interviewers rude', 0.3015113445777637),\n",
       " ('data structure web crawler knowledges', 0.3015113445777637),\n",
       " ('structure web crawler knowledges numpy', 0.3015113445777637),\n",
       " ('person supposed ask different questions', 0.3015113445777637),\n",
       " ('questions data structure web crawler', 0.3015113445777637),\n",
       " ('rounds interview person supposed ask', 0.3015113445777637),\n",
       " ('data scientist interview sure good', 0.3015113445777637),\n",
       " ('people nice try push whatever', 0.3015113445777637),\n",
       " ('scientist interview sure good questions', 0.3015113445777637),\n",
       " ('pandas behavior questions leadership cooperation', 0.3015113445777637),\n",
       " ('microsoft behavioral technical questions sql', 0.3015113445777637),\n",
       " ('round interview employee microsoft behavioral', 0.3015113445777637),\n",
       " ('interviewers rude arrogant one interviewer', 0.3015113445777637),\n",
       " ('web crawler knowledges numpy pandas', 0.3015113445777637),\n",
       " ('knowledges numpy pandas behavior questions', 0.3015113445777637),\n",
       " ('employee microsoft behavioral technical questions', 0.3015113445777637),\n",
       " ('ask different questions people nice', 0.3015113445777637),\n",
       " ('questions people nice try push', 0.3015113445777637),\n",
       " ('interview employee microsoft behavioral technical', 0.3015113445777637),\n",
       " ('asked several questions data structure', 0.3015113445777637),\n",
       " ('microsoft nd everything thought good', 0.3015113445777637),\n",
       " ('microsoft one data scientist interview', 0.3015113445777637),\n",
       " ('un case study con presentación', 0.291729982995789),\n",
       " ('tanto en contenido técnico como', 0.291729982995789),\n",
       " ('técnico como en valores habilidades', 0.291729982995789),\n",
       " ('técnicas entrevista con el manager', 0.291729982995789),\n",
       " ('al team discusión del argumento', 0.291729982995789),\n",
       " ('contenido técnico como en valores', 0.291729982995789),\n",
       " ('yo project manager con presentación', 0.291729982995789),\n",
       " ('project manager con presentación evaluación', 0.291729982995789),\n",
       " ('manager yo project manager con', 0.291729982995789),\n",
       " ('muy completa tanto en contenido', 0.291729982995789),\n",
       " ('valores habilidades dos fases la', 0.291729982995789),\n",
       " ('preguntas técnicas entrevista con el', 0.291729982995789),\n",
       " ('presentación de minutos al team', 0.291729982995789),\n",
       " ('una elaboración de un case', 0.291729982995789),\n",
       " ('team discusión del argumento bastantes', 0.291729982995789),\n",
       " ('habilidades dos fases la primera', 0.291729982995789),\n",
       " ('con presentación de minutos al', 0.291729982995789),\n",
       " ('fases la primera consiste en', 0.291729982995789),\n",
       " ('presentación evaluación de aspectos más', 0.291729982995789),\n",
       " ('aspectos más humanos de experiencia', 0.291729982995789),\n",
       " ('bastantes preguntas técnicas entrevista con', 0.291729982995789),\n",
       " ('manager con presentación evaluación de', 0.291729982995789),\n",
       " ('primera consiste en una elaboración', 0.291729982995789),\n",
       " ('de aspectos más humanos de', 0.291729982995789),\n",
       " ('de minutos al team discusión', 0.291729982995789),\n",
       " ('de un case study con', 0.291729982995789),\n",
       " ('argumento bastantes preguntas técnicas entrevista', 0.291729982995789),\n",
       " ('del argumento bastantes preguntas técnicas', 0.291729982995789),\n",
       " ('con presentación evaluación de aspectos', 0.291729982995789),\n",
       " ('consiste en una elaboración de', 0.291729982995789),\n",
       " ('en contenido técnico como en', 0.291729982995789),\n",
       " ('dos fases la primera consiste', 0.291729982995789),\n",
       " ('entrevista con el manager yo', 0.291729982995789),\n",
       " ('evaluación de aspectos más humanos', 0.291729982995789),\n",
       " ('entrevista muy completa tanto en', 0.291729982995789),\n",
       " ('el manager yo project manager', 0.291729982995789),\n",
       " ('la primera consiste en una', 0.291729982995789),\n",
       " ('completa tanto en contenido técnico', 0.291729982995789),\n",
       " ('minutos al team discusión del', 0.291729982995789),\n",
       " ('case study con presentación de', 0.291729982995789),\n",
       " ('study con presentación de minutos', 0.291729982995789),\n",
       " ('como en valores habilidades dos', 0.291729982995789),\n",
       " ('en una elaboración de un', 0.291729982995789),\n",
       " ('en valores habilidades dos fases', 0.291729982995789),\n",
       " ('elaboración de un case study', 0.291729982995789),\n",
       " ('con el manager yo project', 0.291729982995789),\n",
       " ('discusión del argumento bastantes preguntas', 0.291729982995789),\n",
       " ('background projects algorithm models nice', 0.2886751345948129),\n",
       " ('rounds interviews first rounds made', 0.2886751345948129),\n",
       " ('interview interviewer late attitude poor', 0.2886751345948129),\n",
       " ('rounds round hour four different', 0.2886751345948129),\n",
       " ('time finished mins response believe', 0.2886751345948129),\n",
       " ('last round interview interviewer late', 0.2886751345948129),\n",
       " ('round interview interviewer late attitude', 0.2886751345948129),\n",
       " ('applied online referred friend mins', 0.2886751345948129),\n",
       " ('late attitude poor interviews technical', 0.2886751345948129),\n",
       " ('online referred friend mins interview', 0.2886751345948129),\n",
       " ('interview called mins later expected', 0.2886751345948129),\n",
       " ('mins later expected time finished', 0.2886751345948129),\n",
       " ('read funny thing need raise', 0.2886751345948129),\n",
       " ('mins interview called mins later', 0.2886751345948129),\n",
       " ('punctual however read funny thing', 0.2886751345948129),\n",
       " ('attitude poor interviews technical problems', 0.2886751345948129),\n",
       " ('interviews first rounds made sense', 0.2886751345948129),\n",
       " ('rounds made sense last round', 0.2886751345948129),\n",
       " ('first rounds made sense last', 0.2886751345948129),\n",
       " ('quite punctual however read funny', 0.2886751345948129),\n",
       " ('turn ask background projects algorithm', 0.2886751345948129),\n",
       " ('interview campus rounds round hour', 0.2886751345948129),\n",
       " ('interviewer late attitude poor interviews', 0.2886751345948129),\n",
       " ('thing need raise bar interview', 0.2886751345948129),\n",
       " ('however read funny thing need', 0.2886751345948129),\n",
       " ('people quite punctual however read', 0.2886751345948129),\n",
       " ('different people turn ask background', 0.2886751345948129),\n",
       " ('campus rounds round hour four', 0.2886751345948129),\n",
       " ('called mins later expected time', 0.2886751345948129),\n",
       " ('round hour four different people', 0.2886751345948129),\n",
       " ('raise bar interview process difficult', 0.2886751345948129),\n",
       " ('friend mins interview called mins', 0.2886751345948129),\n",
       " ('made sense last round interview', 0.2886751345948129),\n",
       " ('recruiters people quite punctual however', 0.2886751345948129),\n",
       " ('expected time finished mins response', 0.2886751345948129),\n",
       " ('organized recruiters people quite punctual', 0.2886751345948129),\n",
       " ('ask background projects algorithm models', 0.2886751345948129),\n",
       " ('sense last round interview interviewer', 0.2886751345948129),\n",
       " ('people turn ask background projects', 0.2886751345948129),\n",
       " ('hour four different people turn', 0.2886751345948129),\n",
       " ('finished mins response believe failed', 0.2886751345948129),\n",
       " ('four different people turn ask', 0.2886751345948129),\n",
       " ('need raise bar interview process', 0.2886751345948129),\n",
       " ('receive interview campus rounds round', 0.2886751345948129),\n",
       " ('later expected time finished mins', 0.2886751345948129),\n",
       " ('well organized recruiters people quite', 0.2886751345948129),\n",
       " ('referred friend mins interview called', 0.2886751345948129),\n",
       " ('funny thing need raise bar', 0.2886751345948129),\n",
       " ('efficient distributed manner length interview', 0.2773500981126146),\n",
       " ('engineer focus overall process good', 0.2773500981126146),\n",
       " ('interview results whole process fast', 0.2773500981126146),\n",
       " ('good never get follow interview', 0.2773500981126146),\n",
       " ('application video interview asked personally', 0.2773500981126146),\n",
       " ('statistics knowledge invited technical interview', 0.2773500981126146),\n",
       " ('going hire data scientist whole', 0.2773500981126146),\n",
       " ('background technical coding question involved', 0.2773500981126146),\n",
       " ('passed th interview well get', 0.2773500981126146),\n",
       " ('scientist whole process engineer focus', 0.2773500981126146),\n",
       " ('involved sorting array efficient distributed', 0.2773500981126146),\n",
       " ('statistics fact didnt know difference', 0.2773500981126146),\n",
       " ('first phone interview english another', 0.2773500981126146),\n",
       " ('test basic probability statistics knowledge', 0.2773500981126146),\n",
       " ('technical coding question involved sorting', 0.2773500981126146),\n",
       " ('knowledge statistics fact didnt know', 0.2773500981126146),\n",
       " ('optional interview easy passed th', 0.2773500981126146),\n",
       " ('interview easy passed th interview', 0.2773500981126146),\n",
       " ('asked deal noise meant error', 0.2773500981126146),\n",
       " ('interview english another phone interview', 0.2773500981126146),\n",
       " ('interview group manager another technical', 0.2773500981126146),\n",
       " ('coding question involved sorting array', 0.2773500981126146),\n",
       " ('process engineer focus overall process', 0.2773500981126146),\n",
       " ('quick smooth got interview online', 0.2773500981126146),\n",
       " ('asked personally based questions long', 0.2773500981126146),\n",
       " ('process good never get follow', 0.2773500981126146),\n",
       " ('interview included brief questions background', 0.2773500981126146),\n",
       " ('questions background technical coding question', 0.2773500981126146),\n",
       " ('array efficient distributed manner length', 0.2773500981126146),\n",
       " ('overall process good never get', 0.2773500981126146),\n",
       " ('outcome interview used skype video', 0.2773500981126146),\n",
       " ('probability statistics knowledge invited technical', 0.2773500981126146),\n",
       " ('get offer since enough experience', 0.2773500981126146),\n",
       " ('online test basic probability statistics', 0.2773500981126146),\n",
       " ('manager another technical interview results', 0.2773500981126146),\n",
       " ('distributed manner length interview hour', 0.2773500981126146),\n",
       " ('microsoft quick smooth got interview', 0.2773500981126146),\n",
       " ('overall conversation microsoft quick smooth', 0.2773500981126146),\n",
       " ('video interview asked personally based', 0.2773500981126146),\n",
       " ('focus overall process good never', 0.2773500981126146),\n",
       " ('interview online test basic probability', 0.2773500981126146),\n",
       " ('interview asked personally based questions', 0.2773500981126146),\n",
       " ('got interview online test basic', 0.2773500981126146),\n",
       " ('knowledge invited technical interview analyst', 0.2773500981126146),\n",
       " ('hire data scientist whole process', 0.2773500981126146),\n",
       " ('team going hire data scientist', 0.2773500981126146),\n",
       " ('interview well get offer since', 0.2773500981126146),\n",
       " ('developer didnt knowledge statistics fact', 0.2773500981126146),\n",
       " ('phone interview english another phone', 0.2773500981126146),\n",
       " ('enough experience impressed interview performance', 0.2773500981126146),\n",
       " ('included brief questions background technical', 0.2773500981126146),\n",
       " ('results whole process fast good', 0.2773500981126146),\n",
       " ('phone interview group manager another', 0.2773500981126146),\n",
       " ('noise error asked deal noise', 0.2773500981126146),\n",
       " ('software developer didnt knowledge statistics', 0.2773500981126146),\n",
       " ('conversation microsoft quick smooth got', 0.2773500981126146),\n",
       " ('whole process engineer focus overall', 0.2773500981126146),\n",
       " ('data scientist whole process engineer', 0.2773500981126146),\n",
       " ('since enough experience impressed interview', 0.2773500981126146),\n",
       " ('didnt know difference noise error', 0.2773500981126146),\n",
       " ('fact didnt know difference noise', 0.2773500981126146),\n",
       " ('technical interview results whole process', 0.2773500981126146),\n",
       " ('brief questions background technical coding', 0.2773500981126146),\n",
       " ('interviewer software developer didnt knowledge', 0.2773500981126146),\n",
       " ('didnt knowledge statistics fact didnt', 0.2773500981126146),\n",
       " ('interviews another optional interview easy', 0.2773500981126146),\n",
       " ('error asked deal noise meant', 0.2773500981126146),\n",
       " ('th interview well get offer', 0.2773500981126146),\n",
       " ('personally based questions long period', 0.2773500981126146),\n",
       " ('difference noise error asked deal', 0.2773500981126146),\n",
       " ('long period received update outcome', 0.2773500981126146),\n",
       " ('period received update outcome interview', 0.2773500981126146),\n",
       " ('engineer team going hire data', 0.2773500981126146),\n",
       " ('based questions long period received', 0.2773500981126146),\n",
       " ('another technical interview results whole', 0.2773500981126146),\n",
       " ('questions long period received update', 0.2773500981126146),\n",
       " ('another phone interview group manager', 0.2773500981126146),\n",
       " ('group manager another technical interview', 0.2773500981126146),\n",
       " ('another optional interview easy passed', 0.2773500981126146),\n",
       " ('know difference noise error asked', 0.2773500981126146),\n",
       " ('offer since enough experience impressed', 0.2773500981126146),\n",
       " ('update outcome interview used skype', 0.2773500981126146),\n",
       " ('sorting array efficient distributed manner', 0.2773500981126146),\n",
       " ('smooth got interview online test', 0.2773500981126146),\n",
       " ('question involved sorting array efficient', 0.2773500981126146),\n",
       " ('received update outcome interview used', 0.2773500981126146),\n",
       " ('well get offer since enough', 0.2773500981126146),\n",
       " ('basic probability statistics knowledge invited', 0.2773500981126146),\n",
       " ('english another phone interview group', 0.2773500981126146),\n",
       " ('easy passed th interview well', 0.2773500981126146),\n",
       " ('interview used skype video interview', 0.2773500981126146),\n",
       " ('actual knowledge area feedback given', 0.26726124191242445),\n",
       " ('round im sure get second', 0.26726124191242445),\n",
       " ('ask basic background deep learning', 0.26726124191242445),\n",
       " ('would last several hours finished', 0.26726124191242445),\n",
       " ('technical interviews well nontechnical ones', 0.26726124191242445),\n",
       " ('phone screen might onsite interview', 0.26726124191242445),\n",
       " ('long talk ask basic background', 0.26726124191242445),\n",
       " ('member team well several management', 0.26726124191242445),\n",
       " ('hours finished first round im', 0.26726124191242445),\n",
       " ('point feel like interviewer interested', 0.26726124191242445),\n",
       " ('long interviews included technical interviews', 0.26726124191242445),\n",
       " ('machine learning well several behavior', 0.26726124191242445),\n",
       " ('knowledge area feedback given even', 0.26726124191242445),\n",
       " ('phone interview mainly resume asked', 0.26726124191242445),\n",
       " ('screen might onsite interview would', 0.26726124191242445),\n",
       " ('interviews well nontechnical ones met', 0.26726124191242445),\n",
       " ('round phone interview mainly resume', 0.26726124191242445),\n",
       " ('interested terminology actual knowledge area', 0.26726124191242445),\n",
       " ('easy second one listed overall', 0.26726124191242445),\n",
       " ('round onsite interview back back', 0.26726124191242445),\n",
       " ('well nontechnical ones met almost', 0.26726124191242445),\n",
       " ('listed overall felt good decided', 0.26726124191242445),\n",
       " ('well point feel like interviewer', 0.26726124191242445),\n",
       " ('overall felt good decided proceed', 0.26726124191242445),\n",
       " ('included technical interviews well nontechnical', 0.26726124191242445),\n",
       " ('interview back back algorithm interviews', 0.26726124191242445),\n",
       " ('probability questions first one easy', 0.26726124191242445),\n",
       " ('given even didnt get position', 0.26726124191242445),\n",
       " ('met almost every member team', 0.26726124191242445),\n",
       " ('area feedback given even didnt', 0.26726124191242445),\n",
       " ('almost every member team well', 0.26726124191242445),\n",
       " ('im sure get second round', 0.26726124191242445),\n",
       " ('hr call minutes long talk', 0.26726124191242445),\n",
       " ('phone interview interviewer asked two', 0.26726124191242445),\n",
       " ('onsite interview back back algorithm', 0.26726124191242445),\n",
       " ...]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microsoftprocess_vectorizer = TfidfVectorizer(ngram_range=(5,5), min_df=0.001, max_df = 0.75)\n",
    "microsoft_vectorized_process = pd.DataFrame(microsoftprocess_vectorizer.fit_transform(microsoft_process_df['Process']).toarray(), columns = microsoftprocess_vectorizer.get_feature_names_out())\n",
    "microsoft_vectorized_process.loc['Total'] = microsoft_vectorized_process.sum(numeric_only=True, axis=0)\n",
    "microsoft_vectorized_process = microsoft_vectorized_process.sort_values(microsoft_vectorized_process.last_valid_index(), axis=1, ascending=False)\n",
    "microsoftprocess_sorted_word_list = [(col, microsoft_vectorized_process[col].iloc[-1]) for col in microsoft_vectorized_process.columns]\n",
    "microsoftprocess_sorted_word_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon TFIDF Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blah blah blah blah blah', 0.7302967433402215),\n",
       " ('take home assignment one interview', 0.7071067811865476),\n",
       " ('questions full day onsite interviews', 0.3691861432497283),\n",
       " ('interview take home assignment one', 0.3535533905932738),\n",
       " ('assignment one interview take home', 0.3535533905932738),\n",
       " ('one interview take home assignment', 0.3535533905932738),\n",
       " ('home assignment one interview take', 0.3535533905932738),\n",
       " ('fill code question ask technology', 0.3333333333333333),\n",
       " ('person nice sde ask fill', 0.3333333333333333),\n",
       " ('question ask technology never used', 0.3333333333333333),\n",
       " ('interview hard person nice sde', 0.3333333333333333),\n",
       " ('sde ask fill code question', 0.3333333333333333),\n",
       " ('hard person nice sde ask', 0.3333333333333333),\n",
       " ('ask fill code question ask', 0.3333333333333333),\n",
       " ('code question ask technology never', 0.3333333333333333),\n",
       " ('nice sde ask fill code', 0.3333333333333333),\n",
       " ('interview via campus placements nice', 0.31622776601683794),\n",
       " ('via campus placements nice experience', 0.31622776601683794),\n",
       " ('got selected interview via campus', 0.31622776601683794),\n",
       " ('campus placements nice experience interviewers', 0.31622776601683794),\n",
       " ('experience interviewers friendly supportive overall', 0.31622776601683794),\n",
       " ('placements nice experience interviewers friendly', 0.31622776601683794),\n",
       " ('nice experience interviewers friendly supportive', 0.31622776601683794),\n",
       " ('friendly supportive overall nice experience', 0.31622776601683794),\n",
       " ('selected interview via campus placements', 0.31622776601683794),\n",
       " ('interviewers friendly supportive overall nice', 0.31622776601683794),\n",
       " ('questions well seems better candidates', 0.30151134457776363),\n",
       " ('hard opinion think answered questions', 0.30151134457776363),\n",
       " ('phone screening sr data scientist', 0.30151134457776363),\n",
       " ('seems better candidates rejected eventually', 0.30151134457776363),\n",
       " ('scientist pass invite group interview', 0.30151134457776363),\n",
       " ('phone screening recruiter technical phone', 0.30151134457776363),\n",
       " ('interview mostly technical much hard', 0.30151134457776363),\n",
       " ('opinion think answered questions well', 0.30151134457776363),\n",
       " ('much hard opinion think answered', 0.30151134457776363),\n",
       " ('initial phone screening recruiter technical', 0.30151134457776363),\n",
       " ('theres initial phone screening recruiter', 0.30151134457776363),\n",
       " ('technical phone screening sr data', 0.30151134457776363),\n",
       " ('screening sr data scientist pass', 0.30151134457776363),\n",
       " ('sr data scientist pass invite', 0.30151134457776363),\n",
       " ('answered questions well seems better', 0.30151134457776363),\n",
       " ('mostly technical much hard opinion', 0.30151134457776363),\n",
       " ('data scientist pass invite group', 0.30151134457776363),\n",
       " ('recruiter technical phone screening sr', 0.30151134457776363),\n",
       " ('think answered questions well seems', 0.30151134457776363),\n",
       " ('technical much hard opinion think', 0.30151134457776363),\n",
       " ('screening recruiter technical phone screening', 0.30151134457776363),\n",
       " ('well seems better candidates rejected', 0.30151134457776363),\n",
       " ('unimpressed process turned sadly bad', 0.28867513459481287),\n",
       " ('questions asked technical questions coding', 0.28867513459481287),\n",
       " ('based data manipulation behavioral questions', 0.28867513459481287),\n",
       " ('based optimization questions second one', 0.28867513459481287),\n",
       " ('bad stories heard amazon true', 0.28867513459481287),\n",
       " ('asked general questions asked technical', 0.28867513459481287),\n",
       " ('video interviews first based optimization', 0.28867513459481287),\n",
       " ('questions coding phase pretty nice', 0.28867513459481287),\n",
       " ('second one technical interview codes', 0.28867513459481287),\n",
       " ('inconsiderate got offer unimpressed process', 0.28867513459481287),\n",
       " ('pretty nice easy part need', 0.28867513459481287),\n",
       " ('prep work recruiter interviewer must', 0.28867513459481287),\n",
       " ('asked technical questions coding phase', 0.28867513459481287),\n",
       " ('straight coding challenge hung failed', 0.28867513459481287),\n",
       " ('ijp need pg phd required', 0.28867513459481287),\n",
       " ('stuff day skipped straight coding', 0.28867513459481287),\n",
       " ('questions second one technical interview', 0.28867513459481287),\n",
       " ('domain difficult crack interview flunk', 0.28867513459481287),\n",
       " ('easy part need prepare dont', 0.28867513459481287),\n",
       " ('flunk first round dont idea', 0.28867513459481287),\n",
       " ('first round dont idea comment', 0.28867513459481287),\n",
       " ('sadly bad stories heard amazon', 0.28867513459481287),\n",
       " ('rude inconsiderate got offer unimpressed', 0.28867513459481287),\n",
       " ('recruiter interviewer must stuff day', 0.28867513459481287),\n",
       " ('skipped straight coding challenge hung', 0.28867513459481287),\n",
       " ('offer unimpressed process turned sadly', 0.28867513459481287),\n",
       " ('general questions asked technical questions', 0.28867513459481287),\n",
       " ('crack interview flunk first round', 0.28867513459481287),\n",
       " ('interviewer must stuff day skipped', 0.28867513459481287),\n",
       " ('technical questions coding phase pretty', 0.28867513459481287),\n",
       " ('nice easy part need prepare', 0.28867513459481287),\n",
       " ('technical interview codes based data', 0.28867513459481287),\n",
       " ('need pg phd required domain', 0.28867513459481287),\n",
       " ('day skipped straight coding challenge', 0.28867513459481287),\n",
       " ('must stuff day skipped straight', 0.28867513459481287),\n",
       " ('recruiters rude inconsiderate got offer', 0.28867513459481287),\n",
       " ('one technical interview codes based', 0.28867513459481287),\n",
       " ('coding phase pretty nice easy', 0.28867513459481287),\n",
       " ('coding challenge hung failed terrible', 0.28867513459481287),\n",
       " ('codes based data manipulation behavioral', 0.28867513459481287),\n",
       " ('phd required domain difficult crack', 0.28867513459481287),\n",
       " ('interviewers recruiters rude inconsiderate got', 0.28867513459481287),\n",
       " ('phase pretty nice easy part', 0.28867513459481287),\n",
       " ('pg phd required domain difficult', 0.28867513459481287),\n",
       " ('hellish interviewers recruiters rude inconsiderate', 0.28867513459481287),\n",
       " ('internal ijp need pg phd', 0.28867513459481287),\n",
       " ('interviews first based optimization questions', 0.28867513459481287),\n",
       " ('turned sadly bad stories heard', 0.28867513459481287),\n",
       " ('part need prepare dont nervous', 0.28867513459481287),\n",
       " ('difficult crack interview flunk first', 0.28867513459481287),\n",
       " ('required domain difficult crack interview', 0.28867513459481287),\n",
       " ('great prep work recruiter interviewer', 0.28867513459481287),\n",
       " ('challenge hung failed terrible expreince', 0.28867513459481287),\n",
       " ('first based optimization questions second', 0.28867513459481287),\n",
       " ('got offer unimpressed process turned', 0.28867513459481287),\n",
       " ('process turned sadly bad stories', 0.28867513459481287),\n",
       " ('optimization questions second one technical', 0.28867513459481287),\n",
       " ('interview flunk first round dont', 0.28867513459481287),\n",
       " ('work recruiter interviewer must stuff', 0.28867513459481287),\n",
       " ('interview codes based data manipulation', 0.28867513459481287),\n",
       " ('got another interview request recruiter', 0.2773500981126146),\n",
       " ('shocked guy managing people team', 0.2773500981126146),\n",
       " ('professionally shocked guy managing people', 0.2773500981126146),\n",
       " ('phone interviews team member project', 0.2773500981126146),\n",
       " ('communication skills acted non professionally', 0.2773500981126146),\n",
       " ('smooth friendly easy basic questions', 0.2773500981126146),\n",
       " ('request recruiter phone interviews team', 0.2773500981126146),\n",
       " ('recruiter days later got another', 0.2773500981126146),\n",
       " ('interviews team member project manager', 0.2773500981126146),\n",
       " ('friendly easy basic questions python', 0.2773500981126146),\n",
       " ('initial phone screening recruiter days', 0.2773500981126146),\n",
       " ('phone screening recruiter days later', 0.2773500981126146),\n",
       " ('screening recruiter days later got', 0.2773500981126146),\n",
       " ('may worst interviewer amazon communication', 0.2773500981126146),\n",
       " ('coding place test code interested', 0.2773500981126146),\n",
       " ('place test code interested approach', 0.2773500981126146),\n",
       " ('another interview request recruiter phone', 0.2773500981126146),\n",
       " ('questions python sql queries asked', 0.2773500981126146),\n",
       " ('interviewer amazon communication skills acted', 0.2773500981126146),\n",
       " ('amazon communication skills acted non', 0.2773500981126146),\n",
       " ('test code interested approach results', 0.2773500981126146),\n",
       " ('interview request recruiter phone interviews', 0.2773500981126146),\n",
       " ('interviewed may worst interviewer amazon', 0.2773500981126146),\n",
       " ('sql queries asked blackbox coding', 0.2773500981126146),\n",
       " ('recruiter phone interviews team member', 0.2773500981126146),\n",
       " ('queries asked blackbox coding place', 0.2773500981126146),\n",
       " ('later got another interview request', 0.2773500981126146),\n",
       " ('acted non professionally shocked guy', 0.2773500981126146),\n",
       " ('skills acted non professionally shocked', 0.2773500981126146),\n",
       " ('basic questions python sql queries', 0.2773500981126146),\n",
       " ('guy interviewed may worst interviewer', 0.2773500981126146),\n",
       " ('days later got another interview', 0.2773500981126146),\n",
       " ('blackbox coding place test code', 0.2773500981126146),\n",
       " ('guy managing people team wow', 0.2773500981126146),\n",
       " ('python sql queries asked blackbox', 0.2773500981126146),\n",
       " ('asked blackbox coding place test', 0.2773500981126146),\n",
       " ('worst interviewer amazon communication skills', 0.2773500981126146),\n",
       " ('non professionally shocked guy managing', 0.2773500981126146),\n",
       " ('easy basic questions python sql', 0.2773500981126146),\n",
       " ('interview live coding fourth site', 0.26726124191242434),\n",
       " ('fine includes individual meetings five', 0.26726124191242434),\n",
       " ('describe company team asked complete', 0.26726124191242434),\n",
       " ('recruiter third screening interview live', 0.26726124191242434),\n",
       " ('initial phone screen minutes going', 0.26726124191242434),\n",
       " ('week return feedback im done', 0.26726124191242434),\n",
       " ('screen minutes going resume background', 0.26726124191242434),\n",
       " ('interview fine includes individual meetings', 0.26726124191242434),\n",
       " ('algorithm overall experience fine need', 0.26726124191242434),\n",
       " ('different topics including coding language', 0.26726124191242434),\n",
       " ('week planned phone interview next', 0.26726124191242434),\n",
       " ('screening interview live coding fourth', 0.26726124191242434),\n",
       " ('minutes going resume background describe', 0.26726124191242434),\n",
       " ('includes individual meetings five six', 0.26726124191242434),\n",
       " ('recruiter linkedin set phone interview', 0.26726124191242434),\n",
       " ('resume screening second interview recruiter', 0.26726124191242434),\n",
       " ('coding assignments using languages choosing', 0.26726124191242434),\n",
       " ('ask project questions algorithm overall', 0.26726124191242434),\n",
       " ('individual meetings five six people', 0.26726124191242434),\n",
       " ('interview process first resume screening', 0.26726124191242434),\n",
       " ('team asked complete coding assignments', 0.26726124191242434),\n",
       " ('asked complete coding assignments using', 0.26726124191242434),\n",
       " ('fourth site interview finalize process', 0.26726124191242434),\n",
       " ('contacted amazons recruiter linkedin set', 0.26726124191242434),\n",
       " ('data scientist answer questions different', 0.26726124191242434),\n",
       " ('recruiter within week planned phone', 0.26726124191242434),\n",
       " ('coding fourth site interview finalize', 0.26726124191242434),\n",
       " ('within week planned phone interview', 0.26726124191242434),\n",
       " ('overall experience fine need prepared', 0.26726124191242434),\n",
       " ('via jobs received invitation recruiter', 0.26726124191242434),\n",
       " ('second interview recruiter third screening', 0.26726124191242434),\n",
       " ('screening second interview recruiter third', 0.26726124191242434),\n",
       " ('interview senior data scientist answer', 0.26726124191242434),\n",
       " ('process first resume screening second', 0.26726124191242434),\n",
       " ('background describe company team asked', 0.26726124191242434),\n",
       " ('resume background describe company team', 0.26726124191242434),\n",
       " ('five six people may ask', 0.26726124191242434),\n",
       " ('amazons recruiter linkedin set phone', 0.26726124191242434),\n",
       " ('questions algorithm overall experience fine', 0.26726124191242434),\n",
       " ('interview next week return feedback', 0.26726124191242434),\n",
       " ('may ask project questions algorithm', 0.26726124191242434),\n",
       " ('people may ask project questions', 0.26726124191242434),\n",
       " ('phone interview senior data scientist', 0.26726124191242434),\n",
       " ('company team asked complete coding', 0.26726124191242434),\n",
       " ('next week return feedback im', 0.26726124191242434),\n",
       " ('submit resume via jobs received', 0.26726124191242434),\n",
       " ('phone interview next week return', 0.26726124191242434),\n",
       " ('senior data scientist answer questions', 0.26726124191242434),\n",
       " ('complete coding assignments using languages', 0.26726124191242434),\n",
       " ('jobs received invitation recruiter within', 0.26726124191242434),\n",
       " ('project questions algorithm overall experience', 0.26726124191242434),\n",
       " ('set phone interview senior data', 0.26726124191242434),\n",
       " ('phone screen minutes going resume', 0.26726124191242434),\n",
       " ('received invitation recruiter within week', 0.26726124191242434),\n",
       " ('resume via jobs received invitation', 0.26726124191242434),\n",
       " ('six people may ask project', 0.26726124191242434),\n",
       " ('linkedin set phone interview senior', 0.26726124191242434),\n",
       " ('live coding fourth site interview', 0.26726124191242434),\n",
       " ('invitation recruiter within week planned', 0.26726124191242434),\n",
       " ('assignments using languages choosing interview', 0.26726124191242434),\n",
       " ('topics including coding language choosing', 0.26726124191242434),\n",
       " ('first resume screening second interview', 0.26726124191242434),\n",
       " ('answer questions different topics including', 0.26726124191242434),\n",
       " ('going resume background describe company', 0.26726124191242434),\n",
       " ('third screening interview live coding', 0.26726124191242434),\n",
       " ('meetings five six people may', 0.26726124191242434),\n",
       " ('planned phone interview next week', 0.26726124191242434),\n",
       " ('interview recruiter third screening interview', 0.26726124191242434),\n",
       " ('scientist answer questions different topics', 0.26726124191242434),\n",
       " ('questions different topics including coding', 0.26726124191242434),\n",
       " ('projects internships por extracurricular statistics', 0.2649064714130087),\n",
       " ('statistics round ml model implementation', 0.2649064714130087),\n",
       " ('resume projects internships por extracurricular', 0.2649064714130087),\n",
       " ('implementation puzzles hr basic hr', 0.2649064714130087),\n",
       " ('por extracurricular statistics round ml', 0.2649064714130087),\n",
       " ('round ml model implementation puzzles', 0.2649064714130087),\n",
       " ('puzzles hr basic hr questions', 0.2649064714130087),\n",
       " ('model implementation puzzles hr basic', 0.2649064714130087),\n",
       " ('internships por extracurricular statistics round', 0.2649064714130087),\n",
       " ('extracurricular statistics round ml model', 0.2649064714130087),\n",
       " ('round resume projects internships por', 0.2649064714130087),\n",
       " ('ml model implementation puzzles hr', 0.2649064714130087),\n",
       " ('day onsite interviews covering technical', 0.25947226658514855),\n",
       " ('questions well good response time', 0.25947226658514855),\n",
       " ('phone screen technical questions behavioral', 0.25947226658514855),\n",
       " ('covering technical behavioral questions well', 0.25947226658514855),\n",
       " ('started phone screen technical questions', 0.25947226658514855),\n",
       " ('questions behavioral questions full day', 0.25947226658514855),\n",
       " ('full day onsite interviews covering', 0.25947226658514855),\n",
       " ('interviews covering technical behavioral questions', 0.25947226658514855),\n",
       " ('screen technical questions behavioral questions', 0.25947226658514855),\n",
       " ('technical questions behavioral questions full', 0.25947226658514855),\n",
       " ('onsite interviews covering technical behavioral', 0.25947226658514855),\n",
       " ('technical behavioral questions well good', 0.25947226658514855),\n",
       " ('behavioral questions well good response', 0.25947226658514855),\n",
       " ('behavioral questions full day onsite', 0.25947226658514855),\n",
       " ('enough maybe sql basic lp', 0.2581988897471611),\n",
       " ('first round case study question', 0.2581988897471611),\n",
       " ('basic lp solutions assumption sure', 0.2581988897471611),\n",
       " ('good experience overall didnt get', 0.2581988897471611),\n",
       " ('assumption sure sr want experiences', 0.2581988897471611),\n",
       " ('phone interview second round business', 0.2581988897471611),\n",
       " ('pure behavior questions ask leadership', 0.2581988897471611),\n",
       " ('small case studies easy math', 0.2581988897471611),\n",
       " ('interview second round business case', 0.2581988897471611),\n",
       " ('first phone interview second round', 0.2581988897471611),\n",
       " ('total first one pure technical', 0.2581988897471611),\n",
       " ('one pure behavior questions ask', 0.2581988897471611),\n",
       " ('feedback interviewer hr interview bad', 0.2581988897471611),\n",
       " ('sql basic lp solutions assumption', 0.2581988897471611),\n",
       " ('case second round week prepare', 0.2581988897471611),\n",
       " ('studies easy math problems time', 0.2581988897471611),\n",
       " ('screening interview typically brief conversation', 0.2581988897471611),\n",
       " ('case studies easy math problems', 0.2581988897471611),\n",
       " ('application selected may contacted phone', 0.2581988897471611),\n",
       " ('management questions consisting emails company', 0.2581988897471611),\n",
       " ('lp solutions assumption sure sr', 0.2581988897471611),\n",
       " ('coding tests feedback interviewer hr', 0.2581988897471611),\n",
       " ('round week prepare one business', 0.2581988897471611),\n",
       " ('round case study question along', 0.2581988897471611),\n",
       " ('phone interviews hours total first', 0.2581988897471611),\n",
       " ('interviews hours total first one', 0.2581988897471611),\n",
       " ('joint two round first phone', 0.2581988897471611),\n",
       " ('interviewer hr interview bad experience', 0.2581988897471611),\n",
       " ('selected may contacted phone video', 0.2581988897471611),\n",
       " ('hours total first one pure', 0.2581988897471611),\n",
       " ('experience overall didnt get offer', 0.2581988897471611),\n",
       " ('round business case second round', 0.2581988897471611),\n",
       " ('offer didnt senior enough maybe', 0.2581988897471611),\n",
       " ('along technical machine learning questions', 0.2581988897471611),\n",
       " ('maybe sql basic lp solutions', 0.2581988897471611),\n",
       " ('questions ask leadership principles drive', 0.2581988897471611),\n",
       " ('study question along technical machine', 0.2581988897471611),\n",
       " ('brief conversation recruiter hiring manager', 0.2581988897471611),\n",
       " ('phone video screening interview typically', 0.2581988897471611),\n",
       " ('technical question second one pure', 0.2581988897471611),\n",
       " ('problems time management questions consisting', 0.2581988897471611),\n",
       " ('one pure technical question second', 0.2581988897471611),\n",
       " ('conversation recruiter hiring manager assess', 0.2581988897471611),\n",
       " ('may contacted phone video screening', 0.2581988897471611),\n",
       " ('manager assess qualifications interest role', 0.2581988897471611),\n",
       " ('planning business day prioritizing tasks', 0.2581988897471611),\n",
       " ('week prepare one business case', 0.2581988897471611),\n",
       " ('company planning business day prioritizing', 0.2581988897471611),\n",
       " ('stage small case studies easy', 0.2581988897471611),\n",
       " ('business case second round week', 0.2581988897471611),\n",
       " ('didnt get offer didnt senior', 0.2581988897471611),\n",
       " ('case study question along technical', 0.2581988897471611),\n",
       " ('technical machine learning questions isnt', 0.2581988897471611),\n",
       " ('time management questions consisting emails', 0.2581988897471611),\n",
       " ('math problems time management questions', 0.2581988897471611),\n",
       " ('get offer didnt senior enough', 0.2581988897471611),\n",
       " ('pure technical question second one', 0.2581988897471611),\n",
       " ('question along technical machine learning', 0.2581988897471611),\n",
       " ('video screening interview typically brief', 0.2581988897471611),\n",
       " ('interview typically brief conversation recruiter', 0.2581988897471611),\n",
       " ('round first phone interview second', 0.2581988897471611),\n",
       " ('second one pure behavior questions', 0.2581988897471611),\n",
       " ('learning questions isnt coding tests', 0.2581988897471611),\n",
       " ('behavior questions ask leadership principles', 0.2581988897471611),\n",
       " ('two round first phone interview', 0.2581988897471611),\n",
       " ('recruiter hiring manager assess qualifications', 0.2581988897471611),\n",
       " ('emails company planning business day', 0.2581988897471611),\n",
       " ('question second one pure behavior', 0.2581988897471611),\n",
       " ('machine learning questions isnt coding', 0.2581988897471611),\n",
       " ('tests feedback interviewer hr interview', 0.2581988897471611),\n",
       " ('applying application selected may contacted', 0.2581988897471611),\n",
       " ('senior enough maybe sql basic', 0.2581988897471611),\n",
       " ('questions consisting emails company planning', 0.2581988897471611),\n",
       " ('typically brief conversation recruiter hiring', 0.2581988897471611),\n",
       " ('easy math problems time management', 0.2581988897471611),\n",
       " ('questions isnt coding tests feedback', 0.2581988897471611),\n",
       " ('second round week prepare one', 0.2581988897471611),\n",
       " ('one business case submit team', 0.2581988897471611),\n",
       " ('first stage small case studies', 0.2581988897471611),\n",
       " ('isnt coding tests feedback interviewer', 0.2581988897471611),\n",
       " ('consisting emails company planning business', 0.2581988897471611),\n",
       " ('prepare one business case submit', 0.2581988897471611),\n",
       " ('contacted phone video screening interview', 0.2581988897471611),\n",
       " ('overall didnt get offer didnt', 0.2581988897471611),\n",
       " ('didnt senior enough maybe sql', 0.2581988897471611),\n",
       " ('hiring manager assess qualifications interest', 0.2581988897471611),\n",
       " ('second round business case second', 0.2581988897471611),\n",
       " ('ask leadership principles drive amazon', 0.2581988897471611),\n",
       " ('first one pure technical question', 0.2581988897471611),\n",
       " ('solutions assumption sure sr want', 0.2581988897471611),\n",
       " ('technical questions second phone interview', 0.25),\n",
       " ('interviewers recruiters friendly process moved', 0.25),\n",
       " ('past project pvalue interview well', 0.25),\n",
       " ('round hours different data scientistsapplied', 0.25),\n",
       " ('join company tech assessment coding', 0.25),\n",
       " ('gave feedback days later theres', 0.25),\n",
       " ('similar interview guide recruiter would', 0.25),\n",
       " ('joins max would situation directly', 0.25),\n",
       " ('one round phone screen rounds', 0.25),\n",
       " ('live coding asked coding questions', 0.25),\n",
       " ('big day lunch body assigned', 0.25),\n",
       " ('team round rounds interviews offer', 0.25),\n",
       " ('hard week asked work artifact', 0.25),\n",
       " ('try see goes recommended others', 0.25),\n",
       " ('big day rounds big day', 0.25),\n",
       " ('questions team round rounds interviews', 0.25),\n",
       " ('bie position interviewer asked past', 0.25),\n",
       " ('theres questionair process two weeks', 0.25),\n",
       " ('interview guide recruiter would share', 0.25),\n",
       " ('round interviews one team members', 0.25),\n",
       " ('left minutes end ask half', 0.25),\n",
       " ('obscure statistical ml topics minute', 0.25),\n",
       " ('company tech assessment coding exercise', 0.25),\n",
       " ('ml topics minute interview interviewer', 0.25),\n",
       " ('round member team live coding', 0.25),\n",
       " ('final round hours different data', 0.25),\n",
       " ('interview made clear looking someone', 0.25),\n",
       " ('max would situation directly relevant', 0.25),\n",
       " ('body assigned lunch chat lunch', 0.25),\n",
       " ('stat knowledge medium sql questions', 0.25),\n",
       " ('looking someone different set experiences', 0.25),\n",
       " ('general interview hr second round', 0.25),\n",
       " ('technical assessments using chime big', 0.25),\n",
       " ('gave information expect upcoming phone', 0.25),\n",
       " ('moderately hard week asked work', 0.25),\n",
       " ('projects left minutes end ask', 0.25),\n",
       " ('recruiter call asking past experience', 0.25),\n",
       " ('different data scientistsapplied scientistshiring manager', 0.25),\n",
       " ('got offer internal transfer bie', 0.25),\n",
       " ('chime big day rounds big', 0.25),\n",
       " ('first contact took longer time', 0.25),\n",
       " ('lease prepare interviewers recruiters friendly', 0.25),\n",
       " ('interviews technical questions second phone', 0.25),\n",
       " ('chat lunch talk part interview', 0.25),\n",
       " ('hiring manager bar raiser mix', 0.25),\n",
       " ('coding exercise stats questions team', 0.25),\n",
       " ('timely encourage collaboration open culture', 0.25),\n",
       " ('rounds onsite seattle office interviewers', 0.25),\n",
       " ('schedule one first screening interviewers', 0.25),\n",
       " ('office interviewers nice gave feedback', 0.25),\n",
       " ('contacted recruiter via email technical', 0.25),\n",
       " ('would situation directly relevant principle', 0.25),\n",
       " ('team live coding asked coding', 0.25),\n",
       " ('first screening interviewers asked lots', 0.25),\n",
       " ('time schedule interview availability based', 0.25),\n",
       " ('offer internal transfer bie position', 0.25),\n",
       " ('knowledge medium sql questions amazon', 0.25),\n",
       " ('onsite seattle office interviewers nice', 0.25),\n",
       " ('open culture enjoyed experience opportunities', 0.25),\n",
       " ('minutes end ask half question', 0.25),\n",
       " ('minute interview interviewer ask projects', 0.25),\n",
       " ('minutes interview interviewer asked lot', 0.25),\n",
       " ('onsite rounds data scientists hiring', 0.25),\n",
       " ('coding asked coding questions data', 0.25),\n",
       " ('opportunities well also try see', 0.25),\n",
       " ('schedule interview availability based schedule', 0.25),\n",
       " ('contact took longer time schedule', 0.25),\n",
       " ('would share lease prepare interviewers', 0.25),\n",
       " ('clear looking someone different set', 0.25),\n",
       " ('share lease prepare interviewers recruiters', 0.25),\n",
       " ('expect upcoming phone interviews technical', 0.25),\n",
       " ('mix technical questions behavioral questions', 0.25),\n",
       " ('reasons join company tech assessment', 0.25),\n",
       " ('coding questions data structure algorithms', 0.25),\n",
       " ('interviews one team members interviewer', 0.25),\n",
       " ('guide recruiter would share lease', 0.25),\n",
       " ('team members interviewer mainly asked', 0.25),\n",
       " ('call technical phone interview data', 0.25),\n",
       " ('first round interviews one team', 0.25),\n",
       " ('quiz obscure statistical ml topics', 0.25),\n",
       " ('half interviews lp questions find', 0.25),\n",
       " ('medium sql questions amazon principles', 0.25),\n",
       " ('interviews lp questions find online', 0.25),\n",
       " ('goes recommended others try opportunities', 0.25),\n",
       " ('one month first contact took', 0.25),\n",
       " ('transfer bie position interviewer asked', 0.25),\n",
       " ('scheduled following week lasted around', 0.25),\n",
       " ('call asking past experience reasons', 0.25),\n",
       " ('past experience reasons join company', 0.25),\n",
       " ('one team members interviewer mainly', 0.25),\n",
       " ('lasted around hour next step', 0.25),\n",
       " ('collaboration open culture enjoyed experience', 0.25),\n",
       " ('raiser mix technical questions behavioral', 0.25),\n",
       " ('longer time schedule interview availability', 0.25),\n",
       " ('coding scheduled following week lasted', 0.25),\n",
       " ('one first screening interviewers asked', 0.25),\n",
       " ('took longer time schedule interview', 0.25),\n",
       " ('took one month first contact', 0.25),\n",
       " ('recruiter gave information expect upcoming', 0.25),\n",
       " ('members interviewer mainly asked questions', 0.25),\n",
       " ('month first contact took longer', 0.25),\n",
       " ('paced moderately hard week asked', 0.25),\n",
       " ('topics minute interview interviewer ask', 0.25),\n",
       " ('online hourlong technical assessments using', 0.25),\n",
       " ('tech assessment coding exercise stats', 0.25),\n",
       " ('fist round general interview hr', 0.25),\n",
       " ('member team live coding asked', 0.25),\n",
       " ('random pop quiz obscure statistical', 0.25),\n",
       " ('screen rounds onsite seattle office', 0.25),\n",
       " ('organized timely encourage collaboration open', 0.25),\n",
       " ('internal transfer bie position interviewer', 0.25),\n",
       " ('questions like lot similar interview', 0.25),\n",
       " ('second round member team live', 0.25),\n",
       " ('asked past project pvalue interview', 0.25),\n",
       " ('recruiter via email technical interview', 0.25),\n",
       " ('technical phone interview data scientist', 0.25),\n",
       " ('asked lot questions work done', 0.25),\n",
       " ('interview coding scheduled following week', 0.25),\n",
       " ('pvalue sql question use joins', 0.25),\n",
       " ('structure algorithms deep learning question', 0.25),\n",
       " ('sql round final round hours', 0.25),\n",
       " ('asked coding questions data structure', 0.25),\n",
       " ('data scientist onsite rounds data', 0.25),\n",
       " ('questions previous experience minutes interview', 0.25),\n",
       " ('immediately began random pop quiz', 0.25),\n",
       " ('prepare interviewers recruiters friendly process', 0.25),\n",
       " ('ask projects left minutes end', 0.25),\n",
       " ('interview availability based schedule one', 0.25),\n",
       " ('round final round hours different', 0.25),\n",
       " ('round phone screen rounds onsite', 0.25),\n",
       " ('second phone interview made clear', 0.25),\n",
       " ('recruiter would share lease prepare', 0.25),\n",
       " ('around hour next step likely', 0.25),\n",
       " ('email technical interview coding scheduled', 0.25),\n",
       " ('mainly asked questions previous experience', 0.25),\n",
       " ('interviewers nice gave feedback days', 0.25),\n",
       " ('position interviewer asked past project', 0.25),\n",
       " ('like lot similar interview guide', 0.25),\n",
       " ('hr second round member team', 0.25),\n",
       " ('interview data scientist onsite rounds', 0.25),\n",
       " ('assigned lunch chat lunch talk', 0.25),\n",
       " ('assessments using chime big day', 0.25),\n",
       " ('use joins max would situation', 0.25),\n",
       " ('using chime big day rounds', 0.25),\n",
       " ('assessment coding exercise stats questions', 0.25),\n",
       " ('scientist onsite rounds data scientists', 0.25),\n",
       " ('asking past experience reasons join', 0.25),\n",
       " ('see goes recommended others try', 0.25),\n",
       " ('friendly process moved relatively fast', 0.25),\n",
       " ('pvalue interview well paced moderately', 0.25),\n",
       " ('someone different set experiences skills', 0.25),\n",
       " ('value questions like lot similar', 0.25),\n",
       " ('pop quiz obscure statistical ml', 0.25),\n",
       " ('interview well paced moderately hard', 0.25),\n",
       " ('via email technical interview coding', 0.25),\n",
       " ('asked questions previous experience minutes', 0.25),\n",
       " ('experience minutes interview interviewer asked', 0.25),\n",
       " ('made clear looking someone different', 0.25),\n",
       " ('also try see goes recommended', 0.25),\n",
       " ('data scientistsapplied scientistshiring manager half', 0.25),\n",
       " ('data structure algorithms deep learning', 0.25),\n",
       " ('experience reasons join company tech', 0.25),\n",
       " ('scientistshiring manager half interviews lp', 0.25),\n",
       " ('lunch chat lunch talk part', 0.25),\n",
       " ('stats questions team round rounds', 0.25),\n",
       " ('questions amazon principles whats pvalue', 0.25),\n",
       " ('lunch body assigned lunch chat', 0.25),\n",
       " ('day rounds big day lunch', 0.25),\n",
       " ('technical interview coding scheduled following', 0.25),\n",
       " ('questionair process two weeks later', 0.25),\n",
       " ('leadership principles sql round final', 0.25),\n",
       " ('round rounds interviews offer stage', 0.25),\n",
       " ('following week lasted around hour', 0.25),\n",
       " ('whats pvalue sql question use', 0.25),\n",
       " ('experience opportunities well also try', 0.25),\n",
       " ('question use joins max would', 0.25),\n",
       " ('amazon principles whats pvalue sql', 0.25),\n",
       " ('much focus leadership principles sql', 0.25),\n",
       " ('day lunch body assigned lunch', 0.25),\n",
       " ('scientistsapplied scientistshiring manager half interviews', 0.25),\n",
       " ('screening interviewers asked lots questions', 0.25),\n",
       " ('encourage collaboration open culture enjoyed', 0.25),\n",
       " ('data scientists hiring manager bar', 0.25),\n",
       " ('previous experience minutes interview interviewer', 0.25),\n",
       " ('questions data structure algorithms deep', 0.25),\n",
       " ('week lasted around hour next', 0.25),\n",
       " ('statistical ml topics minute interview', 0.25),\n",
       " ('information expect upcoming phone interviews', 0.25),\n",
       " ('seattle office interviewers nice gave', 0.25),\n",
       " ('informed organized timely encourage collaboration', 0.25),\n",
       " ('likely would hours interview rounds', 0.25),\n",
       " ('principles sql round final round', 0.25),\n",
       " ('lot similar interview guide recruiter', 0.25),\n",
       " ('principles whats pvalue sql question', 0.25),\n",
       " ('well also try see goes', 0.25),\n",
       " ('enjoyed experience opportunities well also', 0.25),\n",
       " ('lot value questions like lot', 0.25),\n",
       " ('well informed organized timely encourage', 0.25),\n",
       " ('recruiters friendly process moved relatively', 0.25),\n",
       " ('scientists hiring manager bar raiser', 0.25),\n",
       " ('step likely would hours interview', 0.25),\n",
       " ('well paced moderately hard week', 0.25),\n",
       " ('later theres questionair process two', 0.25),\n",
       " ('nice gave feedback days later', 0.25),\n",
       " ('feedback days later theres questionair', 0.25),\n",
       " ('sql questions amazon principles whats', 0.25),\n",
       " ('hr call technical phone interview', 0.25),\n",
       " ('interview interviewer ask projects left', 0.25),\n",
       " ('basic stat knowledge medium sql', 0.25),\n",
       " ('interviewer mainly asked questions previous', 0.25),\n",
       " ('upcoming phone interviews technical questions', 0.25),\n",
       " ('phone screen rounds onsite seattle', 0.25),\n",
       " ('hour next step likely would', 0.25),\n",
       " ('manager bar raiser mix technical', 0.25),\n",
       " ('interview interviewer asked lot questions', 0.25),\n",
       " ('rounds data scientists hiring manager', 0.25),\n",
       " ('next step likely would hours', 0.25),\n",
       " ('phone interview made clear looking', 0.25),\n",
       " ('hours different data scientistsapplied scientistshiring', 0.25),\n",
       " ('phone interviews technical questions second', 0.25),\n",
       " ('round general interview hr second', 0.25),\n",
       " ('hourlong technical assessments using chime', 0.25),\n",
       " ('bar raiser mix technical questions', 0.25),\n",
       " ('questions second phone interview made', 0.25),\n",
       " ('rounds big day lunch body', 0.25),\n",
       " ('based schedule one first screening', 0.25),\n",
       " ('manager half interviews lp questions', 0.25),\n",
       " ('focus leadership principles sql round', 0.25),\n",
       " ('days later theres questionair process', 0.25),\n",
       " ('culture enjoyed experience opportunities well', 0.25),\n",
       " ('began random pop quiz obscure', 0.25),\n",
       " ('project pvalue interview well paced', 0.25),\n",
       " ('interview hr second round member', 0.25),\n",
       " ('interviewer asked lot questions work', 0.25),\n",
       " ('interviewer ask projects left minutes', 0.25),\n",
       " ('phone interview data scientist onsite', 0.25),\n",
       " ('availability based schedule one first', 0.25),\n",
       " ('exercise stats questions team round', 0.25),\n",
       " ('interviewer asked past project pvalue', 0.25),\n",
       " ('sql question use joins max', 0.25),\n",
       " ('got call within days set', 0.24253562503633294),\n",
       " ('referral got call within days', 0.24253562503633294),\n",
       " ('live coding session difficult matters', 0.24253562503633294),\n",
       " ('one project mentioned asked solved', 0.24253562503633294),\n",
       " ('applied referral got call within', 0.24253562503633294),\n",
       " ('role applied referral got call', 0.24253562503633294),\n",
       " ('principles included every interview prepare', 0.24253562503633294),\n",
       " ('project mentioned asked solved ambiguous', 0.24253562503633294),\n",
       " ('test live coding session difficult', 0.24253562503633294),\n",
       " ('nice people test live coding', 0.24253562503633294),\n",
       " ('second part detailed discussion one', 0.24253562503633294),\n",
       " ('people behavior questions leadership principles', 0.24253562503633294),\n",
       " ('data scientist role applied referral', 0.24253562503633294),\n",
       " ('onsite interviews groups people behavior', 0.24253562503633294),\n",
       " ('team human resource round human', 0.24253562503633294),\n",
       " ('alexa team cambridge data scientist', 0.24253562503633294),\n",
       " ('interviews groups people behavior questions', 0.24253562503633294),\n",
       " ('part afterwards ittest overall questioners', 0.24253562503633294),\n",
       " ('lp asked following questions mostly', 0.24253562503633294),\n",
       " ('interview technical team human resource', 0.24253562503633294),\n",
       " ('lots examples answering behavior questions', 0.24253562503633294),\n",
       " ('interview divided two parts first', 0.24253562503633294),\n",
       " ('tested mainly basics asked lp', 0.24253562503633294),\n",
       " ('really nice people test live', 0.24253562503633294),\n",
       " ('first part related coding second', 0.24253562503633294),\n",
       " ('home assignment data science project', 0.24253562503633294),\n",
       " ('days set interview one machine', 0.24253562503633294),\n",
       " ('recruiter call recruiter mainly regarding', 0.24253562503633294),\n",
       " ('basics asked lp asked following', 0.24253562503633294),\n",
       " ('questioners really nice people test', 0.24253562503633294),\n",
       " ('screen call recruiter call recruiter', 0.24253562503633294),\n",
       " ('science project technical interview technical', 0.24253562503633294),\n",
       " ('one machine learning engineer junior', 0.24253562503633294),\n",
       " ('leadership principles included every interview', 0.24253562503633294),\n",
       " ('technical interview technical team human', 0.24253562503633294),\n",
       " ('answer part afterwards ittest overall', 0.24253562503633294),\n",
       " ('detailed discussion one project mentioned', 0.24253562503633294),\n",
       " ('related coding second part detailed', 0.24253562503633294),\n",
       " ('project technical interview technical team', 0.24253562503633294),\n",
       " ('expect next interview tested mainly', 0.24253562503633294),\n",
       " ('included every interview prepare lots', 0.24253562503633294),\n",
       " ('coding session difficult matters performed', 0.24253562503633294),\n",
       " ('behavior questions leadership principles included', 0.24253562503633294),\n",
       " ('coding second part detailed discussion', 0.24253562503633294),\n",
       " ('ittest overall questioners really nice', 0.24253562503633294),\n",
       " ('behavioral interview using star method', 0.24253562503633294),\n",
       " ('machine learning engineer junior person', 0.24253562503633294),\n",
       " ('matters performed well fluent enough', 0.24253562503633294),\n",
       " ('screens virtual onsite interviews groups', 0.24253562503633294),\n",
       " ('people test live coding session', 0.24253562503633294),\n",
       " ('star method take home assignment', 0.24253562503633294),\n",
       " ('two parts first part related', 0.24253562503633294),\n",
       " ('divided two parts first part', 0.24253562503633294),\n",
       " ('session difficult matters performed well', 0.24253562503633294),\n",
       " ('interview tested mainly basics asked', 0.24253562503633294),\n",
       " ('technical phone screen call recruiter', 0.24253562503633294),\n",
       " ('technical team human resource round', 0.24253562503633294),\n",
       " ('questions leadership principles included every', 0.24253562503633294),\n",
       " ('resource round human resource team', 0.24253562503633294),\n",
       " ('every interview prepare lots examples', 0.24253562503633294),\n",
       " ('recruiter mainly regarding expect next', 0.24253562503633294),\n",
       " ('mainly basics asked lp asked', 0.24253562503633294),\n",
       " ('asked solved ambiguous business problem', 0.24253562503633294),\n",
       " ('afterwards ittest overall questioners really', 0.24253562503633294),\n",
       " ('data science project technical interview', 0.24253562503633294),\n",
       " ('call recruiter call recruiter mainly', 0.24253562503633294),\n",
       " ('method take home assignment data', 0.24253562503633294),\n",
       " ('mainly regarding expect next interview', 0.24253562503633294),\n",
       " ('difficult matters performed well fluent', 0.24253562503633294),\n",
       " ('groups people behavior questions leadership', 0.24253562503633294),\n",
       " ('call recruiter mainly regarding expect', 0.24253562503633294),\n",
       " ('rounds phone screens virtual onsite', 0.24253562503633294),\n",
       " ('phone screens virtual onsite interviews', 0.24253562503633294),\n",
       " ('set interview one machine learning', 0.24253562503633294),\n",
       " ('interviewed alexa team cambridge data', 0.24253562503633294),\n",
       " ('call within days set interview', 0.24253562503633294),\n",
       " ('overall questioners really nice people', 0.24253562503633294),\n",
       " ('parts first part related coding', 0.24253562503633294),\n",
       " ('mentioned asked solved ambiguous business', 0.24253562503633294),\n",
       " ('using star method take home', 0.24253562503633294),\n",
       " ('human resource round human resource', 0.24253562503633294),\n",
       " ('part related coding second part', 0.24253562503633294),\n",
       " ('assignment data science project technical', 0.24253562503633294),\n",
       " ('discussion one project mentioned asked', 0.24253562503633294),\n",
       " ('cambridge data scientist role applied', 0.24253562503633294),\n",
       " ('part detailed discussion one project', 0.24253562503633294),\n",
       " ('take home assignment data science', 0.24253562503633294),\n",
       " ('interview one machine learning engineer', 0.24253562503633294),\n",
       " ('question answer part afterwards ittest', 0.24253562503633294),\n",
       " ('interview using star method take', 0.24253562503633294),\n",
       " ('within days set interview one', 0.24253562503633294),\n",
       " ('next interview tested mainly basics', 0.24253562503633294),\n",
       " ('scientist role applied referral got', 0.24253562503633294),\n",
       " ('phone screen call recruiter call', 0.24253562503633294),\n",
       " ('asked lp asked following questions', 0.24253562503633294),\n",
       " ('interview prepare lots examples answering', 0.24253562503633294),\n",
       " ('minute interview divided two parts', 0.24253562503633294),\n",
       " ('virtual onsite interviews groups people', 0.24253562503633294),\n",
       " ('prepare lots examples answering behavior', 0.24253562503633294),\n",
       " ('classical question answer part afterwards', 0.24253562503633294),\n",
       " ('regarding expect next interview tested', 0.24253562503633294),\n",
       " ('team cambridge data scientist role', 0.24253562503633294),\n",
       " ('python sql tools would like', 0.23570226039551584),\n",
       " ('regression many big picture sort', 0.23570226039551584),\n",
       " ('date time interview steps changed', 0.23570226039551584),\n",
       " ('demanding rewarding exciting signed nda', 0.23570226039551584),\n",
       " ('nda cant go specifics interview', 0.23570226039551584),\n",
       " ('data look like solve question', 0.23570226039551584),\n",
       " ('first round phone interview second', 0.23570226039551584),\n",
       " ('interview involved speaking different individuals', 0.23570226039551584),\n",
       " ('technical conversations lots behavioral questions', 0.23570226039551584),\n",
       " ('deliver result resume detailed questions', 0.23570226039551584),\n",
       " ('technical interview past projects finalonsite', 0.23570226039551584),\n",
       " ('round phone interview second round', 0.23570226039551584),\n",
       " ('sort questions seen similar roles', 0.23570226039551584),\n",
       " ('technical skills like good bs', 0.23570226039551584),\n",
       " ('technical took hour answered questions', 0.23570226039551584),\n",
       " ('recruiter reached linkedin first round', 0.23570226039551584),\n",
       " ('fit questions interviewee simply said', 0.23570226039551584),\n",
       " ('data processing overall good experience', 0.23570226039551584),\n",
       " ('skills like good bs good', 0.23570226039551584),\n",
       " ('five assumptions linear regression many', 0.23570226039551584),\n",
       " ('python based choice basic ml', 0.23570226039551584),\n",
       " ('wrong date time interview steps', 0.23570226039551584),\n",
       " ('kind problems meet whats data', 0.23570226039551584),\n",
       " ('round phone interview focuses sql', 0.23570226039551584),\n",
       " ('conversations lots behavioral questions study', 0.23570226039551584),\n",
       " ('leadership principle interview mathematical test', 0.23570226039551584),\n",
       " ('tell time goal hard achievewhat', 0.23570226039551584),\n",
       " ('obsession data science job care', 0.23570226039551584),\n",
       " ('interview interviews called wrong date', 0.23570226039551584),\n",
       " ('exciting signed nda cant go', 0.23570226039551584),\n",
       " ('round technical took hour answered', 0.23570226039551584),\n",
       " ('one hour calls data science', 0.23570226039551584),\n",
       " ('customer obsession data science job', 0.23570226039551584),\n",
       " ('terrible culture fit questions interviewee', 0.23570226039551584),\n",
       " ('culture fit questions interviewee simply', 0.23570226039551584),\n",
       " ('name five assumptions linear regression', 0.23570226039551584),\n",
       " ('offer also asked basic oops', 0.23570226039551584),\n",
       " ('writing ml python package realistic', 0.23570226039551584),\n",
       " ('data science team interview involved', 0.23570226039551584),\n",
       " ('focuses sql python based choice', 0.23570226039551584),\n",
       " ('nothing technical skills like good', 0.23570226039551584),\n",
       " ('nothing serious basically asked mentioned', 0.23570226039551584),\n",
       " ('dbms programmingpython java etc great', 0.23570226039551584),\n",
       " ('learning itgot job offer also', 0.23570226039551584),\n",
       " ('leadership principles examples multiple examples', 0.23570226039551584),\n",
       " ('data science job care nothing', 0.23570226039551584),\n",
       " ('focus behavioral questions involving lps', 0.23570226039551584),\n",
       " ('first round phone interview focuses', 0.23570226039551584),\n",
       " ('test oral technical interview past', 0.23570226039551584),\n",
       " ('achievewhat learn deliver result resume', 0.23570226039551584),\n",
       " ('hard achievewhat learn deliver result', 0.23570226039551584),\n",
       " ('said value customer obsession data', 0.23570226039551584),\n",
       " ('interview past projects finalonsite interview', 0.23570226039551584),\n",
       " ('hour second question writing ml', 0.23570226039551584),\n",
       " ('based choice basic ml questions', 0.23570226039551584),\n",
       " ('questions resume kind problems meet', 0.23570226039551584),\n",
       " ('questions related machine learning statistics', 0.23570226039551584),\n",
       " ('science team interview involved speaking', 0.23570226039551584),\n",
       " ('almost triviastyle questions ie name', 0.23570226039551584),\n",
       " ('picture sort questions seen similar', 0.23570226039551584),\n",
       " ('study leadership principles examples multiple', 0.23570226039551584),\n",
       " ('also asked basic oops dbms', 0.23570226039551584),\n",
       " ('hr nothing serious basically asked', 0.23570226039551584),\n",
       " ('assumptions linear regression many big', 0.23570226039551584),\n",
       " ('interviewee simply said value customer', 0.23570226039551584),\n",
       " ('resume detailed questions resume kind', 0.23570226039551584),\n",
       " ('resume kind problems meet whats', 0.23570226039551584),\n",
       " ('questions optimization data processing overall', 0.23570226039551584),\n",
       " ('value customer obsession data science', 0.23570226039551584),\n",
       " ('asked vo speaking one hour', 0.23570226039551584),\n",
       " ('result resume detailed questions resume', 0.23570226039551584),\n",
       " ('like good bs good chance', 0.23570226039551584),\n",
       " ('phone interview second round technical', 0.23570226039551584),\n",
       " ('hour calls data science team', 0.23570226039551584),\n",
       " ('two questions hour second question', 0.23570226039551584),\n",
       " ('highly related team interview python', 0.23570226039551584),\n",
       " ('many big picture sort questions', 0.23570226039551584),\n",
       " ('behavioral questions study leadership principles', 0.23570226039551584),\n",
       " ('related machine learning statistics coding', 0.23570226039551584),\n",
       " ('easy first round phone interview', 0.23570226039551584),\n",
       " ('hour answered questions optimization data', 0.23570226039551584),\n",
       " ('science job care nothing technical', 0.23570226039551584),\n",
       " ('hour onsite interview drill almost', 0.23570226039551584),\n",
       " ('basically asked mentioned quiz received', 0.23570226039551584),\n",
       " ('interview mathematical test oral technical', 0.23570226039551584),\n",
       " ('interview drill almost triviastyle questions', 0.23570226039551584),\n",
       " ('questions seen similar roles companies', 0.23570226039551584),\n",
       " ('basic oops dbms programmingpython java', 0.23570226039551584),\n",
       " ('hour lots focus behavioral questions', 0.23570226039551584),\n",
       " ('basic ml questions first round', 0.23570226039551584),\n",
       " ('fairly easy first round phone', 0.23570226039551584),\n",
       " ('linkedin first round phone interview', 0.23570226039551584),\n",
       " ('drill almost triviastyle questions ie', 0.23570226039551584),\n",
       " ('link answer two questions hour', 0.23570226039551584),\n",
       " ('lots behavioral questions study leadership', 0.23570226039551584),\n",
       " ('answered questions optimization data processing', 0.23570226039551584),\n",
       " ('answer two questions hour second', 0.23570226039551584),\n",
       " ('rewarding exciting signed nda cant', 0.23570226039551584),\n",
       " ('problems meet whats data look', 0.23570226039551584),\n",
       " ('another phone screen onsite intereview', 0.23570226039551584),\n",
       " ('process fairly easy first round', 0.23570226039551584),\n",
       " ('linear regression many big picture', 0.23570226039551584),\n",
       " ('process liked overall learning itgot', 0.23570226039551584),\n",
       " ('interview questions technical conversations lots', 0.23570226039551584),\n",
       " ('interview questions related machine learning', 0.23570226039551584),\n",
       " ('question writing ml python package', 0.23570226039551584),\n",
       " ('interview python sql tools would', 0.23570226039551584),\n",
       " ('whats data look like solve', 0.23570226039551584),\n",
       " ('etc great experience got learn', 0.23570226039551584),\n",
       " ('lots focus behavioral questions involving', 0.23570226039551584),\n",
       " ('interview process liked overall learning', 0.23570226039551584),\n",
       " ('interview second round technical took', 0.23570226039551584),\n",
       " ('sql tools would like use', 0.23570226039551584),\n",
       " ('liked overall learning itgot job', 0.23570226039551584),\n",
       " ('questions highly related team interview', 0.23570226039551584),\n",
       " ('like use finish coding session', 0.23570226039551584),\n",
       " ('second round technical took hour', 0.23570226039551584),\n",
       " ('asked mentioned quiz received link', 0.23570226039551584),\n",
       " ('also hour lots focus behavioral', 0.23570226039551584),\n",
       " ('questions interviewee simply said value', 0.23570226039551584),\n",
       " ('questions ie name five assumptions', 0.23570226039551584),\n",
       " ('questions hour second question writing', 0.23570226039551584),\n",
       " ('ie name five assumptions linear', 0.23570226039551584),\n",
       " ('individuals also hour lots focus', 0.23570226039551584),\n",
       " ('vo speaking one hour calls', 0.23570226039551584),\n",
       " ('asked basic oops dbms programmingpython', 0.23570226039551584),\n",
       " ('programmingpython java etc great experience', 0.23570226039551584),\n",
       " ('second question writing ml python', 0.23570226039551584),\n",
       " ('questions first round another phone', 0.23570226039551584),\n",
       " ('principle interview mathematical test oral', 0.23570226039551584),\n",
       " ('machine learning statistics coding coding', 0.23570226039551584),\n",
       " ('learn deliver result resume detailed', 0.23570226039551584),\n",
       " ('phone interview focuses sql python', 0.23570226039551584),\n",
       " ('mathematical test oral technical interview', 0.23570226039551584),\n",
       " ('overall learning itgot job offer', 0.23570226039551584),\n",
       " ('team interview python sql tools', 0.23570226039551584),\n",
       " ('team interview involved speaking different', 0.23570226039551584),\n",
       " ('coding coding questions highly related', 0.23570226039551584),\n",
       " ('involved speaking different individuals also', 0.23570226039551584),\n",
       " ('related team interview python sql', 0.23570226039551584),\n",
       " ('statistics coding coding questions highly', 0.23570226039551584),\n",
       " ('time goal hard achievewhat learn', 0.23570226039551584),\n",
       " ('oops dbms programmingpython java etc', 0.23570226039551584),\n",
       " ('time interview steps changed process', 0.23570226039551584),\n",
       " ('intimidating demanding rewarding exciting signed', 0.23570226039551584),\n",
       " ('interview focuses sql python based', 0.23570226039551584),\n",
       " ('optimization data processing overall good', 0.23570226039551584),\n",
       " ('oral technical interview past projects', 0.23570226039551584),\n",
       " ('different individuals also hour lots', 0.23570226039551584),\n",
       " ('reached linkedin first round phone', 0.23570226039551584),\n",
       " ('round another phone screen onsite', 0.23570226039551584),\n",
       " ('great experience got learn alot', 0.23570226039551584),\n",
       " ('ml questions first round another', 0.23570226039551584),\n",
       " ('itgot job offer also asked', 0.23570226039551584),\n",
       " ('coding questions highly related team', 0.23570226039551584),\n",
       " ('job care nothing technical skills', 0.23570226039551584),\n",
       " ('simply said value customer obsession', 0.23570226039551584),\n",
       " ('go specifics interview questions technical', 0.23570226039551584),\n",
       " ('signed nda cant go specifics', 0.23570226039551584),\n",
       " ('job offer also asked basic', 0.23570226039551584),\n",
       " ('first round another phone screen', 0.23570226039551584),\n",
       " ('received link answer two questions', 0.23570226039551584),\n",
       " ('goal hard achievewhat learn deliver', 0.23570226039551584),\n",
       " ('speaking different individuals also hour', 0.23570226039551584),\n",
       " ('onsite interview drill almost triviastyle', 0.23570226039551584),\n",
       " ('java etc great experience got', 0.23570226039551584),\n",
       " ('detailed questions resume kind problems', 0.23570226039551584),\n",
       " ('speaking one hour calls data', 0.23570226039551584),\n",
       " ('good interview process liked overall', 0.23570226039551584),\n",
       " ('short discussion hr nothing serious', 0.23570226039551584),\n",
       " ('learning statistics coding coding questions', 0.23570226039551584),\n",
       " ('three interviews process fairly easy', 0.23570226039551584),\n",
       " ('interviews process fairly easy first', 0.23570226039551584),\n",
       " ('choice basic ml questions first', 0.23570226039551584),\n",
       " ('sql python based choice basic', 0.23570226039551584),\n",
       " ('tools would like use finish', 0.23570226039551584),\n",
       " ('serious basically asked mentioned quiz', 0.23570226039551584),\n",
       " ('would like use finish coding', 0.23570226039551584),\n",
       " ('starting leadership principle interview mathematical', 0.23570226039551584),\n",
       " ('quiz received link answer two', 0.23570226039551584),\n",
       " ('meet whats data look like', 0.23570226039551584),\n",
       " ('look like solve question result', 0.23570226039551584),\n",
       " ('mentioned quiz received link answer', 0.23570226039551584),\n",
       " ('called wrong date time interview', 0.23570226039551584),\n",
       " ('calls data science team interview', 0.23570226039551584),\n",
       " ('discussion hr nothing serious basically', 0.23570226039551584),\n",
       " ('projects finalonsite interview interviews called', 0.23570226039551584),\n",
       " ('interviews called wrong date time', 0.23570226039551584),\n",
       " ('triviastyle questions ie name five', 0.23570226039551584),\n",
       " ('past projects finalonsite interview interviews', 0.23570226039551584),\n",
       " ('cant go specifics interview questions', 0.23570226039551584),\n",
       " ('questions technical conversations lots behavioral', 0.23570226039551584),\n",
       " ('finalonsite interview interviews called wrong', 0.23570226039551584),\n",
       " ('care nothing technical skills like', 0.23570226039551584),\n",
       " ('took hour answered questions optimization', 0.23570226039551584),\n",
       " ('big picture sort questions seen', 0.23570226039551584),\n",
       " ('questions study leadership principles examples', 0.23570226039551584),\n",
       " ('specifics interview questions technical conversations',\n",
       "  0.23570226039551584),\n",
       " ('linear multivariate analysis questions also', 0.22941573387056177),\n",
       " ('description clear questions asked related', 0.22941573387056177),\n",
       " ('statistics focus machine learning shoein', 0.22941573387056177),\n",
       " ('design basically come answer within', 0.22941573387056177),\n",
       " ('every project worked also asked', 0.22941573387056177),\n",
       " ('lunch break two afternoon technical', 0.22941573387056177),\n",
       " ('easy need practice lot case', 0.22941573387056177),\n",
       " ('manly via calls unfortunately got', 0.22941573387056177),\n",
       " ('morning lunch break two afternoon', 0.22941573387056177),\n",
       " ('statistics coding algorithms also product', 0.22941573387056177),\n",
       " ('linear regression overfit vs underfit', 0.22941573387056177),\n",
       " ('due covid normal call interview', 0.22941573387056177),\n",
       " ('even hr interview scheduled twice', 0.22941573387056177),\n",
       " ('manager things went pretty well', 0.22941573387056177),\n",
       " ('merge operations pandas coding basic', 0.22941573387056177),\n",
       " ('everything went well like whole', 0.22941573387056177),\n",
       " ('related sql scheduling interviews also', 0.22941573387056177),\n",
       " ('study kind simple need familiar', 0.22941573387056177),\n",
       " ('round one coding problem one', 0.22941573387056177),\n",
       " ('first applied via web ad', 0.22941573387056177),\n",
       " ('different rounds two morning lunch', 0.22941573387056177),\n",
       " ('like person interview interviewer went', 0.22941573387056177),\n",
       " ('sql questions merge operations pandas', 0.22941573387056177),\n",
       " ('months schedule technical interview even', 0.22941573387056177),\n",
       " ('discussed correlation heatmap pca dimensionality', 0.22941573387056177),\n",
       " ('difference grid search cv random', 0.22941573387056177),\n",
       " ('study statistical knowledge coding easy', 0.22941573387056177),\n",
       " ('regression overfit vs underfit hard', 0.22941573387056177),\n",
       " ('days several rounds interviews manly', 0.22941573387056177),\n",
       " ('like whole progress recommended interview', 0.22941573387056177),\n",
       " ('focus jobs towards statistics focus', 0.22941573387056177),\n",
       " ('sql scheduling interviews also smooth', 0.22941573387056177),\n",
       " ('lot case study kind simple', 0.22941573387056177),\n",
       " ('first round one coding problem', 0.22941573387056177),\n",
       " ('team manager things went pretty', 0.22941573387056177),\n",
       " ('extensive interviews long process general', 0.22941573387056177),\n",
       " ('long process general first applied', 0.22941573387056177),\n",
       " ('interview interviewer went cv asked', 0.22941573387056177),\n",
       " ('statistical knowledge coding easy need', 0.22941573387056177),\n",
       " ('clear questions asked related sql', 0.22941573387056177),\n",
       " ('asked related sql scheduling interviews', 0.22941573387056177),\n",
       " ('operations pandas coding basic functions', 0.22941573387056177),\n",
       " ('via web ad got contacted', 0.22941573387056177),\n",
       " ('read publications quite impressed accomplishments', 0.22941573387056177),\n",
       " ('search cv random search cv', 0.22941573387056177),\n",
       " ('questions chosen statistics coding algorithms', 0.22941573387056177),\n",
       " ('interviews virtual due covid normal', 0.22941573387056177),\n",
       " ('search cv assumptions linear regression', 0.22941573387056177),\n",
       " ('clear everything went well like', 0.22941573387056177),\n",
       " ('two morning lunch break two', 0.22941573387056177),\n",
       " ('chosen statistics coding algorithms also', 0.22941573387056177),\n",
       " ('several rounds interviews manly via', 0.22941573387056177),\n",
       " ('asked phd thesis related job', 0.22941573387056177),\n",
       " ('applied via web ad got', 0.22941573387056177),\n",
       " ('interview went quite well interviewer', 0.22941573387056177),\n",
       " ('coding algorithms also product design', 0.22941573387056177),\n",
       " ('process general first applied via', 0.22941573387056177),\n",
       " ('coding problem one case study', 0.22941573387056177),\n",
       " ('senior person hiring group read', 0.22941573387056177),\n",
       " ('went cv asked every project', 0.22941573387056177),\n",
       " ('three months schedule technical interview', 0.22941573387056177),\n",
       " ('instructor clear everything went well', 0.22941573387056177),\n",
       " ('questions merge operations pandas coding', 0.22941573387056177),\n",
       " ('questions asked related sql scheduling', 0.22941573387056177),\n",
       " ('well like whole progress recommended', 0.22941573387056177),\n",
       " ('coding basic functions pandas beginning', 0.22941573387056177),\n",
       " ('problem one case study statistical', 0.22941573387056177),\n",
       " ('well interviewer senior person hiring', 0.22941573387056177),\n",
       " ('variable bootstrapping difference grid search', 0.22941573387056177),\n",
       " ('coding easy need practice lot', 0.22941573387056177),\n",
       " ('via calls unfortunately got rejected', 0.22941573387056177),\n",
       " ('got contacted within days several', 0.22941573387056177),\n",
       " ('virtual due covid normal call', 0.22941573387056177),\n",
       " ('person interview interviewer went cv', 0.22941573387056177),\n",
       " ('categorical variable bootstrapping difference grid', 0.22941573387056177),\n",
       " ('call interview like person interview', 0.22941573387056177),\n",
       " ('pandas coding basic functions pandas', 0.22941573387056177),\n",
       " ('total three months schedule technical', 0.22941573387056177),\n",
       " ('towards statistics focus machine learning', 0.22941573387056177),\n",
       " ('quite well interviewer senior person', 0.22941573387056177),\n",
       " ('handle categorical variable bootstrapping difference', 0.22941573387056177),\n",
       " ('interviews long process general first', 0.22941573387056177),\n",
       " ('quite impressed accomplishments focus jobs', 0.22941573387056177),\n",
       " ('case study statistical knowledge coding', 0.22941573387056177),\n",
       " ('asked every project worked also', 0.22941573387056177),\n",
       " ('two afternoon technical questions chosen', 0.22941573387056177),\n",
       " ('vs underfit hard simple easy', 0.22941573387056177),\n",
       " ('break two afternoon technical questions', 0.22941573387056177),\n",
       " ('hard simple easy hope helps', 0.22941573387056177),\n",
       " ('practice lot case study kind', 0.22941573387056177),\n",
       " ('impressed accomplishments focus jobs towards', 0.22941573387056177),\n",
       " ('pandas beginning linear multivariate analysis', 0.22941573387056177),\n",
       " ('interviews manly via calls unfortunately', 0.22941573387056177),\n",
       " ('random search cv assumptions linear', 0.22941573387056177),\n",
       " ('pretty well whole interview progress', 0.22941573387056177),\n",
       " ('took total three months schedule', 0.22941573387056177),\n",
       " ('overfit vs underfit hard simple', 0.22941573387056177),\n",
       " ('interviews also smooth took total', 0.22941573387056177),\n",
       " ('tom great team manager things', 0.22941573387056177),\n",
       " ('scheduling interviews also smooth took', 0.22941573387056177),\n",
       " ('web ad got contacted within', 0.22941573387056177),\n",
       " ('group read publications quite impressed', 0.22941573387056177),\n",
       " ('person hiring group read publications', 0.22941573387056177),\n",
       " ('schedule technical interview even hr', 0.22941573387056177),\n",
       " ('case study kind simple need', 0.22941573387056177),\n",
       " ('grid search cv random search', 0.22941573387056177),\n",
       " ('great team manager things went', 0.22941573387056177),\n",
       " ('analysis questions also discussed correlation', 0.22941573387056177),\n",
       " ('good instructor clear everything went', 0.22941573387056177),\n",
       " ('went pretty well whole interview', 0.22941573387056177),\n",
       " ('interviewer senior person hiring group', 0.22941573387056177),\n",
       " ('ad got contacted within days', 0.22941573387056177),\n",
       " ('future tom great team manager', 0.22941573387056177),\n",
       " ('technical questions chosen statistics coding', 0.22941573387056177),\n",
       " ('interview like person interview interviewer', 0.22941573387056177),\n",
       " ('covid normal call interview like', 0.22941573387056177),\n",
       " ('afternoon technical questions chosen statistics', 0.22941573387056177),\n",
       " ('interview even hr interview scheduled', 0.22941573387056177),\n",
       " ('worked also asked phd thesis', 0.22941573387056177),\n",
       " ('interviewer went cv asked every', 0.22941573387056177),\n",
       " ('normal call interview like person', 0.22941573387056177),\n",
       " ('project worked also asked phd', 0.22941573387056177),\n",
       " ('general first applied via web', 0.22941573387056177),\n",
       " ('rounds interviews manly via calls', 0.22941573387056177),\n",
       " ('correlation heatmap pca dimensionality reduction', 0.22941573387056177),\n",
       " ('cv asked every project worked', 0.22941573387056177),\n",
       " ('cv assumptions linear regression overfit', 0.22941573387056177),\n",
       " ...]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonprocess_vectorizer = TfidfVectorizer(ngram_range=(5,5), min_df=0.001, max_df = 0.75)\n",
    "amazon_vectorized_process = pd.DataFrame(amazonprocess_vectorizer.fit_transform(amazon_process_df['Process']).toarray(), columns = amazonprocess_vectorizer.get_feature_names_out())\n",
    "amazon_vectorized_process.loc['Total'] = amazon_vectorized_process.sum(numeric_only=True, axis=0)\n",
    "amazon_vectorized_process = amazon_vectorized_process.sort_values(amazon_vectorized_process.last_valid_index(), axis=1, ascending=False)\n",
    "amazonprocess_sorted_word_list = [(col, amazon_vectorized_process[col].iloc[-1]) for col in amazon_vectorized_process.columns]\n",
    "amazonprocess_sorted_word_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "best_company",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
